{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7db062d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T13:18:27.359337Z",
     "start_time": "2021-11-26T13:18:26.632172Z"
    }
   },
   "outputs": [],
   "source": [
    "from nets.yolo import YoloBody\n",
    "import torch\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76278d4a",
   "metadata": {},
   "source": [
    "## SwinYOLO=709\n",
    "## backbone=617, head=108\n",
    "## backbone.backbone=361\n",
    "### backbone.backbone.patch_embed=4,\n",
    "### backbone.backbone.layers=357\n",
    "#### layers.0=28,layers.1=31,layers.2=255,layers.3=31,layers.4=12(即spp)\n",
    "## bu_conv2=6,bu_conv1=6, lateral=6, reduce_conv=6, c3=216   记为other：240"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525d76d4",
   "metadata": {},
   "source": [
    "## other(240) + head(108) + layers.4(12)= 360 from YOLOX\n",
    "## backbone.backbone.patch_embed(4) + backbone.backbone.layers(0-3)(345)=349 from swin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65ad757",
   "metadata": {},
   "source": [
    "## 查看model其中的参数（非体系）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e39a440b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T13:18:29.180661Z",
     "start_time": "2021-11-26T13:18:27.360885Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backbone.backbone.patch_embed.proj.weight \t torch.Size([128, 3, 4, 4])\n",
      "709 0\n",
      "backbone.backbone.patch_embed.proj.bias \t torch.Size([128])\n",
      "709 0\n",
      "backbone.backbone.patch_embed.norm.weight \t torch.Size([128])\n",
      "709 0\n",
      "backbone.backbone.patch_embed.norm.bias \t torch.Size([128])\n",
      "709 0\n",
      "backbone.backbone.layers.0.blocks.0.norm1.weight \t torch.Size([128])\n",
      "709 0\n",
      "backbone.backbone.layers.0.blocks.0.norm1.bias \t torch.Size([128])\n",
      "709 0\n",
      "backbone.backbone.layers.0.blocks.0.attn.relative_position_bias_table \t torch.Size([529, 4])\n",
      "709 0\n",
      "backbone.backbone.layers.0.blocks.0.attn.relative_position_index \t torch.Size([144, 144])\n",
      "709 0\n",
      "backbone.backbone.layers.0.blocks.0.attn.qkv.weight \t torch.Size([384, 128])\n",
      "709 0\n",
      "backbone.backbone.layers.0.blocks.0.attn.qkv.bias \t torch.Size([384])\n",
      "709 0\n",
      "backbone.backbone.layers.0.blocks.0.attn.proj.weight \t torch.Size([128, 128])\n",
      "709 0\n",
      "backbone.backbone.layers.0.blocks.0.attn.proj.bias \t torch.Size([128])\n",
      "709 0\n",
      "backbone.backbone.layers.0.blocks.0.norm2.weight \t torch.Size([128])\n",
      "709 0\n",
      "backbone.backbone.layers.0.blocks.0.norm2.bias \t torch.Size([128])\n",
      "709 0\n",
      "backbone.backbone.layers.0.blocks.0.mlp.fc1.weight \t torch.Size([512, 128])\n",
      "709 0\n",
      "backbone.backbone.layers.0.blocks.0.mlp.fc1.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.0.blocks.0.mlp.fc2.weight \t torch.Size([128, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.0.blocks.0.mlp.fc2.bias \t torch.Size([128])\n",
      "709 0\n",
      "backbone.backbone.layers.0.blocks.1.norm1.weight \t torch.Size([128])\n",
      "709 0\n",
      "backbone.backbone.layers.0.blocks.1.norm1.bias \t torch.Size([128])\n",
      "709 0\n",
      "backbone.backbone.layers.0.blocks.1.attn.relative_position_bias_table \t torch.Size([529, 4])\n",
      "709 0\n",
      "backbone.backbone.layers.0.blocks.1.attn.relative_position_index \t torch.Size([144, 144])\n",
      "709 0\n",
      "backbone.backbone.layers.0.blocks.1.attn.qkv.weight \t torch.Size([384, 128])\n",
      "709 0\n",
      "backbone.backbone.layers.0.blocks.1.attn.qkv.bias \t torch.Size([384])\n",
      "709 0\n",
      "backbone.backbone.layers.0.blocks.1.attn.proj.weight \t torch.Size([128, 128])\n",
      "709 0\n",
      "backbone.backbone.layers.0.blocks.1.attn.proj.bias \t torch.Size([128])\n",
      "709 0\n",
      "backbone.backbone.layers.0.blocks.1.norm2.weight \t torch.Size([128])\n",
      "709 0\n",
      "backbone.backbone.layers.0.blocks.1.norm2.bias \t torch.Size([128])\n",
      "709 0\n",
      "backbone.backbone.layers.0.blocks.1.mlp.fc1.weight \t torch.Size([512, 128])\n",
      "709 0\n",
      "backbone.backbone.layers.0.blocks.1.mlp.fc1.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.0.blocks.1.mlp.fc2.weight \t torch.Size([128, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.0.blocks.1.mlp.fc2.bias \t torch.Size([128])\n",
      "709 0\n",
      "backbone.backbone.layers.1.blocks.0.norm1.weight \t torch.Size([256])\n",
      "709 0\n",
      "backbone.backbone.layers.1.blocks.0.norm1.bias \t torch.Size([256])\n",
      "709 0\n",
      "backbone.backbone.layers.1.blocks.0.attn.relative_position_bias_table \t torch.Size([529, 8])\n",
      "709 0\n",
      "backbone.backbone.layers.1.blocks.0.attn.relative_position_index \t torch.Size([144, 144])\n",
      "709 0\n",
      "backbone.backbone.layers.1.blocks.0.attn.qkv.weight \t torch.Size([768, 256])\n",
      "709 0\n",
      "backbone.backbone.layers.1.blocks.0.attn.qkv.bias \t torch.Size([768])\n",
      "709 0\n",
      "backbone.backbone.layers.1.blocks.0.attn.proj.weight \t torch.Size([256, 256])\n",
      "709 0\n",
      "backbone.backbone.layers.1.blocks.0.attn.proj.bias \t torch.Size([256])\n",
      "709 0\n",
      "backbone.backbone.layers.1.blocks.0.norm2.weight \t torch.Size([256])\n",
      "709 0\n",
      "backbone.backbone.layers.1.blocks.0.norm2.bias \t torch.Size([256])\n",
      "709 0\n",
      "backbone.backbone.layers.1.blocks.0.mlp.fc1.weight \t torch.Size([1024, 256])\n",
      "709 0\n",
      "backbone.backbone.layers.1.blocks.0.mlp.fc1.bias \t torch.Size([1024])\n",
      "709 0\n",
      "backbone.backbone.layers.1.blocks.0.mlp.fc2.weight \t torch.Size([256, 1024])\n",
      "709 0\n",
      "backbone.backbone.layers.1.blocks.0.mlp.fc2.bias \t torch.Size([256])\n",
      "709 0\n",
      "backbone.backbone.layers.1.blocks.1.norm1.weight \t torch.Size([256])\n",
      "709 0\n",
      "backbone.backbone.layers.1.blocks.1.norm1.bias \t torch.Size([256])\n",
      "709 0\n",
      "backbone.backbone.layers.1.blocks.1.attn.relative_position_bias_table \t torch.Size([529, 8])\n",
      "709 0\n",
      "backbone.backbone.layers.1.blocks.1.attn.relative_position_index \t torch.Size([144, 144])\n",
      "709 0\n",
      "backbone.backbone.layers.1.blocks.1.attn.qkv.weight \t torch.Size([768, 256])\n",
      "709 0\n",
      "backbone.backbone.layers.1.blocks.1.attn.qkv.bias \t torch.Size([768])\n",
      "709 0\n",
      "backbone.backbone.layers.1.blocks.1.attn.proj.weight \t torch.Size([256, 256])\n",
      "709 0\n",
      "backbone.backbone.layers.1.blocks.1.attn.proj.bias \t torch.Size([256])\n",
      "709 0\n",
      "backbone.backbone.layers.1.blocks.1.norm2.weight \t torch.Size([256])\n",
      "709 0\n",
      "backbone.backbone.layers.1.blocks.1.norm2.bias \t torch.Size([256])\n",
      "709 0\n",
      "backbone.backbone.layers.1.blocks.1.mlp.fc1.weight \t torch.Size([1024, 256])\n",
      "709 0\n",
      "backbone.backbone.layers.1.blocks.1.mlp.fc1.bias \t torch.Size([1024])\n",
      "709 0\n",
      "backbone.backbone.layers.1.blocks.1.mlp.fc2.weight \t torch.Size([256, 1024])\n",
      "709 0\n",
      "backbone.backbone.layers.1.blocks.1.mlp.fc2.bias \t torch.Size([256])\n",
      "709 0\n",
      "backbone.backbone.layers.1.downsample.reduction.weight \t torch.Size([256, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.1.downsample.norm.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.1.downsample.norm.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.0.norm1.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.0.norm1.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.0.attn.relative_position_bias_table \t torch.Size([529, 16])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.0.attn.relative_position_index \t torch.Size([144, 144])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.0.attn.qkv.weight \t torch.Size([1536, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.0.attn.qkv.bias \t torch.Size([1536])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.0.attn.proj.weight \t torch.Size([512, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.0.attn.proj.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.0.norm2.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.0.norm2.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.0.mlp.fc1.weight \t torch.Size([2048, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.0.mlp.fc1.bias \t torch.Size([2048])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.0.mlp.fc2.weight \t torch.Size([512, 2048])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.0.mlp.fc2.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.1.norm1.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.1.norm1.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.1.attn.relative_position_bias_table \t torch.Size([529, 16])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.1.attn.relative_position_index \t torch.Size([144, 144])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.1.attn.qkv.weight \t torch.Size([1536, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.1.attn.qkv.bias \t torch.Size([1536])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.1.attn.proj.weight \t torch.Size([512, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.1.attn.proj.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.1.norm2.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.1.norm2.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.1.mlp.fc1.weight \t torch.Size([2048, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.1.mlp.fc1.bias \t torch.Size([2048])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.1.mlp.fc2.weight \t torch.Size([512, 2048])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.1.mlp.fc2.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.2.norm1.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.2.norm1.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.2.attn.relative_position_bias_table \t torch.Size([529, 16])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.2.attn.relative_position_index \t torch.Size([144, 144])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.2.attn.qkv.weight \t torch.Size([1536, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.2.attn.qkv.bias \t torch.Size([1536])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.2.attn.proj.weight \t torch.Size([512, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.2.attn.proj.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.2.norm2.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.2.norm2.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.2.mlp.fc1.weight \t torch.Size([2048, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.2.mlp.fc1.bias \t torch.Size([2048])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.2.mlp.fc2.weight \t torch.Size([512, 2048])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.2.mlp.fc2.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.3.norm1.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.3.norm1.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.3.attn.relative_position_bias_table \t torch.Size([529, 16])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.3.attn.relative_position_index \t torch.Size([144, 144])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.3.attn.qkv.weight \t torch.Size([1536, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.3.attn.qkv.bias \t torch.Size([1536])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.3.attn.proj.weight \t torch.Size([512, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.3.attn.proj.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.3.norm2.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.3.norm2.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.3.mlp.fc1.weight \t torch.Size([2048, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.3.mlp.fc1.bias \t torch.Size([2048])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.3.mlp.fc2.weight \t torch.Size([512, 2048])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.3.mlp.fc2.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.4.norm1.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.4.norm1.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.4.attn.relative_position_bias_table \t torch.Size([529, 16])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.4.attn.relative_position_index \t torch.Size([144, 144])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.4.attn.qkv.weight \t torch.Size([1536, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.4.attn.qkv.bias \t torch.Size([1536])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.4.attn.proj.weight \t torch.Size([512, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.4.attn.proj.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.4.norm2.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.4.norm2.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.4.mlp.fc1.weight \t torch.Size([2048, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.4.mlp.fc1.bias \t torch.Size([2048])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.4.mlp.fc2.weight \t torch.Size([512, 2048])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.4.mlp.fc2.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.5.norm1.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.5.norm1.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.5.attn.relative_position_bias_table \t torch.Size([529, 16])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.5.attn.relative_position_index \t torch.Size([144, 144])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.5.attn.qkv.weight \t torch.Size([1536, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.5.attn.qkv.bias \t torch.Size([1536])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.5.attn.proj.weight \t torch.Size([512, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.5.attn.proj.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.5.norm2.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.5.norm2.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.5.mlp.fc1.weight \t torch.Size([2048, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.5.mlp.fc1.bias \t torch.Size([2048])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.5.mlp.fc2.weight \t torch.Size([512, 2048])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.5.mlp.fc2.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.6.norm1.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.6.norm1.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.6.attn.relative_position_bias_table \t torch.Size([529, 16])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.6.attn.relative_position_index \t torch.Size([144, 144])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.6.attn.qkv.weight \t torch.Size([1536, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.6.attn.qkv.bias \t torch.Size([1536])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.6.attn.proj.weight \t torch.Size([512, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.6.attn.proj.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.6.norm2.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.6.norm2.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.6.mlp.fc1.weight \t torch.Size([2048, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.6.mlp.fc1.bias \t torch.Size([2048])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.6.mlp.fc2.weight \t torch.Size([512, 2048])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.6.mlp.fc2.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.7.norm1.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.7.norm1.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.7.attn.relative_position_bias_table \t torch.Size([529, 16])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.7.attn.relative_position_index \t torch.Size([144, 144])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.7.attn.qkv.weight \t torch.Size([1536, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.7.attn.qkv.bias \t torch.Size([1536])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.7.attn.proj.weight \t torch.Size([512, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.7.attn.proj.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.7.norm2.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.7.norm2.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.7.mlp.fc1.weight \t torch.Size([2048, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.7.mlp.fc1.bias \t torch.Size([2048])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.7.mlp.fc2.weight \t torch.Size([512, 2048])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.7.mlp.fc2.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.8.norm1.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.8.norm1.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.8.attn.relative_position_bias_table \t torch.Size([529, 16])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.8.attn.relative_position_index \t torch.Size([144, 144])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.8.attn.qkv.weight \t torch.Size([1536, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.8.attn.qkv.bias \t torch.Size([1536])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.8.attn.proj.weight \t torch.Size([512, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.8.attn.proj.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.8.norm2.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.8.norm2.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.8.mlp.fc1.weight \t torch.Size([2048, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.8.mlp.fc1.bias \t torch.Size([2048])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.8.mlp.fc2.weight \t torch.Size([512, 2048])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.8.mlp.fc2.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.9.norm1.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.9.norm1.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.9.attn.relative_position_bias_table \t torch.Size([529, 16])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.9.attn.relative_position_index \t torch.Size([144, 144])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.9.attn.qkv.weight \t torch.Size([1536, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.9.attn.qkv.bias \t torch.Size([1536])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.9.attn.proj.weight \t torch.Size([512, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.9.attn.proj.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.9.norm2.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.9.norm2.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.9.mlp.fc1.weight \t torch.Size([2048, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.9.mlp.fc1.bias \t torch.Size([2048])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.9.mlp.fc2.weight \t torch.Size([512, 2048])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.9.mlp.fc2.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.10.norm1.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.10.norm1.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.10.attn.relative_position_bias_table \t torch.Size([529, 16])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.10.attn.relative_position_index \t torch.Size([144, 144])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.10.attn.qkv.weight \t torch.Size([1536, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.10.attn.qkv.bias \t torch.Size([1536])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.10.attn.proj.weight \t torch.Size([512, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.10.attn.proj.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.10.norm2.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.10.norm2.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.10.mlp.fc1.weight \t torch.Size([2048, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.10.mlp.fc1.bias \t torch.Size([2048])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.10.mlp.fc2.weight \t torch.Size([512, 2048])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.10.mlp.fc2.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.11.norm1.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.11.norm1.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.11.attn.relative_position_bias_table \t torch.Size([529, 16])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.11.attn.relative_position_index \t torch.Size([144, 144])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.11.attn.qkv.weight \t torch.Size([1536, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.11.attn.qkv.bias \t torch.Size([1536])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.11.attn.proj.weight \t torch.Size([512, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.11.attn.proj.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.11.norm2.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.11.norm2.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.11.mlp.fc1.weight \t torch.Size([2048, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.11.mlp.fc1.bias \t torch.Size([2048])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.11.mlp.fc2.weight \t torch.Size([512, 2048])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.11.mlp.fc2.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.12.norm1.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.12.norm1.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.12.attn.relative_position_bias_table \t torch.Size([529, 16])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.12.attn.relative_position_index \t torch.Size([144, 144])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.12.attn.qkv.weight \t torch.Size([1536, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.12.attn.qkv.bias \t torch.Size([1536])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.12.attn.proj.weight \t torch.Size([512, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.12.attn.proj.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.12.norm2.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.12.norm2.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.12.mlp.fc1.weight \t torch.Size([2048, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.12.mlp.fc1.bias \t torch.Size([2048])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.12.mlp.fc2.weight \t torch.Size([512, 2048])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.12.mlp.fc2.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.13.norm1.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.13.norm1.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.13.attn.relative_position_bias_table \t torch.Size([529, 16])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.13.attn.relative_position_index \t torch.Size([144, 144])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.13.attn.qkv.weight \t torch.Size([1536, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.13.attn.qkv.bias \t torch.Size([1536])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.13.attn.proj.weight \t torch.Size([512, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.13.attn.proj.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.13.norm2.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.13.norm2.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.13.mlp.fc1.weight \t torch.Size([2048, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.13.mlp.fc1.bias \t torch.Size([2048])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.13.mlp.fc2.weight \t torch.Size([512, 2048])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.13.mlp.fc2.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.14.norm1.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.14.norm1.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.14.attn.relative_position_bias_table \t torch.Size([529, 16])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.14.attn.relative_position_index \t torch.Size([144, 144])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.14.attn.qkv.weight \t torch.Size([1536, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.14.attn.qkv.bias \t torch.Size([1536])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.14.attn.proj.weight \t torch.Size([512, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.14.attn.proj.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.14.norm2.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.14.norm2.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.14.mlp.fc1.weight \t torch.Size([2048, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.14.mlp.fc1.bias \t torch.Size([2048])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.14.mlp.fc2.weight \t torch.Size([512, 2048])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.14.mlp.fc2.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.15.norm1.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.15.norm1.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.15.attn.relative_position_bias_table \t torch.Size([529, 16])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.15.attn.relative_position_index \t torch.Size([144, 144])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.15.attn.qkv.weight \t torch.Size([1536, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.15.attn.qkv.bias \t torch.Size([1536])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.15.attn.proj.weight \t torch.Size([512, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.15.attn.proj.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.15.norm2.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.15.norm2.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.15.mlp.fc1.weight \t torch.Size([2048, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.15.mlp.fc1.bias \t torch.Size([2048])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.15.mlp.fc2.weight \t torch.Size([512, 2048])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.15.mlp.fc2.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.16.norm1.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.16.norm1.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.16.attn.relative_position_bias_table \t torch.Size([529, 16])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.16.attn.relative_position_index \t torch.Size([144, 144])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.16.attn.qkv.weight \t torch.Size([1536, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.16.attn.qkv.bias \t torch.Size([1536])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.16.attn.proj.weight \t torch.Size([512, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.16.attn.proj.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.16.norm2.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.16.norm2.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.16.mlp.fc1.weight \t torch.Size([2048, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.16.mlp.fc1.bias \t torch.Size([2048])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.16.mlp.fc2.weight \t torch.Size([512, 2048])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.16.mlp.fc2.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.17.norm1.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.17.norm1.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.17.attn.relative_position_bias_table \t torch.Size([529, 16])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.17.attn.relative_position_index \t torch.Size([144, 144])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.17.attn.qkv.weight \t torch.Size([1536, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.17.attn.qkv.bias \t torch.Size([1536])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.17.attn.proj.weight \t torch.Size([512, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.17.attn.proj.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.17.norm2.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.17.norm2.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.17.mlp.fc1.weight \t torch.Size([2048, 512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.17.mlp.fc1.bias \t torch.Size([2048])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.17.mlp.fc2.weight \t torch.Size([512, 2048])\n",
      "709 0\n",
      "backbone.backbone.layers.2.blocks.17.mlp.fc2.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.2.downsample.reduction.weight \t torch.Size([512, 1024])\n",
      "709 0\n",
      "backbone.backbone.layers.2.downsample.norm.weight \t torch.Size([1024])\n",
      "709 0\n",
      "backbone.backbone.layers.2.downsample.norm.bias \t torch.Size([1024])\n",
      "709 0\n",
      "backbone.backbone.layers.3.blocks.0.norm1.weight \t torch.Size([1024])\n",
      "709 0\n",
      "backbone.backbone.layers.3.blocks.0.norm1.bias \t torch.Size([1024])\n",
      "709 0\n",
      "backbone.backbone.layers.3.blocks.0.attn.relative_position_bias_table \t torch.Size([529, 32])\n",
      "709 0\n",
      "backbone.backbone.layers.3.blocks.0.attn.relative_position_index \t torch.Size([144, 144])\n",
      "709 0\n",
      "backbone.backbone.layers.3.blocks.0.attn.qkv.weight \t torch.Size([3072, 1024])\n",
      "709 0\n",
      "backbone.backbone.layers.3.blocks.0.attn.qkv.bias \t torch.Size([3072])\n",
      "709 0\n",
      "backbone.backbone.layers.3.blocks.0.attn.proj.weight \t torch.Size([1024, 1024])\n",
      "709 0\n",
      "backbone.backbone.layers.3.blocks.0.attn.proj.bias \t torch.Size([1024])\n",
      "709 0\n",
      "backbone.backbone.layers.3.blocks.0.norm2.weight \t torch.Size([1024])\n",
      "709 0\n",
      "backbone.backbone.layers.3.blocks.0.norm2.bias \t torch.Size([1024])\n",
      "709 0\n",
      "backbone.backbone.layers.3.blocks.0.mlp.fc1.weight \t torch.Size([4096, 1024])\n",
      "709 0\n",
      "backbone.backbone.layers.3.blocks.0.mlp.fc1.bias \t torch.Size([4096])\n",
      "709 0\n",
      "backbone.backbone.layers.3.blocks.0.mlp.fc2.weight \t torch.Size([1024, 4096])\n",
      "709 0\n",
      "backbone.backbone.layers.3.blocks.0.mlp.fc2.bias \t torch.Size([1024])\n",
      "709 0\n",
      "backbone.backbone.layers.3.blocks.1.norm1.weight \t torch.Size([1024])\n",
      "709 0\n",
      "backbone.backbone.layers.3.blocks.1.norm1.bias \t torch.Size([1024])\n",
      "709 0\n",
      "backbone.backbone.layers.3.blocks.1.attn.relative_position_bias_table \t torch.Size([529, 32])\n",
      "709 0\n",
      "backbone.backbone.layers.3.blocks.1.attn.relative_position_index \t torch.Size([144, 144])\n",
      "709 0\n",
      "backbone.backbone.layers.3.blocks.1.attn.qkv.weight \t torch.Size([3072, 1024])\n",
      "709 0\n",
      "backbone.backbone.layers.3.blocks.1.attn.qkv.bias \t torch.Size([3072])\n",
      "709 0\n",
      "backbone.backbone.layers.3.blocks.1.attn.proj.weight \t torch.Size([1024, 1024])\n",
      "709 0\n",
      "backbone.backbone.layers.3.blocks.1.attn.proj.bias \t torch.Size([1024])\n",
      "709 0\n",
      "backbone.backbone.layers.3.blocks.1.norm2.weight \t torch.Size([1024])\n",
      "709 0\n",
      "backbone.backbone.layers.3.blocks.1.norm2.bias \t torch.Size([1024])\n",
      "709 0\n",
      "backbone.backbone.layers.3.blocks.1.mlp.fc1.weight \t torch.Size([4096, 1024])\n",
      "709 0\n",
      "backbone.backbone.layers.3.blocks.1.mlp.fc1.bias \t torch.Size([4096])\n",
      "709 0\n",
      "backbone.backbone.layers.3.blocks.1.mlp.fc2.weight \t torch.Size([1024, 4096])\n",
      "709 0\n",
      "backbone.backbone.layers.3.blocks.1.mlp.fc2.bias \t torch.Size([1024])\n",
      "709 0\n",
      "backbone.backbone.layers.3.downsample.reduction.weight \t torch.Size([1024, 2048])\n",
      "709 0\n",
      "backbone.backbone.layers.3.downsample.norm.weight \t torch.Size([2048])\n",
      "709 0\n",
      "backbone.backbone.layers.3.downsample.norm.bias \t torch.Size([2048])\n",
      "709 0\n",
      "backbone.backbone.layers.4.conv1.conv.weight \t torch.Size([512, 1024, 1, 1])\n",
      "709 0\n",
      "backbone.backbone.layers.4.conv1.bn.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.4.conv1.bn.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.4.conv1.bn.running_mean \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.4.conv1.bn.running_var \t torch.Size([512])\n",
      "709 0\n",
      "backbone.backbone.layers.4.conv1.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "backbone.backbone.layers.4.conv2.conv.weight \t torch.Size([1024, 2048, 1, 1])\n",
      "709 0\n",
      "backbone.backbone.layers.4.conv2.bn.weight \t torch.Size([1024])\n",
      "709 0\n",
      "backbone.backbone.layers.4.conv2.bn.bias \t torch.Size([1024])\n",
      "709 0\n",
      "backbone.backbone.layers.4.conv2.bn.running_mean \t torch.Size([1024])\n",
      "709 0\n",
      "backbone.backbone.layers.4.conv2.bn.running_var \t torch.Size([1024])\n",
      "709 0\n",
      "backbone.backbone.layers.4.conv2.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "backbone.lateral_conv0.conv.weight \t torch.Size([512, 1024, 1, 1])\n",
      "709 0\n",
      "backbone.lateral_conv0.bn.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.lateral_conv0.bn.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.lateral_conv0.bn.running_mean \t torch.Size([512])\n",
      "709 0\n",
      "backbone.lateral_conv0.bn.running_var \t torch.Size([512])\n",
      "709 0\n",
      "backbone.lateral_conv0.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "backbone.C3_p4.conv1.conv.weight \t torch.Size([256, 1024, 1, 1])\n",
      "709 0\n",
      "backbone.C3_p4.conv1.bn.weight \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_p4.conv1.bn.bias \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_p4.conv1.bn.running_mean \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_p4.conv1.bn.running_var \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_p4.conv1.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "backbone.C3_p4.conv2.conv.weight \t torch.Size([256, 1024, 1, 1])\n",
      "709 0\n",
      "backbone.C3_p4.conv2.bn.weight \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_p4.conv2.bn.bias \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_p4.conv2.bn.running_mean \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_p4.conv2.bn.running_var \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_p4.conv2.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "backbone.C3_p4.conv3.conv.weight \t torch.Size([512, 512, 1, 1])\n",
      "709 0\n",
      "backbone.C3_p4.conv3.bn.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.C3_p4.conv3.bn.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.C3_p4.conv3.bn.running_mean \t torch.Size([512])\n",
      "709 0\n",
      "backbone.C3_p4.conv3.bn.running_var \t torch.Size([512])\n",
      "709 0\n",
      "backbone.C3_p4.conv3.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "backbone.C3_p4.m.0.conv1.conv.weight \t torch.Size([256, 256, 1, 1])\n",
      "709 0\n",
      "backbone.C3_p4.m.0.conv1.bn.weight \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_p4.m.0.conv1.bn.bias \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_p4.m.0.conv1.bn.running_mean \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_p4.m.0.conv1.bn.running_var \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_p4.m.0.conv1.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "backbone.C3_p4.m.0.conv2.conv.weight \t torch.Size([256, 256, 3, 3])\n",
      "709 0\n",
      "backbone.C3_p4.m.0.conv2.bn.weight \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_p4.m.0.conv2.bn.bias \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_p4.m.0.conv2.bn.running_mean \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_p4.m.0.conv2.bn.running_var \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_p4.m.0.conv2.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "backbone.C3_p4.m.1.conv1.conv.weight \t torch.Size([256, 256, 1, 1])\n",
      "709 0\n",
      "backbone.C3_p4.m.1.conv1.bn.weight \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_p4.m.1.conv1.bn.bias \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_p4.m.1.conv1.bn.running_mean \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_p4.m.1.conv1.bn.running_var \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_p4.m.1.conv1.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "backbone.C3_p4.m.1.conv2.conv.weight \t torch.Size([256, 256, 3, 3])\n",
      "709 0\n",
      "backbone.C3_p4.m.1.conv2.bn.weight \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_p4.m.1.conv2.bn.bias \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_p4.m.1.conv2.bn.running_mean \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_p4.m.1.conv2.bn.running_var \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_p4.m.1.conv2.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "backbone.C3_p4.m.2.conv1.conv.weight \t torch.Size([256, 256, 1, 1])\n",
      "709 0\n",
      "backbone.C3_p4.m.2.conv1.bn.weight \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_p4.m.2.conv1.bn.bias \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_p4.m.2.conv1.bn.running_mean \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_p4.m.2.conv1.bn.running_var \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_p4.m.2.conv1.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "backbone.C3_p4.m.2.conv2.conv.weight \t torch.Size([256, 256, 3, 3])\n",
      "709 0\n",
      "backbone.C3_p4.m.2.conv2.bn.weight \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_p4.m.2.conv2.bn.bias \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_p4.m.2.conv2.bn.running_mean \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_p4.m.2.conv2.bn.running_var \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_p4.m.2.conv2.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "backbone.reduce_conv1.conv.weight \t torch.Size([256, 512, 1, 1])\n",
      "709 0\n",
      "backbone.reduce_conv1.bn.weight \t torch.Size([256])\n",
      "709 0\n",
      "backbone.reduce_conv1.bn.bias \t torch.Size([256])\n",
      "709 0\n",
      "backbone.reduce_conv1.bn.running_mean \t torch.Size([256])\n",
      "709 0\n",
      "backbone.reduce_conv1.bn.running_var \t torch.Size([256])\n",
      "709 0\n",
      "backbone.reduce_conv1.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "backbone.C3_p3.conv1.conv.weight \t torch.Size([128, 512, 1, 1])\n",
      "709 0\n",
      "backbone.C3_p3.conv1.bn.weight \t torch.Size([128])\n",
      "709 0\n",
      "backbone.C3_p3.conv1.bn.bias \t torch.Size([128])\n",
      "709 0\n",
      "backbone.C3_p3.conv1.bn.running_mean \t torch.Size([128])\n",
      "709 0\n",
      "backbone.C3_p3.conv1.bn.running_var \t torch.Size([128])\n",
      "709 0\n",
      "backbone.C3_p3.conv1.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "backbone.C3_p3.conv2.conv.weight \t torch.Size([128, 512, 1, 1])\n",
      "709 0\n",
      "backbone.C3_p3.conv2.bn.weight \t torch.Size([128])\n",
      "709 0\n",
      "backbone.C3_p3.conv2.bn.bias \t torch.Size([128])\n",
      "709 0\n",
      "backbone.C3_p3.conv2.bn.running_mean \t torch.Size([128])\n",
      "709 0\n",
      "backbone.C3_p3.conv2.bn.running_var \t torch.Size([128])\n",
      "709 0\n",
      "backbone.C3_p3.conv2.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "backbone.C3_p3.conv3.conv.weight \t torch.Size([256, 256, 1, 1])\n",
      "709 0\n",
      "backbone.C3_p3.conv3.bn.weight \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_p3.conv3.bn.bias \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_p3.conv3.bn.running_mean \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_p3.conv3.bn.running_var \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_p3.conv3.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "backbone.C3_p3.m.0.conv1.conv.weight \t torch.Size([128, 128, 1, 1])\n",
      "709 0\n",
      "backbone.C3_p3.m.0.conv1.bn.weight \t torch.Size([128])\n",
      "709 0\n",
      "backbone.C3_p3.m.0.conv1.bn.bias \t torch.Size([128])\n",
      "709 0\n",
      "backbone.C3_p3.m.0.conv1.bn.running_mean \t torch.Size([128])\n",
      "709 0\n",
      "backbone.C3_p3.m.0.conv1.bn.running_var \t torch.Size([128])\n",
      "709 0\n",
      "backbone.C3_p3.m.0.conv1.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backbone.C3_p3.m.0.conv2.conv.weight \t torch.Size([128, 128, 3, 3])\n",
      "709 0\n",
      "backbone.C3_p3.m.0.conv2.bn.weight \t torch.Size([128])\n",
      "709 0\n",
      "backbone.C3_p3.m.0.conv2.bn.bias \t torch.Size([128])\n",
      "709 0\n",
      "backbone.C3_p3.m.0.conv2.bn.running_mean \t torch.Size([128])\n",
      "709 0\n",
      "backbone.C3_p3.m.0.conv2.bn.running_var \t torch.Size([128])\n",
      "709 0\n",
      "backbone.C3_p3.m.0.conv2.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "backbone.C3_p3.m.1.conv1.conv.weight \t torch.Size([128, 128, 1, 1])\n",
      "709 0\n",
      "backbone.C3_p3.m.1.conv1.bn.weight \t torch.Size([128])\n",
      "709 0\n",
      "backbone.C3_p3.m.1.conv1.bn.bias \t torch.Size([128])\n",
      "709 0\n",
      "backbone.C3_p3.m.1.conv1.bn.running_mean \t torch.Size([128])\n",
      "709 0\n",
      "backbone.C3_p3.m.1.conv1.bn.running_var \t torch.Size([128])\n",
      "709 0\n",
      "backbone.C3_p3.m.1.conv1.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "backbone.C3_p3.m.1.conv2.conv.weight \t torch.Size([128, 128, 3, 3])\n",
      "709 0\n",
      "backbone.C3_p3.m.1.conv2.bn.weight \t torch.Size([128])\n",
      "709 0\n",
      "backbone.C3_p3.m.1.conv2.bn.bias \t torch.Size([128])\n",
      "709 0\n",
      "backbone.C3_p3.m.1.conv2.bn.running_mean \t torch.Size([128])\n",
      "709 0\n",
      "backbone.C3_p3.m.1.conv2.bn.running_var \t torch.Size([128])\n",
      "709 0\n",
      "backbone.C3_p3.m.1.conv2.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "backbone.C3_p3.m.2.conv1.conv.weight \t torch.Size([128, 128, 1, 1])\n",
      "709 0\n",
      "backbone.C3_p3.m.2.conv1.bn.weight \t torch.Size([128])\n",
      "709 0\n",
      "backbone.C3_p3.m.2.conv1.bn.bias \t torch.Size([128])\n",
      "709 0\n",
      "backbone.C3_p3.m.2.conv1.bn.running_mean \t torch.Size([128])\n",
      "709 0\n",
      "backbone.C3_p3.m.2.conv1.bn.running_var \t torch.Size([128])\n",
      "709 0\n",
      "backbone.C3_p3.m.2.conv1.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "backbone.C3_p3.m.2.conv2.conv.weight \t torch.Size([128, 128, 3, 3])\n",
      "709 0\n",
      "backbone.C3_p3.m.2.conv2.bn.weight \t torch.Size([128])\n",
      "709 0\n",
      "backbone.C3_p3.m.2.conv2.bn.bias \t torch.Size([128])\n",
      "709 0\n",
      "backbone.C3_p3.m.2.conv2.bn.running_mean \t torch.Size([128])\n",
      "709 0\n",
      "backbone.C3_p3.m.2.conv2.bn.running_var \t torch.Size([128])\n",
      "709 0\n",
      "backbone.C3_p3.m.2.conv2.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "backbone.bu_conv2.conv.weight \t torch.Size([256, 256, 3, 3])\n",
      "709 0\n",
      "backbone.bu_conv2.bn.weight \t torch.Size([256])\n",
      "709 0\n",
      "backbone.bu_conv2.bn.bias \t torch.Size([256])\n",
      "709 0\n",
      "backbone.bu_conv2.bn.running_mean \t torch.Size([256])\n",
      "709 0\n",
      "backbone.bu_conv2.bn.running_var \t torch.Size([256])\n",
      "709 0\n",
      "backbone.bu_conv2.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "backbone.C3_n3.conv1.conv.weight \t torch.Size([256, 512, 1, 1])\n",
      "709 0\n",
      "backbone.C3_n3.conv1.bn.weight \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_n3.conv1.bn.bias \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_n3.conv1.bn.running_mean \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_n3.conv1.bn.running_var \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_n3.conv1.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "backbone.C3_n3.conv2.conv.weight \t torch.Size([256, 512, 1, 1])\n",
      "709 0\n",
      "backbone.C3_n3.conv2.bn.weight \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_n3.conv2.bn.bias \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_n3.conv2.bn.running_mean \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_n3.conv2.bn.running_var \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_n3.conv2.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "backbone.C3_n3.conv3.conv.weight \t torch.Size([512, 512, 1, 1])\n",
      "709 0\n",
      "backbone.C3_n3.conv3.bn.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.C3_n3.conv3.bn.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.C3_n3.conv3.bn.running_mean \t torch.Size([512])\n",
      "709 0\n",
      "backbone.C3_n3.conv3.bn.running_var \t torch.Size([512])\n",
      "709 0\n",
      "backbone.C3_n3.conv3.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "backbone.C3_n3.m.0.conv1.conv.weight \t torch.Size([256, 256, 1, 1])\n",
      "709 0\n",
      "backbone.C3_n3.m.0.conv1.bn.weight \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_n3.m.0.conv1.bn.bias \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_n3.m.0.conv1.bn.running_mean \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_n3.m.0.conv1.bn.running_var \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_n3.m.0.conv1.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "backbone.C3_n3.m.0.conv2.conv.weight \t torch.Size([256, 256, 3, 3])\n",
      "709 0\n",
      "backbone.C3_n3.m.0.conv2.bn.weight \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_n3.m.0.conv2.bn.bias \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_n3.m.0.conv2.bn.running_mean \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_n3.m.0.conv2.bn.running_var \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_n3.m.0.conv2.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "backbone.C3_n3.m.1.conv1.conv.weight \t torch.Size([256, 256, 1, 1])\n",
      "709 0\n",
      "backbone.C3_n3.m.1.conv1.bn.weight \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_n3.m.1.conv1.bn.bias \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_n3.m.1.conv1.bn.running_mean \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_n3.m.1.conv1.bn.running_var \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_n3.m.1.conv1.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "backbone.C3_n3.m.1.conv2.conv.weight \t torch.Size([256, 256, 3, 3])\n",
      "709 0\n",
      "backbone.C3_n3.m.1.conv2.bn.weight \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_n3.m.1.conv2.bn.bias \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_n3.m.1.conv2.bn.running_mean \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_n3.m.1.conv2.bn.running_var \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_n3.m.1.conv2.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "backbone.C3_n3.m.2.conv1.conv.weight \t torch.Size([256, 256, 1, 1])\n",
      "709 0\n",
      "backbone.C3_n3.m.2.conv1.bn.weight \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_n3.m.2.conv1.bn.bias \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_n3.m.2.conv1.bn.running_mean \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_n3.m.2.conv1.bn.running_var \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_n3.m.2.conv1.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "backbone.C3_n3.m.2.conv2.conv.weight \t torch.Size([256, 256, 3, 3])\n",
      "709 0\n",
      "backbone.C3_n3.m.2.conv2.bn.weight \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_n3.m.2.conv2.bn.bias \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_n3.m.2.conv2.bn.running_mean \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_n3.m.2.conv2.bn.running_var \t torch.Size([256])\n",
      "709 0\n",
      "backbone.C3_n3.m.2.conv2.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "backbone.bu_conv1.conv.weight \t torch.Size([512, 512, 3, 3])\n",
      "709 0\n",
      "backbone.bu_conv1.bn.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.bu_conv1.bn.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.bu_conv1.bn.running_mean \t torch.Size([512])\n",
      "709 0\n",
      "backbone.bu_conv1.bn.running_var \t torch.Size([512])\n",
      "709 0\n",
      "backbone.bu_conv1.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "backbone.C3_n4.conv1.conv.weight \t torch.Size([512, 1024, 1, 1])\n",
      "709 0\n",
      "backbone.C3_n4.conv1.bn.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.C3_n4.conv1.bn.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.C3_n4.conv1.bn.running_mean \t torch.Size([512])\n",
      "709 0\n",
      "backbone.C3_n4.conv1.bn.running_var \t torch.Size([512])\n",
      "709 0\n",
      "backbone.C3_n4.conv1.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "backbone.C3_n4.conv2.conv.weight \t torch.Size([512, 1024, 1, 1])\n",
      "709 0\n",
      "backbone.C3_n4.conv2.bn.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.C3_n4.conv2.bn.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.C3_n4.conv2.bn.running_mean \t torch.Size([512])\n",
      "709 0\n",
      "backbone.C3_n4.conv2.bn.running_var \t torch.Size([512])\n",
      "709 0\n",
      "backbone.C3_n4.conv2.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "backbone.C3_n4.conv3.conv.weight \t torch.Size([1024, 1024, 1, 1])\n",
      "709 0\n",
      "backbone.C3_n4.conv3.bn.weight \t torch.Size([1024])\n",
      "709 0\n",
      "backbone.C3_n4.conv3.bn.bias \t torch.Size([1024])\n",
      "709 0\n",
      "backbone.C3_n4.conv3.bn.running_mean \t torch.Size([1024])\n",
      "709 0\n",
      "backbone.C3_n4.conv3.bn.running_var \t torch.Size([1024])\n",
      "709 0\n",
      "backbone.C3_n4.conv3.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "backbone.C3_n4.m.0.conv1.conv.weight \t torch.Size([512, 512, 1, 1])\n",
      "709 0\n",
      "backbone.C3_n4.m.0.conv1.bn.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.C3_n4.m.0.conv1.bn.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.C3_n4.m.0.conv1.bn.running_mean \t torch.Size([512])\n",
      "709 0\n",
      "backbone.C3_n4.m.0.conv1.bn.running_var \t torch.Size([512])\n",
      "709 0\n",
      "backbone.C3_n4.m.0.conv1.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "backbone.C3_n4.m.0.conv2.conv.weight \t torch.Size([512, 512, 3, 3])\n",
      "709 0\n",
      "backbone.C3_n4.m.0.conv2.bn.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.C3_n4.m.0.conv2.bn.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.C3_n4.m.0.conv2.bn.running_mean \t torch.Size([512])\n",
      "709 0\n",
      "backbone.C3_n4.m.0.conv2.bn.running_var \t torch.Size([512])\n",
      "709 0\n",
      "backbone.C3_n4.m.0.conv2.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "backbone.C3_n4.m.1.conv1.conv.weight \t torch.Size([512, 512, 1, 1])\n",
      "709 0\n",
      "backbone.C3_n4.m.1.conv1.bn.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.C3_n4.m.1.conv1.bn.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.C3_n4.m.1.conv1.bn.running_mean \t torch.Size([512])\n",
      "709 0\n",
      "backbone.C3_n4.m.1.conv1.bn.running_var \t torch.Size([512])\n",
      "709 0\n",
      "backbone.C3_n4.m.1.conv1.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "backbone.C3_n4.m.1.conv2.conv.weight \t torch.Size([512, 512, 3, 3])\n",
      "709 0\n",
      "backbone.C3_n4.m.1.conv2.bn.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.C3_n4.m.1.conv2.bn.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.C3_n4.m.1.conv2.bn.running_mean \t torch.Size([512])\n",
      "709 0\n",
      "backbone.C3_n4.m.1.conv2.bn.running_var \t torch.Size([512])\n",
      "709 0\n",
      "backbone.C3_n4.m.1.conv2.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "backbone.C3_n4.m.2.conv1.conv.weight \t torch.Size([512, 512, 1, 1])\n",
      "709 0\n",
      "backbone.C3_n4.m.2.conv1.bn.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.C3_n4.m.2.conv1.bn.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.C3_n4.m.2.conv1.bn.running_mean \t torch.Size([512])\n",
      "709 0\n",
      "backbone.C3_n4.m.2.conv1.bn.running_var \t torch.Size([512])\n",
      "709 0\n",
      "backbone.C3_n4.m.2.conv1.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "backbone.C3_n4.m.2.conv2.conv.weight \t torch.Size([512, 512, 3, 3])\n",
      "709 0\n",
      "backbone.C3_n4.m.2.conv2.bn.weight \t torch.Size([512])\n",
      "709 0\n",
      "backbone.C3_n4.m.2.conv2.bn.bias \t torch.Size([512])\n",
      "709 0\n",
      "backbone.C3_n4.m.2.conv2.bn.running_mean \t torch.Size([512])\n",
      "709 0\n",
      "backbone.C3_n4.m.2.conv2.bn.running_var \t torch.Size([512])\n",
      "709 0\n",
      "backbone.C3_n4.m.2.conv2.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "head.cls_convs.0.0.conv.weight \t torch.Size([256, 256, 3, 3])\n",
      "709 0\n",
      "head.cls_convs.0.0.bn.weight \t torch.Size([256])\n",
      "709 0\n",
      "head.cls_convs.0.0.bn.bias \t torch.Size([256])\n",
      "709 0\n",
      "head.cls_convs.0.0.bn.running_mean \t torch.Size([256])\n",
      "709 0\n",
      "head.cls_convs.0.0.bn.running_var \t torch.Size([256])\n",
      "709 0\n",
      "head.cls_convs.0.0.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "head.cls_convs.0.1.conv.weight \t torch.Size([256, 256, 3, 3])\n",
      "709 0\n",
      "head.cls_convs.0.1.bn.weight \t torch.Size([256])\n",
      "709 0\n",
      "head.cls_convs.0.1.bn.bias \t torch.Size([256])\n",
      "709 0\n",
      "head.cls_convs.0.1.bn.running_mean \t torch.Size([256])\n",
      "709 0\n",
      "head.cls_convs.0.1.bn.running_var \t torch.Size([256])\n",
      "709 0\n",
      "head.cls_convs.0.1.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "head.cls_convs.1.0.conv.weight \t torch.Size([256, 256, 3, 3])\n",
      "709 0\n",
      "head.cls_convs.1.0.bn.weight \t torch.Size([256])\n",
      "709 0\n",
      "head.cls_convs.1.0.bn.bias \t torch.Size([256])\n",
      "709 0\n",
      "head.cls_convs.1.0.bn.running_mean \t torch.Size([256])\n",
      "709 0\n",
      "head.cls_convs.1.0.bn.running_var \t torch.Size([256])\n",
      "709 0\n",
      "head.cls_convs.1.0.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "head.cls_convs.1.1.conv.weight \t torch.Size([256, 256, 3, 3])\n",
      "709 0\n",
      "head.cls_convs.1.1.bn.weight \t torch.Size([256])\n",
      "709 0\n",
      "head.cls_convs.1.1.bn.bias \t torch.Size([256])\n",
      "709 0\n",
      "head.cls_convs.1.1.bn.running_mean \t torch.Size([256])\n",
      "709 0\n",
      "head.cls_convs.1.1.bn.running_var \t torch.Size([256])\n",
      "709 0\n",
      "head.cls_convs.1.1.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "head.cls_convs.2.0.conv.weight \t torch.Size([256, 256, 3, 3])\n",
      "709 0\n",
      "head.cls_convs.2.0.bn.weight \t torch.Size([256])\n",
      "709 0\n",
      "head.cls_convs.2.0.bn.bias \t torch.Size([256])\n",
      "709 0\n",
      "head.cls_convs.2.0.bn.running_mean \t torch.Size([256])\n",
      "709 0\n",
      "head.cls_convs.2.0.bn.running_var \t torch.Size([256])\n",
      "709 0\n",
      "head.cls_convs.2.0.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "head.cls_convs.2.1.conv.weight \t torch.Size([256, 256, 3, 3])\n",
      "709 0\n",
      "head.cls_convs.2.1.bn.weight \t torch.Size([256])\n",
      "709 0\n",
      "head.cls_convs.2.1.bn.bias \t torch.Size([256])\n",
      "709 0\n",
      "head.cls_convs.2.1.bn.running_mean \t torch.Size([256])\n",
      "709 0\n",
      "head.cls_convs.2.1.bn.running_var \t torch.Size([256])\n",
      "709 0\n",
      "head.cls_convs.2.1.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "head.reg_convs.0.0.conv.weight \t torch.Size([256, 256, 3, 3])\n",
      "709 0\n",
      "head.reg_convs.0.0.bn.weight \t torch.Size([256])\n",
      "709 0\n",
      "head.reg_convs.0.0.bn.bias \t torch.Size([256])\n",
      "709 0\n",
      "head.reg_convs.0.0.bn.running_mean \t torch.Size([256])\n",
      "709 0\n",
      "head.reg_convs.0.0.bn.running_var \t torch.Size([256])\n",
      "709 0\n",
      "head.reg_convs.0.0.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "head.reg_convs.0.1.conv.weight \t torch.Size([256, 256, 3, 3])\n",
      "709 0\n",
      "head.reg_convs.0.1.bn.weight \t torch.Size([256])\n",
      "709 0\n",
      "head.reg_convs.0.1.bn.bias \t torch.Size([256])\n",
      "709 0\n",
      "head.reg_convs.0.1.bn.running_mean \t torch.Size([256])\n",
      "709 0\n",
      "head.reg_convs.0.1.bn.running_var \t torch.Size([256])\n",
      "709 0\n",
      "head.reg_convs.0.1.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "head.reg_convs.1.0.conv.weight \t torch.Size([256, 256, 3, 3])\n",
      "709 0\n",
      "head.reg_convs.1.0.bn.weight \t torch.Size([256])\n",
      "709 0\n",
      "head.reg_convs.1.0.bn.bias \t torch.Size([256])\n",
      "709 0\n",
      "head.reg_convs.1.0.bn.running_mean \t torch.Size([256])\n",
      "709 0\n",
      "head.reg_convs.1.0.bn.running_var \t torch.Size([256])\n",
      "709 0\n",
      "head.reg_convs.1.0.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "head.reg_convs.1.1.conv.weight \t torch.Size([256, 256, 3, 3])\n",
      "709 0\n",
      "head.reg_convs.1.1.bn.weight \t torch.Size([256])\n",
      "709 0\n",
      "head.reg_convs.1.1.bn.bias \t torch.Size([256])\n",
      "709 0\n",
      "head.reg_convs.1.1.bn.running_mean \t torch.Size([256])\n",
      "709 0\n",
      "head.reg_convs.1.1.bn.running_var \t torch.Size([256])\n",
      "709 0\n",
      "head.reg_convs.1.1.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "head.reg_convs.2.0.conv.weight \t torch.Size([256, 256, 3, 3])\n",
      "709 0\n",
      "head.reg_convs.2.0.bn.weight \t torch.Size([256])\n",
      "709 0\n",
      "head.reg_convs.2.0.bn.bias \t torch.Size([256])\n",
      "709 0\n",
      "head.reg_convs.2.0.bn.running_mean \t torch.Size([256])\n",
      "709 0\n",
      "head.reg_convs.2.0.bn.running_var \t torch.Size([256])\n",
      "709 0\n",
      "head.reg_convs.2.0.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "head.reg_convs.2.1.conv.weight \t torch.Size([256, 256, 3, 3])\n",
      "709 0\n",
      "head.reg_convs.2.1.bn.weight \t torch.Size([256])\n",
      "709 0\n",
      "head.reg_convs.2.1.bn.bias \t torch.Size([256])\n",
      "709 0\n",
      "head.reg_convs.2.1.bn.running_mean \t torch.Size([256])\n",
      "709 0\n",
      "head.reg_convs.2.1.bn.running_var \t torch.Size([256])\n",
      "709 0\n",
      "head.reg_convs.2.1.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "head.cls_preds.0.weight \t torch.Size([80, 256, 1, 1])\n",
      "709 0\n",
      "head.cls_preds.0.bias \t torch.Size([80])\n",
      "709 0\n",
      "head.cls_preds.1.weight \t torch.Size([80, 256, 1, 1])\n",
      "709 0\n",
      "head.cls_preds.1.bias \t torch.Size([80])\n",
      "709 0\n",
      "head.cls_preds.2.weight \t torch.Size([80, 256, 1, 1])\n",
      "709 0\n",
      "head.cls_preds.2.bias \t torch.Size([80])\n",
      "709 0\n",
      "head.reg_preds.0.weight \t torch.Size([4, 256, 1, 1])\n",
      "709 0\n",
      "head.reg_preds.0.bias \t torch.Size([4])\n",
      "709 0\n",
      "head.reg_preds.1.weight \t torch.Size([4, 256, 1, 1])\n",
      "709 0\n",
      "head.reg_preds.1.bias \t torch.Size([4])\n",
      "709 0\n",
      "head.reg_preds.2.weight \t torch.Size([4, 256, 1, 1])\n",
      "709 0\n",
      "head.reg_preds.2.bias \t torch.Size([4])\n",
      "709 0\n",
      "head.obj_preds.0.weight \t torch.Size([1, 256, 1, 1])\n",
      "709 0\n",
      "head.obj_preds.0.bias \t torch.Size([1])\n",
      "709 0\n",
      "head.obj_preds.1.weight \t torch.Size([1, 256, 1, 1])\n",
      "709 0\n",
      "head.obj_preds.1.bias \t torch.Size([1])\n",
      "709 0\n",
      "head.obj_preds.2.weight \t torch.Size([1, 256, 1, 1])\n",
      "709 0\n",
      "head.obj_preds.2.bias \t torch.Size([1])\n",
      "709 0\n",
      "head.stems.0.conv.weight \t torch.Size([256, 256, 1, 1])\n",
      "709 0\n",
      "head.stems.0.bn.weight \t torch.Size([256])\n",
      "709 0\n",
      "head.stems.0.bn.bias \t torch.Size([256])\n",
      "709 0\n",
      "head.stems.0.bn.running_mean \t torch.Size([256])\n",
      "709 0\n",
      "head.stems.0.bn.running_var \t torch.Size([256])\n",
      "709 0\n",
      "head.stems.0.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "head.stems.1.conv.weight \t torch.Size([256, 512, 1, 1])\n",
      "709 0\n",
      "head.stems.1.bn.weight \t torch.Size([256])\n",
      "709 0\n",
      "head.stems.1.bn.bias \t torch.Size([256])\n",
      "709 0\n",
      "head.stems.1.bn.running_mean \t torch.Size([256])\n",
      "709 0\n",
      "head.stems.1.bn.running_var \t torch.Size([256])\n",
      "709 0\n",
      "head.stems.1.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n",
      "head.stems.2.conv.weight \t torch.Size([256, 1024, 1, 1])\n",
      "709 0\n",
      "head.stems.2.bn.weight \t torch.Size([256])\n",
      "709 0\n",
      "head.stems.2.bn.bias \t torch.Size([256])\n",
      "709 0\n",
      "head.stems.2.bn.running_mean \t torch.Size([256])\n",
      "709 0\n",
      "head.stems.2.bn.running_var \t torch.Size([256])\n",
      "709 0\n",
      "head.stems.2.bn.num_batches_tracked \t torch.Size([])\n",
      "709 0\n"
     ]
    }
   ],
   "source": [
    "model = YoloBody(num_classes=80, phi=\"l\")\n",
    "weight = model.state_dict()\n",
    "i = 0\n",
    "for param_tensor in weight: # 字典的遍历默认是遍历 key，所以param_tensor实际上是键值\n",
    "    print(param_tensor,'\\t',weight[param_tensor].size())\n",
    "    print(len(weight), i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0289194d",
   "metadata": {},
   "source": [
    "## 原来YOLOX=750\n",
    "## backbone=642,head = 108\n",
    "## backbone.backbone = 402(CSPDarknet)\n",
    "## bu_conv2=6,bu_conv1=6, lateral=6, reduce_conv=6, c3=216   记为other：240\n",
    "## backbone.backnone分别是stem， dark2， dark3， dark4， dark5.\n",
    "## spp在dark5中，占12个,为backbone.backbone.dark5.1. 。。。。\n",
    "## 我们需要的是 other(240) + head(108) + spp(12) = 360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f4fbfdf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T13:18:29.493780Z",
     "start_time": "2021-11-26T13:18:29.182615Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backbone.backbone.stem.conv.conv.weight     torch.Size([64, 12, 3, 3])\n",
      "750\n",
      "backbone.backbone.stem.conv.bn.weight     torch.Size([64])\n",
      "750\n",
      "backbone.backbone.stem.conv.bn.bias     torch.Size([64])\n",
      "750\n",
      "backbone.backbone.stem.conv.bn.running_mean     torch.Size([64])\n",
      "750\n",
      "backbone.backbone.stem.conv.bn.running_var     torch.Size([64])\n",
      "750\n",
      "backbone.backbone.stem.conv.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark2.0.conv.weight     torch.Size([128, 64, 3, 3])\n",
      "750\n",
      "backbone.backbone.dark2.0.bn.weight     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark2.0.bn.bias     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark2.0.bn.running_mean     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark2.0.bn.running_var     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark2.0.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark2.1.conv1.conv.weight     torch.Size([64, 128, 1, 1])\n",
      "750\n",
      "backbone.backbone.dark2.1.conv1.bn.weight     torch.Size([64])\n",
      "750\n",
      "backbone.backbone.dark2.1.conv1.bn.bias     torch.Size([64])\n",
      "750\n",
      "backbone.backbone.dark2.1.conv1.bn.running_mean     torch.Size([64])\n",
      "750\n",
      "backbone.backbone.dark2.1.conv1.bn.running_var     torch.Size([64])\n",
      "750\n",
      "backbone.backbone.dark2.1.conv1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark2.1.conv2.conv.weight     torch.Size([64, 128, 1, 1])\n",
      "750\n",
      "backbone.backbone.dark2.1.conv2.bn.weight     torch.Size([64])\n",
      "750\n",
      "backbone.backbone.dark2.1.conv2.bn.bias     torch.Size([64])\n",
      "750\n",
      "backbone.backbone.dark2.1.conv2.bn.running_mean     torch.Size([64])\n",
      "750\n",
      "backbone.backbone.dark2.1.conv2.bn.running_var     torch.Size([64])\n",
      "750\n",
      "backbone.backbone.dark2.1.conv2.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark2.1.conv3.conv.weight     torch.Size([128, 128, 1, 1])\n",
      "750\n",
      "backbone.backbone.dark2.1.conv3.bn.weight     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark2.1.conv3.bn.bias     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark2.1.conv3.bn.running_mean     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark2.1.conv3.bn.running_var     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark2.1.conv3.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark2.1.m.0.conv1.conv.weight     torch.Size([64, 64, 1, 1])\n",
      "750\n",
      "backbone.backbone.dark2.1.m.0.conv1.bn.weight     torch.Size([64])\n",
      "750\n",
      "backbone.backbone.dark2.1.m.0.conv1.bn.bias     torch.Size([64])\n",
      "750\n",
      "backbone.backbone.dark2.1.m.0.conv1.bn.running_mean     torch.Size([64])\n",
      "750\n",
      "backbone.backbone.dark2.1.m.0.conv1.bn.running_var     torch.Size([64])\n",
      "750\n",
      "backbone.backbone.dark2.1.m.0.conv1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark2.1.m.0.conv2.conv.weight     torch.Size([64, 64, 3, 3])\n",
      "750\n",
      "backbone.backbone.dark2.1.m.0.conv2.bn.weight     torch.Size([64])\n",
      "750\n",
      "backbone.backbone.dark2.1.m.0.conv2.bn.bias     torch.Size([64])\n",
      "750\n",
      "backbone.backbone.dark2.1.m.0.conv2.bn.running_mean     torch.Size([64])\n",
      "750\n",
      "backbone.backbone.dark2.1.m.0.conv2.bn.running_var     torch.Size([64])\n",
      "750\n",
      "backbone.backbone.dark2.1.m.0.conv2.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark2.1.m.1.conv1.conv.weight     torch.Size([64, 64, 1, 1])\n",
      "750\n",
      "backbone.backbone.dark2.1.m.1.conv1.bn.weight     torch.Size([64])\n",
      "750\n",
      "backbone.backbone.dark2.1.m.1.conv1.bn.bias     torch.Size([64])\n",
      "750\n",
      "backbone.backbone.dark2.1.m.1.conv1.bn.running_mean     torch.Size([64])\n",
      "750\n",
      "backbone.backbone.dark2.1.m.1.conv1.bn.running_var     torch.Size([64])\n",
      "750\n",
      "backbone.backbone.dark2.1.m.1.conv1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark2.1.m.1.conv2.conv.weight     torch.Size([64, 64, 3, 3])\n",
      "750\n",
      "backbone.backbone.dark2.1.m.1.conv2.bn.weight     torch.Size([64])\n",
      "750\n",
      "backbone.backbone.dark2.1.m.1.conv2.bn.bias     torch.Size([64])\n",
      "750\n",
      "backbone.backbone.dark2.1.m.1.conv2.bn.running_mean     torch.Size([64])\n",
      "750\n",
      "backbone.backbone.dark2.1.m.1.conv2.bn.running_var     torch.Size([64])\n",
      "750\n",
      "backbone.backbone.dark2.1.m.1.conv2.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark2.1.m.2.conv1.conv.weight     torch.Size([64, 64, 1, 1])\n",
      "750\n",
      "backbone.backbone.dark2.1.m.2.conv1.bn.weight     torch.Size([64])\n",
      "750\n",
      "backbone.backbone.dark2.1.m.2.conv1.bn.bias     torch.Size([64])\n",
      "750\n",
      "backbone.backbone.dark2.1.m.2.conv1.bn.running_mean     torch.Size([64])\n",
      "750\n",
      "backbone.backbone.dark2.1.m.2.conv1.bn.running_var     torch.Size([64])\n",
      "750\n",
      "backbone.backbone.dark2.1.m.2.conv1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark2.1.m.2.conv2.conv.weight     torch.Size([64, 64, 3, 3])\n",
      "750\n",
      "backbone.backbone.dark2.1.m.2.conv2.bn.weight     torch.Size([64])\n",
      "750\n",
      "backbone.backbone.dark2.1.m.2.conv2.bn.bias     torch.Size([64])\n",
      "750\n",
      "backbone.backbone.dark2.1.m.2.conv2.bn.running_mean     torch.Size([64])\n",
      "750\n",
      "backbone.backbone.dark2.1.m.2.conv2.bn.running_var     torch.Size([64])\n",
      "750\n",
      "backbone.backbone.dark2.1.m.2.conv2.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark3.0.conv.weight     torch.Size([256, 128, 3, 3])\n",
      "750\n",
      "backbone.backbone.dark3.0.bn.weight     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark3.0.bn.bias     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark3.0.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark3.0.bn.running_var     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark3.0.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark3.1.conv1.conv.weight     torch.Size([128, 256, 1, 1])\n",
      "750\n",
      "backbone.backbone.dark3.1.conv1.bn.weight     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.conv1.bn.bias     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.conv1.bn.running_mean     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.conv1.bn.running_var     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.conv1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark3.1.conv2.conv.weight     torch.Size([128, 256, 1, 1])\n",
      "750\n",
      "backbone.backbone.dark3.1.conv2.bn.weight     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.conv2.bn.bias     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.conv2.bn.running_mean     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.conv2.bn.running_var     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.conv2.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark3.1.conv3.conv.weight     torch.Size([256, 256, 1, 1])\n",
      "750\n",
      "backbone.backbone.dark3.1.conv3.bn.weight     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark3.1.conv3.bn.bias     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark3.1.conv3.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark3.1.conv3.bn.running_var     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark3.1.conv3.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.0.conv1.conv.weight     torch.Size([128, 128, 1, 1])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.0.conv1.bn.weight     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.0.conv1.bn.bias     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.0.conv1.bn.running_mean     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.0.conv1.bn.running_var     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.0.conv1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.0.conv2.conv.weight     torch.Size([128, 128, 3, 3])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.0.conv2.bn.weight     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.0.conv2.bn.bias     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.0.conv2.bn.running_mean     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.0.conv2.bn.running_var     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.0.conv2.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.1.conv1.conv.weight     torch.Size([128, 128, 1, 1])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.1.conv1.bn.weight     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.1.conv1.bn.bias     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.1.conv1.bn.running_mean     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.1.conv1.bn.running_var     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.1.conv1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.1.conv2.conv.weight     torch.Size([128, 128, 3, 3])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.1.conv2.bn.weight     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.1.conv2.bn.bias     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.1.conv2.bn.running_mean     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.1.conv2.bn.running_var     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.1.conv2.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.2.conv1.conv.weight     torch.Size([128, 128, 1, 1])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.2.conv1.bn.weight     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.2.conv1.bn.bias     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.2.conv1.bn.running_mean     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.2.conv1.bn.running_var     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.2.conv1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.2.conv2.conv.weight     torch.Size([128, 128, 3, 3])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.2.conv2.bn.weight     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.2.conv2.bn.bias     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.2.conv2.bn.running_mean     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.2.conv2.bn.running_var     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.2.conv2.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.3.conv1.conv.weight     torch.Size([128, 128, 1, 1])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.3.conv1.bn.weight     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.3.conv1.bn.bias     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.3.conv1.bn.running_mean     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.3.conv1.bn.running_var     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.3.conv1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.3.conv2.conv.weight     torch.Size([128, 128, 3, 3])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.3.conv2.bn.weight     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.3.conv2.bn.bias     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.3.conv2.bn.running_mean     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.3.conv2.bn.running_var     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.3.conv2.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.4.conv1.conv.weight     torch.Size([128, 128, 1, 1])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.4.conv1.bn.weight     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.4.conv1.bn.bias     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.4.conv1.bn.running_mean     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.4.conv1.bn.running_var     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.4.conv1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.4.conv2.conv.weight     torch.Size([128, 128, 3, 3])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.4.conv2.bn.weight     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.4.conv2.bn.bias     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.4.conv2.bn.running_mean     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.4.conv2.bn.running_var     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.4.conv2.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.5.conv1.conv.weight     torch.Size([128, 128, 1, 1])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.5.conv1.bn.weight     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.5.conv1.bn.bias     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.5.conv1.bn.running_mean     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.5.conv1.bn.running_var     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.5.conv1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.5.conv2.conv.weight     torch.Size([128, 128, 3, 3])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.5.conv2.bn.weight     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.5.conv2.bn.bias     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.5.conv2.bn.running_mean     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.5.conv2.bn.running_var     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.5.conv2.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.6.conv1.conv.weight     torch.Size([128, 128, 1, 1])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.6.conv1.bn.weight     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.6.conv1.bn.bias     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.6.conv1.bn.running_mean     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.6.conv1.bn.running_var     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.6.conv1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.6.conv2.conv.weight     torch.Size([128, 128, 3, 3])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.6.conv2.bn.weight     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.6.conv2.bn.bias     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.6.conv2.bn.running_mean     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.6.conv2.bn.running_var     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.6.conv2.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.7.conv1.conv.weight     torch.Size([128, 128, 1, 1])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.7.conv1.bn.weight     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.7.conv1.bn.bias     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.7.conv1.bn.running_mean     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.7.conv1.bn.running_var     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.7.conv1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.7.conv2.conv.weight     torch.Size([128, 128, 3, 3])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.7.conv2.bn.weight     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.7.conv2.bn.bias     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.7.conv2.bn.running_mean     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.7.conv2.bn.running_var     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.7.conv2.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.8.conv1.conv.weight     torch.Size([128, 128, 1, 1])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.8.conv1.bn.weight     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.8.conv1.bn.bias     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.8.conv1.bn.running_mean     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.8.conv1.bn.running_var     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.8.conv1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.8.conv2.conv.weight     torch.Size([128, 128, 3, 3])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.8.conv2.bn.weight     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.8.conv2.bn.bias     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.8.conv2.bn.running_mean     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.8.conv2.bn.running_var     torch.Size([128])\n",
      "750\n",
      "backbone.backbone.dark3.1.m.8.conv2.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark4.0.conv.weight     torch.Size([512, 256, 3, 3])\n",
      "750\n",
      "backbone.backbone.dark4.0.bn.weight     torch.Size([512])\n",
      "750\n",
      "backbone.backbone.dark4.0.bn.bias     torch.Size([512])\n",
      "750\n",
      "backbone.backbone.dark4.0.bn.running_mean     torch.Size([512])\n",
      "750\n",
      "backbone.backbone.dark4.0.bn.running_var     torch.Size([512])\n",
      "750\n",
      "backbone.backbone.dark4.0.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark4.1.conv1.conv.weight     torch.Size([256, 512, 1, 1])\n",
      "750\n",
      "backbone.backbone.dark4.1.conv1.bn.weight     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.conv1.bn.bias     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.conv1.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.conv1.bn.running_var     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.conv1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark4.1.conv2.conv.weight     torch.Size([256, 512, 1, 1])\n",
      "750\n",
      "backbone.backbone.dark4.1.conv2.bn.weight     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.conv2.bn.bias     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.conv2.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.conv2.bn.running_var     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.conv2.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark4.1.conv3.conv.weight     torch.Size([512, 512, 1, 1])\n",
      "750\n",
      "backbone.backbone.dark4.1.conv3.bn.weight     torch.Size([512])\n",
      "750\n",
      "backbone.backbone.dark4.1.conv3.bn.bias     torch.Size([512])\n",
      "750\n",
      "backbone.backbone.dark4.1.conv3.bn.running_mean     torch.Size([512])\n",
      "750\n",
      "backbone.backbone.dark4.1.conv3.bn.running_var     torch.Size([512])\n",
      "750\n",
      "backbone.backbone.dark4.1.conv3.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.0.conv1.conv.weight     torch.Size([256, 256, 1, 1])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.0.conv1.bn.weight     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.0.conv1.bn.bias     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.0.conv1.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.0.conv1.bn.running_var     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.0.conv1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.0.conv2.conv.weight     torch.Size([256, 256, 3, 3])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.0.conv2.bn.weight     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.0.conv2.bn.bias     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.0.conv2.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.0.conv2.bn.running_var     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.0.conv2.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.1.conv1.conv.weight     torch.Size([256, 256, 1, 1])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.1.conv1.bn.weight     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.1.conv1.bn.bias     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.1.conv1.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.1.conv1.bn.running_var     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.1.conv1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.1.conv2.conv.weight     torch.Size([256, 256, 3, 3])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.1.conv2.bn.weight     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.1.conv2.bn.bias     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.1.conv2.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.1.conv2.bn.running_var     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.1.conv2.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.2.conv1.conv.weight     torch.Size([256, 256, 1, 1])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.2.conv1.bn.weight     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.2.conv1.bn.bias     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.2.conv1.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.2.conv1.bn.running_var     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.2.conv1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.2.conv2.conv.weight     torch.Size([256, 256, 3, 3])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.2.conv2.bn.weight     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.2.conv2.bn.bias     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.2.conv2.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.2.conv2.bn.running_var     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.2.conv2.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.3.conv1.conv.weight     torch.Size([256, 256, 1, 1])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.3.conv1.bn.weight     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.3.conv1.bn.bias     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.3.conv1.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.3.conv1.bn.running_var     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.3.conv1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.3.conv2.conv.weight     torch.Size([256, 256, 3, 3])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.3.conv2.bn.weight     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.3.conv2.bn.bias     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.3.conv2.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.3.conv2.bn.running_var     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.3.conv2.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.4.conv1.conv.weight     torch.Size([256, 256, 1, 1])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.4.conv1.bn.weight     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.4.conv1.bn.bias     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.4.conv1.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.4.conv1.bn.running_var     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.4.conv1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.4.conv2.conv.weight     torch.Size([256, 256, 3, 3])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.4.conv2.bn.weight     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.4.conv2.bn.bias     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.4.conv2.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.4.conv2.bn.running_var     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.4.conv2.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.5.conv1.conv.weight     torch.Size([256, 256, 1, 1])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.5.conv1.bn.weight     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.5.conv1.bn.bias     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.5.conv1.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.5.conv1.bn.running_var     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.5.conv1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.5.conv2.conv.weight     torch.Size([256, 256, 3, 3])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.5.conv2.bn.weight     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.5.conv2.bn.bias     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.5.conv2.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.5.conv2.bn.running_var     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.5.conv2.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.6.conv1.conv.weight     torch.Size([256, 256, 1, 1])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.6.conv1.bn.weight     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.6.conv1.bn.bias     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.6.conv1.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.6.conv1.bn.running_var     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.6.conv1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.6.conv2.conv.weight     torch.Size([256, 256, 3, 3])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.6.conv2.bn.weight     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.6.conv2.bn.bias     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.6.conv2.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.6.conv2.bn.running_var     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.6.conv2.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.7.conv1.conv.weight     torch.Size([256, 256, 1, 1])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.7.conv1.bn.weight     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.7.conv1.bn.bias     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.7.conv1.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.7.conv1.bn.running_var     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.7.conv1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.7.conv2.conv.weight     torch.Size([256, 256, 3, 3])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.7.conv2.bn.weight     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.7.conv2.bn.bias     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.7.conv2.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.7.conv2.bn.running_var     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.7.conv2.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.8.conv1.conv.weight     torch.Size([256, 256, 1, 1])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.8.conv1.bn.weight     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.8.conv1.bn.bias     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.8.conv1.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.8.conv1.bn.running_var     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.8.conv1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.8.conv2.conv.weight     torch.Size([256, 256, 3, 3])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.8.conv2.bn.weight     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.8.conv2.bn.bias     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.8.conv2.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.8.conv2.bn.running_var     torch.Size([256])\n",
      "750\n",
      "backbone.backbone.dark4.1.m.8.conv2.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark5.0.conv.weight     torch.Size([1024, 512, 3, 3])\n",
      "750\n",
      "backbone.backbone.dark5.0.bn.weight     torch.Size([1024])\n",
      "750\n",
      "backbone.backbone.dark5.0.bn.bias     torch.Size([1024])\n",
      "750\n",
      "backbone.backbone.dark5.0.bn.running_mean     torch.Size([1024])\n",
      "750\n",
      "backbone.backbone.dark5.0.bn.running_var     torch.Size([1024])\n",
      "750\n",
      "backbone.backbone.dark5.0.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark5.1.conv1.conv.weight     torch.Size([512, 1024, 1, 1])\n",
      "750\n",
      "backbone.backbone.dark5.1.conv1.bn.weight     torch.Size([512])\n",
      "750\n",
      "backbone.backbone.dark5.1.conv1.bn.bias     torch.Size([512])\n",
      "750\n",
      "backbone.backbone.dark5.1.conv1.bn.running_mean     torch.Size([512])\n",
      "750\n",
      "backbone.backbone.dark5.1.conv1.bn.running_var     torch.Size([512])\n",
      "750\n",
      "backbone.backbone.dark5.1.conv1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark5.1.conv2.conv.weight     torch.Size([1024, 2048, 1, 1])\n",
      "750\n",
      "backbone.backbone.dark5.1.conv2.bn.weight     torch.Size([1024])\n",
      "750\n",
      "backbone.backbone.dark5.1.conv2.bn.bias     torch.Size([1024])\n",
      "750\n",
      "backbone.backbone.dark5.1.conv2.bn.running_mean     torch.Size([1024])\n",
      "750\n",
      "backbone.backbone.dark5.1.conv2.bn.running_var     torch.Size([1024])\n",
      "750\n",
      "backbone.backbone.dark5.1.conv2.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark5.2.conv1.conv.weight     torch.Size([512, 1024, 1, 1])\n",
      "750\n",
      "backbone.backbone.dark5.2.conv1.bn.weight     torch.Size([512])\n",
      "750\n",
      "backbone.backbone.dark5.2.conv1.bn.bias     torch.Size([512])\n",
      "750\n",
      "backbone.backbone.dark5.2.conv1.bn.running_mean     torch.Size([512])\n",
      "750\n",
      "backbone.backbone.dark5.2.conv1.bn.running_var     torch.Size([512])\n",
      "750\n",
      "backbone.backbone.dark5.2.conv1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark5.2.conv2.conv.weight     torch.Size([512, 1024, 1, 1])\n",
      "750\n",
      "backbone.backbone.dark5.2.conv2.bn.weight     torch.Size([512])\n",
      "750\n",
      "backbone.backbone.dark5.2.conv2.bn.bias     torch.Size([512])\n",
      "750\n",
      "backbone.backbone.dark5.2.conv2.bn.running_mean     torch.Size([512])\n",
      "750\n",
      "backbone.backbone.dark5.2.conv2.bn.running_var     torch.Size([512])\n",
      "750\n",
      "backbone.backbone.dark5.2.conv2.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark5.2.conv3.conv.weight     torch.Size([1024, 1024, 1, 1])\n",
      "750\n",
      "backbone.backbone.dark5.2.conv3.bn.weight     torch.Size([1024])\n",
      "750\n",
      "backbone.backbone.dark5.2.conv3.bn.bias     torch.Size([1024])\n",
      "750\n",
      "backbone.backbone.dark5.2.conv3.bn.running_mean     torch.Size([1024])\n",
      "750\n",
      "backbone.backbone.dark5.2.conv3.bn.running_var     torch.Size([1024])\n",
      "750\n",
      "backbone.backbone.dark5.2.conv3.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark5.2.m.0.conv1.conv.weight     torch.Size([512, 512, 1, 1])\n",
      "750\n",
      "backbone.backbone.dark5.2.m.0.conv1.bn.weight     torch.Size([512])\n",
      "750\n",
      "backbone.backbone.dark5.2.m.0.conv1.bn.bias     torch.Size([512])\n",
      "750\n",
      "backbone.backbone.dark5.2.m.0.conv1.bn.running_mean     torch.Size([512])\n",
      "750\n",
      "backbone.backbone.dark5.2.m.0.conv1.bn.running_var     torch.Size([512])\n",
      "750\n",
      "backbone.backbone.dark5.2.m.0.conv1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark5.2.m.0.conv2.conv.weight     torch.Size([512, 512, 3, 3])\n",
      "750\n",
      "backbone.backbone.dark5.2.m.0.conv2.bn.weight     torch.Size([512])\n",
      "750\n",
      "backbone.backbone.dark5.2.m.0.conv2.bn.bias     torch.Size([512])\n",
      "750\n",
      "backbone.backbone.dark5.2.m.0.conv2.bn.running_mean     torch.Size([512])\n",
      "750\n",
      "backbone.backbone.dark5.2.m.0.conv2.bn.running_var     torch.Size([512])\n",
      "750\n",
      "backbone.backbone.dark5.2.m.0.conv2.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark5.2.m.1.conv1.conv.weight     torch.Size([512, 512, 1, 1])\n",
      "750\n",
      "backbone.backbone.dark5.2.m.1.conv1.bn.weight     torch.Size([512])\n",
      "750\n",
      "backbone.backbone.dark5.2.m.1.conv1.bn.bias     torch.Size([512])\n",
      "750\n",
      "backbone.backbone.dark5.2.m.1.conv1.bn.running_mean     torch.Size([512])\n",
      "750\n",
      "backbone.backbone.dark5.2.m.1.conv1.bn.running_var     torch.Size([512])\n",
      "750\n",
      "backbone.backbone.dark5.2.m.1.conv1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark5.2.m.1.conv2.conv.weight     torch.Size([512, 512, 3, 3])\n",
      "750\n",
      "backbone.backbone.dark5.2.m.1.conv2.bn.weight     torch.Size([512])\n",
      "750\n",
      "backbone.backbone.dark5.2.m.1.conv2.bn.bias     torch.Size([512])\n",
      "750\n",
      "backbone.backbone.dark5.2.m.1.conv2.bn.running_mean     torch.Size([512])\n",
      "750\n",
      "backbone.backbone.dark5.2.m.1.conv2.bn.running_var     torch.Size([512])\n",
      "750\n",
      "backbone.backbone.dark5.2.m.1.conv2.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark5.2.m.2.conv1.conv.weight     torch.Size([512, 512, 1, 1])\n",
      "750\n",
      "backbone.backbone.dark5.2.m.2.conv1.bn.weight     torch.Size([512])\n",
      "750\n",
      "backbone.backbone.dark5.2.m.2.conv1.bn.bias     torch.Size([512])\n",
      "750\n",
      "backbone.backbone.dark5.2.m.2.conv1.bn.running_mean     torch.Size([512])\n",
      "750\n",
      "backbone.backbone.dark5.2.m.2.conv1.bn.running_var     torch.Size([512])\n",
      "750\n",
      "backbone.backbone.dark5.2.m.2.conv1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.backbone.dark5.2.m.2.conv2.conv.weight     torch.Size([512, 512, 3, 3])\n",
      "750\n",
      "backbone.backbone.dark5.2.m.2.conv2.bn.weight     torch.Size([512])\n",
      "750\n",
      "backbone.backbone.dark5.2.m.2.conv2.bn.bias     torch.Size([512])\n",
      "750\n",
      "backbone.backbone.dark5.2.m.2.conv2.bn.running_mean     torch.Size([512])\n",
      "750\n",
      "backbone.backbone.dark5.2.m.2.conv2.bn.running_var     torch.Size([512])\n",
      "750\n",
      "backbone.backbone.dark5.2.m.2.conv2.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.lateral_conv0.conv.weight     torch.Size([512, 1024, 1, 1])\n",
      "750\n",
      "backbone.lateral_conv0.bn.weight     torch.Size([512])\n",
      "750\n",
      "backbone.lateral_conv0.bn.bias     torch.Size([512])\n",
      "750\n",
      "backbone.lateral_conv0.bn.running_mean     torch.Size([512])\n",
      "750\n",
      "backbone.lateral_conv0.bn.running_var     torch.Size([512])\n",
      "750\n",
      "backbone.lateral_conv0.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.C3_p4.conv1.conv.weight     torch.Size([256, 1024, 1, 1])\n",
      "750\n",
      "backbone.C3_p4.conv1.bn.weight     torch.Size([256])\n",
      "750\n",
      "backbone.C3_p4.conv1.bn.bias     torch.Size([256])\n",
      "750\n",
      "backbone.C3_p4.conv1.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "backbone.C3_p4.conv1.bn.running_var     torch.Size([256])\n",
      "750\n",
      "backbone.C3_p4.conv1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.C3_p4.conv2.conv.weight     torch.Size([256, 1024, 1, 1])\n",
      "750\n",
      "backbone.C3_p4.conv2.bn.weight     torch.Size([256])\n",
      "750\n",
      "backbone.C3_p4.conv2.bn.bias     torch.Size([256])\n",
      "750\n",
      "backbone.C3_p4.conv2.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "backbone.C3_p4.conv2.bn.running_var     torch.Size([256])\n",
      "750\n",
      "backbone.C3_p4.conv2.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.C3_p4.conv3.conv.weight     torch.Size([512, 512, 1, 1])\n",
      "750\n",
      "backbone.C3_p4.conv3.bn.weight     torch.Size([512])\n",
      "750\n",
      "backbone.C3_p4.conv3.bn.bias     torch.Size([512])\n",
      "750\n",
      "backbone.C3_p4.conv3.bn.running_mean     torch.Size([512])\n",
      "750\n",
      "backbone.C3_p4.conv3.bn.running_var     torch.Size([512])\n",
      "750\n",
      "backbone.C3_p4.conv3.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.C3_p4.m.0.conv1.conv.weight     torch.Size([256, 256, 1, 1])\n",
      "750\n",
      "backbone.C3_p4.m.0.conv1.bn.weight     torch.Size([256])\n",
      "750\n",
      "backbone.C3_p4.m.0.conv1.bn.bias     torch.Size([256])\n",
      "750\n",
      "backbone.C3_p4.m.0.conv1.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "backbone.C3_p4.m.0.conv1.bn.running_var     torch.Size([256])\n",
      "750\n",
      "backbone.C3_p4.m.0.conv1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.C3_p4.m.0.conv2.conv.weight     torch.Size([256, 256, 3, 3])\n",
      "750\n",
      "backbone.C3_p4.m.0.conv2.bn.weight     torch.Size([256])\n",
      "750\n",
      "backbone.C3_p4.m.0.conv2.bn.bias     torch.Size([256])\n",
      "750\n",
      "backbone.C3_p4.m.0.conv2.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "backbone.C3_p4.m.0.conv2.bn.running_var     torch.Size([256])\n",
      "750\n",
      "backbone.C3_p4.m.0.conv2.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.C3_p4.m.1.conv1.conv.weight     torch.Size([256, 256, 1, 1])\n",
      "750\n",
      "backbone.C3_p4.m.1.conv1.bn.weight     torch.Size([256])\n",
      "750\n",
      "backbone.C3_p4.m.1.conv1.bn.bias     torch.Size([256])\n",
      "750\n",
      "backbone.C3_p4.m.1.conv1.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "backbone.C3_p4.m.1.conv1.bn.running_var     torch.Size([256])\n",
      "750\n",
      "backbone.C3_p4.m.1.conv1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.C3_p4.m.1.conv2.conv.weight     torch.Size([256, 256, 3, 3])\n",
      "750\n",
      "backbone.C3_p4.m.1.conv2.bn.weight     torch.Size([256])\n",
      "750\n",
      "backbone.C3_p4.m.1.conv2.bn.bias     torch.Size([256])\n",
      "750\n",
      "backbone.C3_p4.m.1.conv2.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "backbone.C3_p4.m.1.conv2.bn.running_var     torch.Size([256])\n",
      "750\n",
      "backbone.C3_p4.m.1.conv2.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.C3_p4.m.2.conv1.conv.weight     torch.Size([256, 256, 1, 1])\n",
      "750\n",
      "backbone.C3_p4.m.2.conv1.bn.weight     torch.Size([256])\n",
      "750\n",
      "backbone.C3_p4.m.2.conv1.bn.bias     torch.Size([256])\n",
      "750\n",
      "backbone.C3_p4.m.2.conv1.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "backbone.C3_p4.m.2.conv1.bn.running_var     torch.Size([256])\n",
      "750\n",
      "backbone.C3_p4.m.2.conv1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.C3_p4.m.2.conv2.conv.weight     torch.Size([256, 256, 3, 3])\n",
      "750\n",
      "backbone.C3_p4.m.2.conv2.bn.weight     torch.Size([256])\n",
      "750\n",
      "backbone.C3_p4.m.2.conv2.bn.bias     torch.Size([256])\n",
      "750\n",
      "backbone.C3_p4.m.2.conv2.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "backbone.C3_p4.m.2.conv2.bn.running_var     torch.Size([256])\n",
      "750\n",
      "backbone.C3_p4.m.2.conv2.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.reduce_conv1.conv.weight     torch.Size([256, 512, 1, 1])\n",
      "750\n",
      "backbone.reduce_conv1.bn.weight     torch.Size([256])\n",
      "750\n",
      "backbone.reduce_conv1.bn.bias     torch.Size([256])\n",
      "750\n",
      "backbone.reduce_conv1.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "backbone.reduce_conv1.bn.running_var     torch.Size([256])\n",
      "750\n",
      "backbone.reduce_conv1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.C3_p3.conv1.conv.weight     torch.Size([128, 512, 1, 1])\n",
      "750\n",
      "backbone.C3_p3.conv1.bn.weight     torch.Size([128])\n",
      "750\n",
      "backbone.C3_p3.conv1.bn.bias     torch.Size([128])\n",
      "750\n",
      "backbone.C3_p3.conv1.bn.running_mean     torch.Size([128])\n",
      "750\n",
      "backbone.C3_p3.conv1.bn.running_var     torch.Size([128])\n",
      "750\n",
      "backbone.C3_p3.conv1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.C3_p3.conv2.conv.weight     torch.Size([128, 512, 1, 1])\n",
      "750\n",
      "backbone.C3_p3.conv2.bn.weight     torch.Size([128])\n",
      "750\n",
      "backbone.C3_p3.conv2.bn.bias     torch.Size([128])\n",
      "750\n",
      "backbone.C3_p3.conv2.bn.running_mean     torch.Size([128])\n",
      "750\n",
      "backbone.C3_p3.conv2.bn.running_var     torch.Size([128])\n",
      "750\n",
      "backbone.C3_p3.conv2.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.C3_p3.conv3.conv.weight     torch.Size([256, 256, 1, 1])\n",
      "750\n",
      "backbone.C3_p3.conv3.bn.weight     torch.Size([256])\n",
      "750\n",
      "backbone.C3_p3.conv3.bn.bias     torch.Size([256])\n",
      "750\n",
      "backbone.C3_p3.conv3.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "backbone.C3_p3.conv3.bn.running_var     torch.Size([256])\n",
      "750\n",
      "backbone.C3_p3.conv3.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.C3_p3.m.0.conv1.conv.weight     torch.Size([128, 128, 1, 1])\n",
      "750\n",
      "backbone.C3_p3.m.0.conv1.bn.weight     torch.Size([128])\n",
      "750\n",
      "backbone.C3_p3.m.0.conv1.bn.bias     torch.Size([128])\n",
      "750\n",
      "backbone.C3_p3.m.0.conv1.bn.running_mean     torch.Size([128])\n",
      "750\n",
      "backbone.C3_p3.m.0.conv1.bn.running_var     torch.Size([128])\n",
      "750\n",
      "backbone.C3_p3.m.0.conv1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.C3_p3.m.0.conv2.conv.weight     torch.Size([128, 128, 3, 3])\n",
      "750\n",
      "backbone.C3_p3.m.0.conv2.bn.weight     torch.Size([128])\n",
      "750\n",
      "backbone.C3_p3.m.0.conv2.bn.bias     torch.Size([128])\n",
      "750\n",
      "backbone.C3_p3.m.0.conv2.bn.running_mean     torch.Size([128])\n",
      "750\n",
      "backbone.C3_p3.m.0.conv2.bn.running_var     torch.Size([128])\n",
      "750\n",
      "backbone.C3_p3.m.0.conv2.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.C3_p3.m.1.conv1.conv.weight     torch.Size([128, 128, 1, 1])\n",
      "750\n",
      "backbone.C3_p3.m.1.conv1.bn.weight     torch.Size([128])\n",
      "750\n",
      "backbone.C3_p3.m.1.conv1.bn.bias     torch.Size([128])\n",
      "750\n",
      "backbone.C3_p3.m.1.conv1.bn.running_mean     torch.Size([128])\n",
      "750\n",
      "backbone.C3_p3.m.1.conv1.bn.running_var     torch.Size([128])\n",
      "750\n",
      "backbone.C3_p3.m.1.conv1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.C3_p3.m.1.conv2.conv.weight     torch.Size([128, 128, 3, 3])\n",
      "750\n",
      "backbone.C3_p3.m.1.conv2.bn.weight     torch.Size([128])\n",
      "750\n",
      "backbone.C3_p3.m.1.conv2.bn.bias     torch.Size([128])\n",
      "750\n",
      "backbone.C3_p3.m.1.conv2.bn.running_mean     torch.Size([128])\n",
      "750\n",
      "backbone.C3_p3.m.1.conv2.bn.running_var     torch.Size([128])\n",
      "750\n",
      "backbone.C3_p3.m.1.conv2.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.C3_p3.m.2.conv1.conv.weight     torch.Size([128, 128, 1, 1])\n",
      "750\n",
      "backbone.C3_p3.m.2.conv1.bn.weight     torch.Size([128])\n",
      "750\n",
      "backbone.C3_p3.m.2.conv1.bn.bias     torch.Size([128])\n",
      "750\n",
      "backbone.C3_p3.m.2.conv1.bn.running_mean     torch.Size([128])\n",
      "750\n",
      "backbone.C3_p3.m.2.conv1.bn.running_var     torch.Size([128])\n",
      "750\n",
      "backbone.C3_p3.m.2.conv1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.C3_p3.m.2.conv2.conv.weight     torch.Size([128, 128, 3, 3])\n",
      "750\n",
      "backbone.C3_p3.m.2.conv2.bn.weight     torch.Size([128])\n",
      "750\n",
      "backbone.C3_p3.m.2.conv2.bn.bias     torch.Size([128])\n",
      "750\n",
      "backbone.C3_p3.m.2.conv2.bn.running_mean     torch.Size([128])\n",
      "750\n",
      "backbone.C3_p3.m.2.conv2.bn.running_var     torch.Size([128])\n",
      "750\n",
      "backbone.C3_p3.m.2.conv2.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.bu_conv2.conv.weight     torch.Size([256, 256, 3, 3])\n",
      "750\n",
      "backbone.bu_conv2.bn.weight     torch.Size([256])\n",
      "750\n",
      "backbone.bu_conv2.bn.bias     torch.Size([256])\n",
      "750\n",
      "backbone.bu_conv2.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "backbone.bu_conv2.bn.running_var     torch.Size([256])\n",
      "750\n",
      "backbone.bu_conv2.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.C3_n3.conv1.conv.weight     torch.Size([256, 512, 1, 1])\n",
      "750\n",
      "backbone.C3_n3.conv1.bn.weight     torch.Size([256])\n",
      "750\n",
      "backbone.C3_n3.conv1.bn.bias     torch.Size([256])\n",
      "750\n",
      "backbone.C3_n3.conv1.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "backbone.C3_n3.conv1.bn.running_var     torch.Size([256])\n",
      "750\n",
      "backbone.C3_n3.conv1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.C3_n3.conv2.conv.weight     torch.Size([256, 512, 1, 1])\n",
      "750\n",
      "backbone.C3_n3.conv2.bn.weight     torch.Size([256])\n",
      "750\n",
      "backbone.C3_n3.conv2.bn.bias     torch.Size([256])\n",
      "750\n",
      "backbone.C3_n3.conv2.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "backbone.C3_n3.conv2.bn.running_var     torch.Size([256])\n",
      "750\n",
      "backbone.C3_n3.conv2.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.C3_n3.conv3.conv.weight     torch.Size([512, 512, 1, 1])\n",
      "750\n",
      "backbone.C3_n3.conv3.bn.weight     torch.Size([512])\n",
      "750\n",
      "backbone.C3_n3.conv3.bn.bias     torch.Size([512])\n",
      "750\n",
      "backbone.C3_n3.conv3.bn.running_mean     torch.Size([512])\n",
      "750\n",
      "backbone.C3_n3.conv3.bn.running_var     torch.Size([512])\n",
      "750\n",
      "backbone.C3_n3.conv3.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.C3_n3.m.0.conv1.conv.weight     torch.Size([256, 256, 1, 1])\n",
      "750\n",
      "backbone.C3_n3.m.0.conv1.bn.weight     torch.Size([256])\n",
      "750\n",
      "backbone.C3_n3.m.0.conv1.bn.bias     torch.Size([256])\n",
      "750\n",
      "backbone.C3_n3.m.0.conv1.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "backbone.C3_n3.m.0.conv1.bn.running_var     torch.Size([256])\n",
      "750\n",
      "backbone.C3_n3.m.0.conv1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.C3_n3.m.0.conv2.conv.weight     torch.Size([256, 256, 3, 3])\n",
      "750\n",
      "backbone.C3_n3.m.0.conv2.bn.weight     torch.Size([256])\n",
      "750\n",
      "backbone.C3_n3.m.0.conv2.bn.bias     torch.Size([256])\n",
      "750\n",
      "backbone.C3_n3.m.0.conv2.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "backbone.C3_n3.m.0.conv2.bn.running_var     torch.Size([256])\n",
      "750\n",
      "backbone.C3_n3.m.0.conv2.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.C3_n3.m.1.conv1.conv.weight     torch.Size([256, 256, 1, 1])\n",
      "750\n",
      "backbone.C3_n3.m.1.conv1.bn.weight     torch.Size([256])\n",
      "750\n",
      "backbone.C3_n3.m.1.conv1.bn.bias     torch.Size([256])\n",
      "750\n",
      "backbone.C3_n3.m.1.conv1.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "backbone.C3_n3.m.1.conv1.bn.running_var     torch.Size([256])\n",
      "750\n",
      "backbone.C3_n3.m.1.conv1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.C3_n3.m.1.conv2.conv.weight     torch.Size([256, 256, 3, 3])\n",
      "750\n",
      "backbone.C3_n3.m.1.conv2.bn.weight     torch.Size([256])\n",
      "750\n",
      "backbone.C3_n3.m.1.conv2.bn.bias     torch.Size([256])\n",
      "750\n",
      "backbone.C3_n3.m.1.conv2.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "backbone.C3_n3.m.1.conv2.bn.running_var     torch.Size([256])\n",
      "750\n",
      "backbone.C3_n3.m.1.conv2.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.C3_n3.m.2.conv1.conv.weight     torch.Size([256, 256, 1, 1])\n",
      "750\n",
      "backbone.C3_n3.m.2.conv1.bn.weight     torch.Size([256])\n",
      "750\n",
      "backbone.C3_n3.m.2.conv1.bn.bias     torch.Size([256])\n",
      "750\n",
      "backbone.C3_n3.m.2.conv1.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "backbone.C3_n3.m.2.conv1.bn.running_var     torch.Size([256])\n",
      "750\n",
      "backbone.C3_n3.m.2.conv1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.C3_n3.m.2.conv2.conv.weight     torch.Size([256, 256, 3, 3])\n",
      "750\n",
      "backbone.C3_n3.m.2.conv2.bn.weight     torch.Size([256])\n",
      "750\n",
      "backbone.C3_n3.m.2.conv2.bn.bias     torch.Size([256])\n",
      "750\n",
      "backbone.C3_n3.m.2.conv2.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "backbone.C3_n3.m.2.conv2.bn.running_var     torch.Size([256])\n",
      "750\n",
      "backbone.C3_n3.m.2.conv2.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.bu_conv1.conv.weight     torch.Size([512, 512, 3, 3])\n",
      "750\n",
      "backbone.bu_conv1.bn.weight     torch.Size([512])\n",
      "750\n",
      "backbone.bu_conv1.bn.bias     torch.Size([512])\n",
      "750\n",
      "backbone.bu_conv1.bn.running_mean     torch.Size([512])\n",
      "750\n",
      "backbone.bu_conv1.bn.running_var     torch.Size([512])\n",
      "750\n",
      "backbone.bu_conv1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.C3_n4.conv1.conv.weight     torch.Size([512, 1024, 1, 1])\n",
      "750\n",
      "backbone.C3_n4.conv1.bn.weight     torch.Size([512])\n",
      "750\n",
      "backbone.C3_n4.conv1.bn.bias     torch.Size([512])\n",
      "750\n",
      "backbone.C3_n4.conv1.bn.running_mean     torch.Size([512])\n",
      "750\n",
      "backbone.C3_n4.conv1.bn.running_var     torch.Size([512])\n",
      "750\n",
      "backbone.C3_n4.conv1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.C3_n4.conv2.conv.weight     torch.Size([512, 1024, 1, 1])\n",
      "750\n",
      "backbone.C3_n4.conv2.bn.weight     torch.Size([512])\n",
      "750\n",
      "backbone.C3_n4.conv2.bn.bias     torch.Size([512])\n",
      "750\n",
      "backbone.C3_n4.conv2.bn.running_mean     torch.Size([512])\n",
      "750\n",
      "backbone.C3_n4.conv2.bn.running_var     torch.Size([512])\n",
      "750\n",
      "backbone.C3_n4.conv2.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.C3_n4.conv3.conv.weight     torch.Size([1024, 1024, 1, 1])\n",
      "750\n",
      "backbone.C3_n4.conv3.bn.weight     torch.Size([1024])\n",
      "750\n",
      "backbone.C3_n4.conv3.bn.bias     torch.Size([1024])\n",
      "750\n",
      "backbone.C3_n4.conv3.bn.running_mean     torch.Size([1024])\n",
      "750\n",
      "backbone.C3_n4.conv3.bn.running_var     torch.Size([1024])\n",
      "750\n",
      "backbone.C3_n4.conv3.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.C3_n4.m.0.conv1.conv.weight     torch.Size([512, 512, 1, 1])\n",
      "750\n",
      "backbone.C3_n4.m.0.conv1.bn.weight     torch.Size([512])\n",
      "750\n",
      "backbone.C3_n4.m.0.conv1.bn.bias     torch.Size([512])\n",
      "750\n",
      "backbone.C3_n4.m.0.conv1.bn.running_mean     torch.Size([512])\n",
      "750\n",
      "backbone.C3_n4.m.0.conv1.bn.running_var     torch.Size([512])\n",
      "750\n",
      "backbone.C3_n4.m.0.conv1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.C3_n4.m.0.conv2.conv.weight     torch.Size([512, 512, 3, 3])\n",
      "750\n",
      "backbone.C3_n4.m.0.conv2.bn.weight     torch.Size([512])\n",
      "750\n",
      "backbone.C3_n4.m.0.conv2.bn.bias     torch.Size([512])\n",
      "750\n",
      "backbone.C3_n4.m.0.conv2.bn.running_mean     torch.Size([512])\n",
      "750\n",
      "backbone.C3_n4.m.0.conv2.bn.running_var     torch.Size([512])\n",
      "750\n",
      "backbone.C3_n4.m.0.conv2.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.C3_n4.m.1.conv1.conv.weight     torch.Size([512, 512, 1, 1])\n",
      "750\n",
      "backbone.C3_n4.m.1.conv1.bn.weight     torch.Size([512])\n",
      "750\n",
      "backbone.C3_n4.m.1.conv1.bn.bias     torch.Size([512])\n",
      "750\n",
      "backbone.C3_n4.m.1.conv1.bn.running_mean     torch.Size([512])\n",
      "750\n",
      "backbone.C3_n4.m.1.conv1.bn.running_var     torch.Size([512])\n",
      "750\n",
      "backbone.C3_n4.m.1.conv1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.C3_n4.m.1.conv2.conv.weight     torch.Size([512, 512, 3, 3])\n",
      "750\n",
      "backbone.C3_n4.m.1.conv2.bn.weight     torch.Size([512])\n",
      "750\n",
      "backbone.C3_n4.m.1.conv2.bn.bias     torch.Size([512])\n",
      "750\n",
      "backbone.C3_n4.m.1.conv2.bn.running_mean     torch.Size([512])\n",
      "750\n",
      "backbone.C3_n4.m.1.conv2.bn.running_var     torch.Size([512])\n",
      "750\n",
      "backbone.C3_n4.m.1.conv2.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.C3_n4.m.2.conv1.conv.weight     torch.Size([512, 512, 1, 1])\n",
      "750\n",
      "backbone.C3_n4.m.2.conv1.bn.weight     torch.Size([512])\n",
      "750\n",
      "backbone.C3_n4.m.2.conv1.bn.bias     torch.Size([512])\n",
      "750\n",
      "backbone.C3_n4.m.2.conv1.bn.running_mean     torch.Size([512])\n",
      "750\n",
      "backbone.C3_n4.m.2.conv1.bn.running_var     torch.Size([512])\n",
      "750\n",
      "backbone.C3_n4.m.2.conv1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "backbone.C3_n4.m.2.conv2.conv.weight     torch.Size([512, 512, 3, 3])\n",
      "750\n",
      "backbone.C3_n4.m.2.conv2.bn.weight     torch.Size([512])\n",
      "750\n",
      "backbone.C3_n4.m.2.conv2.bn.bias     torch.Size([512])\n",
      "750\n",
      "backbone.C3_n4.m.2.conv2.bn.running_mean     torch.Size([512])\n",
      "750\n",
      "backbone.C3_n4.m.2.conv2.bn.running_var     torch.Size([512])\n",
      "750\n",
      "backbone.C3_n4.m.2.conv2.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "head.cls_convs.0.0.conv.weight     torch.Size([256, 256, 3, 3])\n",
      "750\n",
      "head.cls_convs.0.0.bn.weight     torch.Size([256])\n",
      "750\n",
      "head.cls_convs.0.0.bn.bias     torch.Size([256])\n",
      "750\n",
      "head.cls_convs.0.0.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "head.cls_convs.0.0.bn.running_var     torch.Size([256])\n",
      "750\n",
      "head.cls_convs.0.0.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "head.cls_convs.0.1.conv.weight     torch.Size([256, 256, 3, 3])\n",
      "750\n",
      "head.cls_convs.0.1.bn.weight     torch.Size([256])\n",
      "750\n",
      "head.cls_convs.0.1.bn.bias     torch.Size([256])\n",
      "750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head.cls_convs.0.1.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "head.cls_convs.0.1.bn.running_var     torch.Size([256])\n",
      "750\n",
      "head.cls_convs.0.1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "head.cls_convs.1.0.conv.weight     torch.Size([256, 256, 3, 3])\n",
      "750\n",
      "head.cls_convs.1.0.bn.weight     torch.Size([256])\n",
      "750\n",
      "head.cls_convs.1.0.bn.bias     torch.Size([256])\n",
      "750\n",
      "head.cls_convs.1.0.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "head.cls_convs.1.0.bn.running_var     torch.Size([256])\n",
      "750\n",
      "head.cls_convs.1.0.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "head.cls_convs.1.1.conv.weight     torch.Size([256, 256, 3, 3])\n",
      "750\n",
      "head.cls_convs.1.1.bn.weight     torch.Size([256])\n",
      "750\n",
      "head.cls_convs.1.1.bn.bias     torch.Size([256])\n",
      "750\n",
      "head.cls_convs.1.1.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "head.cls_convs.1.1.bn.running_var     torch.Size([256])\n",
      "750\n",
      "head.cls_convs.1.1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "head.cls_convs.2.0.conv.weight     torch.Size([256, 256, 3, 3])\n",
      "750\n",
      "head.cls_convs.2.0.bn.weight     torch.Size([256])\n",
      "750\n",
      "head.cls_convs.2.0.bn.bias     torch.Size([256])\n",
      "750\n",
      "head.cls_convs.2.0.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "head.cls_convs.2.0.bn.running_var     torch.Size([256])\n",
      "750\n",
      "head.cls_convs.2.0.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "head.cls_convs.2.1.conv.weight     torch.Size([256, 256, 3, 3])\n",
      "750\n",
      "head.cls_convs.2.1.bn.weight     torch.Size([256])\n",
      "750\n",
      "head.cls_convs.2.1.bn.bias     torch.Size([256])\n",
      "750\n",
      "head.cls_convs.2.1.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "head.cls_convs.2.1.bn.running_var     torch.Size([256])\n",
      "750\n",
      "head.cls_convs.2.1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "head.reg_convs.0.0.conv.weight     torch.Size([256, 256, 3, 3])\n",
      "750\n",
      "head.reg_convs.0.0.bn.weight     torch.Size([256])\n",
      "750\n",
      "head.reg_convs.0.0.bn.bias     torch.Size([256])\n",
      "750\n",
      "head.reg_convs.0.0.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "head.reg_convs.0.0.bn.running_var     torch.Size([256])\n",
      "750\n",
      "head.reg_convs.0.0.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "head.reg_convs.0.1.conv.weight     torch.Size([256, 256, 3, 3])\n",
      "750\n",
      "head.reg_convs.0.1.bn.weight     torch.Size([256])\n",
      "750\n",
      "head.reg_convs.0.1.bn.bias     torch.Size([256])\n",
      "750\n",
      "head.reg_convs.0.1.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "head.reg_convs.0.1.bn.running_var     torch.Size([256])\n",
      "750\n",
      "head.reg_convs.0.1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "head.reg_convs.1.0.conv.weight     torch.Size([256, 256, 3, 3])\n",
      "750\n",
      "head.reg_convs.1.0.bn.weight     torch.Size([256])\n",
      "750\n",
      "head.reg_convs.1.0.bn.bias     torch.Size([256])\n",
      "750\n",
      "head.reg_convs.1.0.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "head.reg_convs.1.0.bn.running_var     torch.Size([256])\n",
      "750\n",
      "head.reg_convs.1.0.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "head.reg_convs.1.1.conv.weight     torch.Size([256, 256, 3, 3])\n",
      "750\n",
      "head.reg_convs.1.1.bn.weight     torch.Size([256])\n",
      "750\n",
      "head.reg_convs.1.1.bn.bias     torch.Size([256])\n",
      "750\n",
      "head.reg_convs.1.1.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "head.reg_convs.1.1.bn.running_var     torch.Size([256])\n",
      "750\n",
      "head.reg_convs.1.1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "head.reg_convs.2.0.conv.weight     torch.Size([256, 256, 3, 3])\n",
      "750\n",
      "head.reg_convs.2.0.bn.weight     torch.Size([256])\n",
      "750\n",
      "head.reg_convs.2.0.bn.bias     torch.Size([256])\n",
      "750\n",
      "head.reg_convs.2.0.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "head.reg_convs.2.0.bn.running_var     torch.Size([256])\n",
      "750\n",
      "head.reg_convs.2.0.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "head.reg_convs.2.1.conv.weight     torch.Size([256, 256, 3, 3])\n",
      "750\n",
      "head.reg_convs.2.1.bn.weight     torch.Size([256])\n",
      "750\n",
      "head.reg_convs.2.1.bn.bias     torch.Size([256])\n",
      "750\n",
      "head.reg_convs.2.1.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "head.reg_convs.2.1.bn.running_var     torch.Size([256])\n",
      "750\n",
      "head.reg_convs.2.1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "head.cls_preds.0.weight     torch.Size([80, 256, 1, 1])\n",
      "750\n",
      "head.cls_preds.0.bias     torch.Size([80])\n",
      "750\n",
      "head.cls_preds.1.weight     torch.Size([80, 256, 1, 1])\n",
      "750\n",
      "head.cls_preds.1.bias     torch.Size([80])\n",
      "750\n",
      "head.cls_preds.2.weight     torch.Size([80, 256, 1, 1])\n",
      "750\n",
      "head.cls_preds.2.bias     torch.Size([80])\n",
      "750\n",
      "head.reg_preds.0.weight     torch.Size([4, 256, 1, 1])\n",
      "750\n",
      "head.reg_preds.0.bias     torch.Size([4])\n",
      "750\n",
      "head.reg_preds.1.weight     torch.Size([4, 256, 1, 1])\n",
      "750\n",
      "head.reg_preds.1.bias     torch.Size([4])\n",
      "750\n",
      "head.reg_preds.2.weight     torch.Size([4, 256, 1, 1])\n",
      "750\n",
      "head.reg_preds.2.bias     torch.Size([4])\n",
      "750\n",
      "head.obj_preds.0.weight     torch.Size([1, 256, 1, 1])\n",
      "750\n",
      "head.obj_preds.0.bias     torch.Size([1])\n",
      "750\n",
      "head.obj_preds.1.weight     torch.Size([1, 256, 1, 1])\n",
      "750\n",
      "head.obj_preds.1.bias     torch.Size([1])\n",
      "750\n",
      "head.obj_preds.2.weight     torch.Size([1, 256, 1, 1])\n",
      "750\n",
      "head.obj_preds.2.bias     torch.Size([1])\n",
      "750\n",
      "head.stems.0.conv.weight     torch.Size([256, 256, 1, 1])\n",
      "750\n",
      "head.stems.0.bn.weight     torch.Size([256])\n",
      "750\n",
      "head.stems.0.bn.bias     torch.Size([256])\n",
      "750\n",
      "head.stems.0.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "head.stems.0.bn.running_var     torch.Size([256])\n",
      "750\n",
      "head.stems.0.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "head.stems.1.conv.weight     torch.Size([256, 512, 1, 1])\n",
      "750\n",
      "head.stems.1.bn.weight     torch.Size([256])\n",
      "750\n",
      "head.stems.1.bn.bias     torch.Size([256])\n",
      "750\n",
      "head.stems.1.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "head.stems.1.bn.running_var     torch.Size([256])\n",
      "750\n",
      "head.stems.1.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "head.stems.2.conv.weight     torch.Size([256, 1024, 1, 1])\n",
      "750\n",
      "head.stems.2.bn.weight     torch.Size([256])\n",
      "750\n",
      "head.stems.2.bn.bias     torch.Size([256])\n",
      "750\n",
      "head.stems.2.bn.running_mean     torch.Size([256])\n",
      "750\n",
      "head.stems.2.bn.running_var     torch.Size([256])\n",
      "750\n",
      "head.stems.2.bn.num_batches_tracked     torch.Size([])\n",
      "750\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "path = r\"G:\\学习资料\\目标检测\\yolox_l.pth\"\n",
    "\n",
    "\n",
    "\n",
    "no_backbone_weight = torch.load(path)\n",
    "# print(type(no_backbone_weight))\n",
    "i = 0\n",
    "# for k in list(no_backbone_weight.keys()):\n",
    "#     if \"backbone.backbone.dark\" in k:\n",
    "#         i += 1\n",
    "#         del no_backbone_weight[k]\n",
    "#     if \"backbone\" in k:\n",
    "#         i += 1\n",
    "#         del no_backbone_weight[k]\n",
    "for name, para in no_backbone_weight.items():\n",
    "    print(name,\"   \", para.size())\n",
    "    print(len(no_backbone_weight))\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c299d9e6",
   "metadata": {},
   "source": [
    "## SwinTransformer = 364\n",
    "## stem=4, head=2, norm=2\n",
    "## layers=356\n",
    "## layers.0 = 32,layers.1=32, layers.2=264, layers.3 = 28,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1a70b6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T13:18:31.427650Z",
     "start_time": "2021-11-26T13:18:29.497772Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patch_embed.proj.weight       torch.Size([128, 3, 4, 4])\n",
      "364 0\n",
      "patch_embed.proj.bias       torch.Size([128])\n",
      "364 0\n",
      "patch_embed.norm.weight       torch.Size([128])\n",
      "364 0\n",
      "patch_embed.norm.bias       torch.Size([128])\n",
      "364 0\n",
      "layers.0.blocks.0.norm1.weight       torch.Size([128])\n",
      "364 0\n",
      "layers.0.blocks.0.norm1.bias       torch.Size([128])\n",
      "364 0\n",
      "layers.0.blocks.0.attn.qkv.weight       torch.Size([384, 128])\n",
      "364 0\n",
      "layers.0.blocks.0.attn.qkv.bias       torch.Size([384])\n",
      "364 0\n",
      "layers.0.blocks.0.attn.proj.weight       torch.Size([128, 128])\n",
      "364 0\n",
      "layers.0.blocks.0.attn.proj.bias       torch.Size([128])\n",
      "364 0\n",
      "layers.0.blocks.0.norm2.weight       torch.Size([128])\n",
      "364 0\n",
      "layers.0.blocks.0.norm2.bias       torch.Size([128])\n",
      "364 0\n",
      "layers.0.blocks.0.mlp.fc1.weight       torch.Size([512, 128])\n",
      "364 0\n",
      "layers.0.blocks.0.mlp.fc1.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.0.blocks.0.mlp.fc2.weight       torch.Size([128, 512])\n",
      "364 0\n",
      "layers.0.blocks.0.mlp.fc2.bias       torch.Size([128])\n",
      "364 0\n",
      "layers.0.blocks.1.norm1.weight       torch.Size([128])\n",
      "364 0\n",
      "layers.0.blocks.1.norm1.bias       torch.Size([128])\n",
      "364 0\n",
      "layers.0.blocks.1.attn.qkv.weight       torch.Size([384, 128])\n",
      "364 0\n",
      "layers.0.blocks.1.attn.qkv.bias       torch.Size([384])\n",
      "364 0\n",
      "layers.0.blocks.1.attn.proj.weight       torch.Size([128, 128])\n",
      "364 0\n",
      "layers.0.blocks.1.attn.proj.bias       torch.Size([128])\n",
      "364 0\n",
      "layers.0.blocks.1.norm2.weight       torch.Size([128])\n",
      "364 0\n",
      "layers.0.blocks.1.norm2.bias       torch.Size([128])\n",
      "364 0\n",
      "layers.0.blocks.1.mlp.fc1.weight       torch.Size([512, 128])\n",
      "364 0\n",
      "layers.0.blocks.1.mlp.fc1.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.0.blocks.1.mlp.fc2.weight       torch.Size([128, 512])\n",
      "364 0\n",
      "layers.0.blocks.1.mlp.fc2.bias       torch.Size([128])\n",
      "364 0\n",
      "layers.0.downsample.norm.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.0.downsample.norm.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.1.blocks.0.norm1.weight       torch.Size([256])\n",
      "364 0\n",
      "layers.1.blocks.0.norm1.bias       torch.Size([256])\n",
      "364 0\n",
      "layers.1.blocks.0.attn.qkv.weight       torch.Size([768, 256])\n",
      "364 0\n",
      "layers.1.blocks.0.attn.qkv.bias       torch.Size([768])\n",
      "364 0\n",
      "layers.1.blocks.0.attn.proj.weight       torch.Size([256, 256])\n",
      "364 0\n",
      "layers.1.blocks.0.attn.proj.bias       torch.Size([256])\n",
      "364 0\n",
      "layers.1.blocks.0.norm2.weight       torch.Size([256])\n",
      "364 0\n",
      "layers.1.blocks.0.norm2.bias       torch.Size([256])\n",
      "364 0\n",
      "layers.1.blocks.0.mlp.fc1.weight       torch.Size([1024, 256])\n",
      "364 0\n",
      "layers.1.blocks.0.mlp.fc1.bias       torch.Size([1024])\n",
      "364 0\n",
      "layers.1.blocks.0.mlp.fc2.weight       torch.Size([256, 1024])\n",
      "364 0\n",
      "layers.1.blocks.0.mlp.fc2.bias       torch.Size([256])\n",
      "364 0\n",
      "layers.1.blocks.1.norm1.weight       torch.Size([256])\n",
      "364 0\n",
      "layers.1.blocks.1.norm1.bias       torch.Size([256])\n",
      "364 0\n",
      "layers.1.blocks.1.attn.qkv.weight       torch.Size([768, 256])\n",
      "364 0\n",
      "layers.1.blocks.1.attn.qkv.bias       torch.Size([768])\n",
      "364 0\n",
      "layers.1.blocks.1.attn.proj.weight       torch.Size([256, 256])\n",
      "364 0\n",
      "layers.1.blocks.1.attn.proj.bias       torch.Size([256])\n",
      "364 0\n",
      "layers.1.blocks.1.norm2.weight       torch.Size([256])\n",
      "364 0\n",
      "layers.1.blocks.1.norm2.bias       torch.Size([256])\n",
      "364 0\n",
      "layers.1.blocks.1.mlp.fc1.weight       torch.Size([1024, 256])\n",
      "364 0\n",
      "layers.1.blocks.1.mlp.fc1.bias       torch.Size([1024])\n",
      "364 0\n",
      "layers.1.blocks.1.mlp.fc2.weight       torch.Size([256, 1024])\n",
      "364 0\n",
      "layers.1.blocks.1.mlp.fc2.bias       torch.Size([256])\n",
      "364 0\n",
      "layers.1.downsample.norm.weight       torch.Size([1024])\n",
      "364 0\n",
      "layers.1.downsample.norm.bias       torch.Size([1024])\n",
      "364 0\n",
      "layers.2.blocks.0.norm1.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.0.norm1.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.0.attn.qkv.weight       torch.Size([1536, 512])\n",
      "364 0\n",
      "layers.2.blocks.0.attn.qkv.bias       torch.Size([1536])\n",
      "364 0\n",
      "layers.2.blocks.0.attn.proj.weight       torch.Size([512, 512])\n",
      "364 0\n",
      "layers.2.blocks.0.attn.proj.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.0.norm2.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.0.norm2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.0.mlp.fc1.weight       torch.Size([2048, 512])\n",
      "364 0\n",
      "layers.2.blocks.0.mlp.fc1.bias       torch.Size([2048])\n",
      "364 0\n",
      "layers.2.blocks.0.mlp.fc2.weight       torch.Size([512, 2048])\n",
      "364 0\n",
      "layers.2.blocks.0.mlp.fc2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.1.norm1.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.1.norm1.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.1.attn.qkv.weight       torch.Size([1536, 512])\n",
      "364 0\n",
      "layers.2.blocks.1.attn.qkv.bias       torch.Size([1536])\n",
      "364 0\n",
      "layers.2.blocks.1.attn.proj.weight       torch.Size([512, 512])\n",
      "364 0\n",
      "layers.2.blocks.1.attn.proj.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.1.norm2.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.1.norm2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.1.mlp.fc1.weight       torch.Size([2048, 512])\n",
      "364 0\n",
      "layers.2.blocks.1.mlp.fc1.bias       torch.Size([2048])\n",
      "364 0\n",
      "layers.2.blocks.1.mlp.fc2.weight       torch.Size([512, 2048])\n",
      "364 0\n",
      "layers.2.blocks.1.mlp.fc2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.2.norm1.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.2.norm1.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.2.attn.qkv.weight       torch.Size([1536, 512])\n",
      "364 0\n",
      "layers.2.blocks.2.attn.qkv.bias       torch.Size([1536])\n",
      "364 0\n",
      "layers.2.blocks.2.attn.proj.weight       torch.Size([512, 512])\n",
      "364 0\n",
      "layers.2.blocks.2.attn.proj.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.2.norm2.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.2.norm2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.2.mlp.fc1.weight       torch.Size([2048, 512])\n",
      "364 0\n",
      "layers.2.blocks.2.mlp.fc1.bias       torch.Size([2048])\n",
      "364 0\n",
      "layers.2.blocks.2.mlp.fc2.weight       torch.Size([512, 2048])\n",
      "364 0\n",
      "layers.2.blocks.2.mlp.fc2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.3.norm1.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.3.norm1.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.3.attn.qkv.weight       torch.Size([1536, 512])\n",
      "364 0\n",
      "layers.2.blocks.3.attn.qkv.bias       torch.Size([1536])\n",
      "364 0\n",
      "layers.2.blocks.3.attn.proj.weight       torch.Size([512, 512])\n",
      "364 0\n",
      "layers.2.blocks.3.attn.proj.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.3.norm2.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.3.norm2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.3.mlp.fc1.weight       torch.Size([2048, 512])\n",
      "364 0\n",
      "layers.2.blocks.3.mlp.fc1.bias       torch.Size([2048])\n",
      "364 0\n",
      "layers.2.blocks.3.mlp.fc2.weight       torch.Size([512, 2048])\n",
      "364 0\n",
      "layers.2.blocks.3.mlp.fc2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.4.norm1.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.4.norm1.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.4.attn.qkv.weight       torch.Size([1536, 512])\n",
      "364 0\n",
      "layers.2.blocks.4.attn.qkv.bias       torch.Size([1536])\n",
      "364 0\n",
      "layers.2.blocks.4.attn.proj.weight       torch.Size([512, 512])\n",
      "364 0\n",
      "layers.2.blocks.4.attn.proj.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.4.norm2.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.4.norm2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.4.mlp.fc1.weight       torch.Size([2048, 512])\n",
      "364 0\n",
      "layers.2.blocks.4.mlp.fc1.bias       torch.Size([2048])\n",
      "364 0\n",
      "layers.2.blocks.4.mlp.fc2.weight       torch.Size([512, 2048])\n",
      "364 0\n",
      "layers.2.blocks.4.mlp.fc2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.5.norm1.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.5.norm1.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.5.attn.qkv.weight       torch.Size([1536, 512])\n",
      "364 0\n",
      "layers.2.blocks.5.attn.qkv.bias       torch.Size([1536])\n",
      "364 0\n",
      "layers.2.blocks.5.attn.proj.weight       torch.Size([512, 512])\n",
      "364 0\n",
      "layers.2.blocks.5.attn.proj.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.5.norm2.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.5.norm2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.5.mlp.fc1.weight       torch.Size([2048, 512])\n",
      "364 0\n",
      "layers.2.blocks.5.mlp.fc1.bias       torch.Size([2048])\n",
      "364 0\n",
      "layers.2.blocks.5.mlp.fc2.weight       torch.Size([512, 2048])\n",
      "364 0\n",
      "layers.2.blocks.5.mlp.fc2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.6.norm1.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.6.norm1.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.6.attn.qkv.weight       torch.Size([1536, 512])\n",
      "364 0\n",
      "layers.2.blocks.6.attn.qkv.bias       torch.Size([1536])\n",
      "364 0\n",
      "layers.2.blocks.6.attn.proj.weight       torch.Size([512, 512])\n",
      "364 0\n",
      "layers.2.blocks.6.attn.proj.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.6.norm2.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.6.norm2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.6.mlp.fc1.weight       torch.Size([2048, 512])\n",
      "364 0\n",
      "layers.2.blocks.6.mlp.fc1.bias       torch.Size([2048])\n",
      "364 0\n",
      "layers.2.blocks.6.mlp.fc2.weight       torch.Size([512, 2048])\n",
      "364 0\n",
      "layers.2.blocks.6.mlp.fc2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.7.norm1.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.7.norm1.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.7.attn.qkv.weight       torch.Size([1536, 512])\n",
      "364 0\n",
      "layers.2.blocks.7.attn.qkv.bias       torch.Size([1536])\n",
      "364 0\n",
      "layers.2.blocks.7.attn.proj.weight       torch.Size([512, 512])\n",
      "364 0\n",
      "layers.2.blocks.7.attn.proj.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.7.norm2.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.7.norm2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.7.mlp.fc1.weight       torch.Size([2048, 512])\n",
      "364 0\n",
      "layers.2.blocks.7.mlp.fc1.bias       torch.Size([2048])\n",
      "364 0\n",
      "layers.2.blocks.7.mlp.fc2.weight       torch.Size([512, 2048])\n",
      "364 0\n",
      "layers.2.blocks.7.mlp.fc2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.8.norm1.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.8.norm1.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.8.attn.qkv.weight       torch.Size([1536, 512])\n",
      "364 0\n",
      "layers.2.blocks.8.attn.qkv.bias       torch.Size([1536])\n",
      "364 0\n",
      "layers.2.blocks.8.attn.proj.weight       torch.Size([512, 512])\n",
      "364 0\n",
      "layers.2.blocks.8.attn.proj.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.8.norm2.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.8.norm2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.8.mlp.fc1.weight       torch.Size([2048, 512])\n",
      "364 0\n",
      "layers.2.blocks.8.mlp.fc1.bias       torch.Size([2048])\n",
      "364 0\n",
      "layers.2.blocks.8.mlp.fc2.weight       torch.Size([512, 2048])\n",
      "364 0\n",
      "layers.2.blocks.8.mlp.fc2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.9.norm1.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.9.norm1.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.9.attn.qkv.weight       torch.Size([1536, 512])\n",
      "364 0\n",
      "layers.2.blocks.9.attn.qkv.bias       torch.Size([1536])\n",
      "364 0\n",
      "layers.2.blocks.9.attn.proj.weight       torch.Size([512, 512])\n",
      "364 0\n",
      "layers.2.blocks.9.attn.proj.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.9.norm2.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.9.norm2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.9.mlp.fc1.weight       torch.Size([2048, 512])\n",
      "364 0\n",
      "layers.2.blocks.9.mlp.fc1.bias       torch.Size([2048])\n",
      "364 0\n",
      "layers.2.blocks.9.mlp.fc2.weight       torch.Size([512, 2048])\n",
      "364 0\n",
      "layers.2.blocks.9.mlp.fc2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.10.norm1.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.10.norm1.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.10.attn.qkv.weight       torch.Size([1536, 512])\n",
      "364 0\n",
      "layers.2.blocks.10.attn.qkv.bias       torch.Size([1536])\n",
      "364 0\n",
      "layers.2.blocks.10.attn.proj.weight       torch.Size([512, 512])\n",
      "364 0\n",
      "layers.2.blocks.10.attn.proj.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.10.norm2.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.10.norm2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.10.mlp.fc1.weight       torch.Size([2048, 512])\n",
      "364 0\n",
      "layers.2.blocks.10.mlp.fc1.bias       torch.Size([2048])\n",
      "364 0\n",
      "layers.2.blocks.10.mlp.fc2.weight       torch.Size([512, 2048])\n",
      "364 0\n",
      "layers.2.blocks.10.mlp.fc2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.11.norm1.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.11.norm1.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.11.attn.qkv.weight       torch.Size([1536, 512])\n",
      "364 0\n",
      "layers.2.blocks.11.attn.qkv.bias       torch.Size([1536])\n",
      "364 0\n",
      "layers.2.blocks.11.attn.proj.weight       torch.Size([512, 512])\n",
      "364 0\n",
      "layers.2.blocks.11.attn.proj.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.11.norm2.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.11.norm2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.11.mlp.fc1.weight       torch.Size([2048, 512])\n",
      "364 0\n",
      "layers.2.blocks.11.mlp.fc1.bias       torch.Size([2048])\n",
      "364 0\n",
      "layers.2.blocks.11.mlp.fc2.weight       torch.Size([512, 2048])\n",
      "364 0\n",
      "layers.2.blocks.11.mlp.fc2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.12.norm1.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.12.norm1.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.12.attn.qkv.weight       torch.Size([1536, 512])\n",
      "364 0\n",
      "layers.2.blocks.12.attn.qkv.bias       torch.Size([1536])\n",
      "364 0\n",
      "layers.2.blocks.12.attn.proj.weight       torch.Size([512, 512])\n",
      "364 0\n",
      "layers.2.blocks.12.attn.proj.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.12.norm2.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.12.norm2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.12.mlp.fc1.weight       torch.Size([2048, 512])\n",
      "364 0\n",
      "layers.2.blocks.12.mlp.fc1.bias       torch.Size([2048])\n",
      "364 0\n",
      "layers.2.blocks.12.mlp.fc2.weight       torch.Size([512, 2048])\n",
      "364 0\n",
      "layers.2.blocks.12.mlp.fc2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.13.norm1.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.13.norm1.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.13.attn.qkv.weight       torch.Size([1536, 512])\n",
      "364 0\n",
      "layers.2.blocks.13.attn.qkv.bias       torch.Size([1536])\n",
      "364 0\n",
      "layers.2.blocks.13.attn.proj.weight       torch.Size([512, 512])\n",
      "364 0\n",
      "layers.2.blocks.13.attn.proj.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.13.norm2.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.13.norm2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.13.mlp.fc1.weight       torch.Size([2048, 512])\n",
      "364 0\n",
      "layers.2.blocks.13.mlp.fc1.bias       torch.Size([2048])\n",
      "364 0\n",
      "layers.2.blocks.13.mlp.fc2.weight       torch.Size([512, 2048])\n",
      "364 0\n",
      "layers.2.blocks.13.mlp.fc2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.14.norm1.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.14.norm1.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.14.attn.qkv.weight       torch.Size([1536, 512])\n",
      "364 0\n",
      "layers.2.blocks.14.attn.qkv.bias       torch.Size([1536])\n",
      "364 0\n",
      "layers.2.blocks.14.attn.proj.weight       torch.Size([512, 512])\n",
      "364 0\n",
      "layers.2.blocks.14.attn.proj.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.14.norm2.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.14.norm2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.14.mlp.fc1.weight       torch.Size([2048, 512])\n",
      "364 0\n",
      "layers.2.blocks.14.mlp.fc1.bias       torch.Size([2048])\n",
      "364 0\n",
      "layers.2.blocks.14.mlp.fc2.weight       torch.Size([512, 2048])\n",
      "364 0\n",
      "layers.2.blocks.14.mlp.fc2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.15.norm1.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.15.norm1.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.15.attn.qkv.weight       torch.Size([1536, 512])\n",
      "364 0\n",
      "layers.2.blocks.15.attn.qkv.bias       torch.Size([1536])\n",
      "364 0\n",
      "layers.2.blocks.15.attn.proj.weight       torch.Size([512, 512])\n",
      "364 0\n",
      "layers.2.blocks.15.attn.proj.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.15.norm2.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.15.norm2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.15.mlp.fc1.weight       torch.Size([2048, 512])\n",
      "364 0\n",
      "layers.2.blocks.15.mlp.fc1.bias       torch.Size([2048])\n",
      "364 0\n",
      "layers.2.blocks.15.mlp.fc2.weight       torch.Size([512, 2048])\n",
      "364 0\n",
      "layers.2.blocks.15.mlp.fc2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.16.norm1.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.16.norm1.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.16.attn.qkv.weight       torch.Size([1536, 512])\n",
      "364 0\n",
      "layers.2.blocks.16.attn.qkv.bias       torch.Size([1536])\n",
      "364 0\n",
      "layers.2.blocks.16.attn.proj.weight       torch.Size([512, 512])\n",
      "364 0\n",
      "layers.2.blocks.16.attn.proj.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.16.norm2.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.16.norm2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.16.mlp.fc1.weight       torch.Size([2048, 512])\n",
      "364 0\n",
      "layers.2.blocks.16.mlp.fc1.bias       torch.Size([2048])\n",
      "364 0\n",
      "layers.2.blocks.16.mlp.fc2.weight       torch.Size([512, 2048])\n",
      "364 0\n",
      "layers.2.blocks.16.mlp.fc2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.17.norm1.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.17.norm1.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.17.attn.qkv.weight       torch.Size([1536, 512])\n",
      "364 0\n",
      "layers.2.blocks.17.attn.qkv.bias       torch.Size([1536])\n",
      "364 0\n",
      "layers.2.blocks.17.attn.proj.weight       torch.Size([512, 512])\n",
      "364 0\n",
      "layers.2.blocks.17.attn.proj.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.17.norm2.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.17.norm2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.17.mlp.fc1.weight       torch.Size([2048, 512])\n",
      "364 0\n",
      "layers.2.blocks.17.mlp.fc1.bias       torch.Size([2048])\n",
      "364 0\n",
      "layers.2.blocks.17.mlp.fc2.weight       torch.Size([512, 2048])\n",
      "364 0\n",
      "layers.2.blocks.17.mlp.fc2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.downsample.norm.weight       torch.Size([2048])\n",
      "364 0\n",
      "layers.2.downsample.norm.bias       torch.Size([2048])\n",
      "364 0\n",
      "layers.3.blocks.0.norm1.weight       torch.Size([1024])\n",
      "364 0\n",
      "layers.3.blocks.0.norm1.bias       torch.Size([1024])\n",
      "364 0\n",
      "layers.3.blocks.0.attn.qkv.weight       torch.Size([3072, 1024])\n",
      "364 0\n",
      "layers.3.blocks.0.attn.qkv.bias       torch.Size([3072])\n",
      "364 0\n",
      "layers.3.blocks.0.attn.proj.weight       torch.Size([1024, 1024])\n",
      "364 0\n",
      "layers.3.blocks.0.attn.proj.bias       torch.Size([1024])\n",
      "364 0\n",
      "layers.3.blocks.0.norm2.weight       torch.Size([1024])\n",
      "364 0\n",
      "layers.3.blocks.0.norm2.bias       torch.Size([1024])\n",
      "364 0\n",
      "layers.3.blocks.0.mlp.fc1.weight       torch.Size([4096, 1024])\n",
      "364 0\n",
      "layers.3.blocks.0.mlp.fc1.bias       torch.Size([4096])\n",
      "364 0\n",
      "layers.3.blocks.0.mlp.fc2.weight       torch.Size([1024, 4096])\n",
      "364 0\n",
      "layers.3.blocks.0.mlp.fc2.bias       torch.Size([1024])\n",
      "364 0\n",
      "layers.3.blocks.1.norm1.weight       torch.Size([1024])\n",
      "364 0\n",
      "layers.3.blocks.1.norm1.bias       torch.Size([1024])\n",
      "364 0\n",
      "layers.3.blocks.1.attn.qkv.weight       torch.Size([3072, 1024])\n",
      "364 0\n",
      "layers.3.blocks.1.attn.qkv.bias       torch.Size([3072])\n",
      "364 0\n",
      "layers.3.blocks.1.attn.proj.weight       torch.Size([1024, 1024])\n",
      "364 0\n",
      "layers.3.blocks.1.attn.proj.bias       torch.Size([1024])\n",
      "364 0\n",
      "layers.3.blocks.1.norm2.weight       torch.Size([1024])\n",
      "364 0\n",
      "layers.3.blocks.1.norm2.bias       torch.Size([1024])\n",
      "364 0\n",
      "layers.3.blocks.1.mlp.fc1.weight       torch.Size([4096, 1024])\n",
      "364 0\n",
      "layers.3.blocks.1.mlp.fc1.bias       torch.Size([4096])\n",
      "364 0\n",
      "layers.3.blocks.1.mlp.fc2.weight       torch.Size([1024, 4096])\n",
      "364 0\n",
      "layers.3.blocks.1.mlp.fc2.bias       torch.Size([1024])\n",
      "364 0\n",
      "norm.weight       torch.Size([1024])\n",
      "364 0\n",
      "norm.bias       torch.Size([1024])\n",
      "364 0\n",
      "head.weight       torch.Size([1000, 1024])\n",
      "364 0\n",
      "head.bias       torch.Size([1000])\n",
      "364 0\n",
      "layers.0.blocks.0.attn.relative_position_index       torch.Size([144, 144])\n",
      "364 0\n",
      "layers.0.blocks.1.attn.relative_position_index       torch.Size([144, 144])\n",
      "364 0\n",
      "layers.1.blocks.0.attn.relative_position_index       torch.Size([144, 144])\n",
      "364 0\n",
      "layers.1.blocks.1.attn.relative_position_index       torch.Size([144, 144])\n",
      "364 0\n",
      "layers.2.blocks.0.attn.relative_position_index       torch.Size([144, 144])\n",
      "364 0\n",
      "layers.2.blocks.1.attn.relative_position_index       torch.Size([144, 144])\n",
      "364 0\n",
      "layers.2.blocks.2.attn.relative_position_index       torch.Size([144, 144])\n",
      "364 0\n",
      "layers.2.blocks.3.attn.relative_position_index       torch.Size([144, 144])\n",
      "364 0\n",
      "layers.2.blocks.4.attn.relative_position_index       torch.Size([144, 144])\n",
      "364 0\n",
      "layers.2.blocks.5.attn.relative_position_index       torch.Size([144, 144])\n",
      "364 0\n",
      "layers.2.blocks.6.attn.relative_position_index       torch.Size([144, 144])\n",
      "364 0\n",
      "layers.2.blocks.7.attn.relative_position_index       torch.Size([144, 144])\n",
      "364 0\n",
      "layers.2.blocks.8.attn.relative_position_index       torch.Size([144, 144])\n",
      "364 0\n",
      "layers.2.blocks.9.attn.relative_position_index       torch.Size([144, 144])\n",
      "364 0\n",
      "layers.2.blocks.10.attn.relative_position_index       torch.Size([144, 144])\n",
      "364 0\n",
      "layers.2.blocks.11.attn.relative_position_index       torch.Size([144, 144])\n",
      "364 0\n",
      "layers.2.blocks.12.attn.relative_position_index       torch.Size([144, 144])\n",
      "364 0\n",
      "layers.2.blocks.13.attn.relative_position_index       torch.Size([144, 144])\n",
      "364 0\n",
      "layers.2.blocks.14.attn.relative_position_index       torch.Size([144, 144])\n",
      "364 0\n",
      "layers.2.blocks.15.attn.relative_position_index       torch.Size([144, 144])\n",
      "364 0\n",
      "layers.2.blocks.16.attn.relative_position_index       torch.Size([144, 144])\n",
      "364 0\n",
      "layers.2.blocks.17.attn.relative_position_index       torch.Size([144, 144])\n",
      "364 0\n",
      "layers.3.blocks.0.attn.relative_position_index       torch.Size([144, 144])\n",
      "364 0\n",
      "layers.3.blocks.1.attn.relative_position_index       torch.Size([144, 144])\n",
      "364 0\n",
      "layers.0.blocks.1.attn_mask       torch.Size([64, 144, 144])\n",
      "364 0\n",
      "layers.1.blocks.1.attn_mask       torch.Size([16, 144, 144])\n",
      "364 0\n",
      "layers.2.blocks.1.attn_mask       torch.Size([4, 144, 144])\n",
      "364 0\n",
      "layers.2.blocks.3.attn_mask       torch.Size([4, 144, 144])\n",
      "364 0\n",
      "layers.2.blocks.5.attn_mask       torch.Size([4, 144, 144])\n",
      "364 0\n",
      "layers.2.blocks.7.attn_mask       torch.Size([4, 144, 144])\n",
      "364 0\n",
      "layers.2.blocks.9.attn_mask       torch.Size([4, 144, 144])\n",
      "364 0\n",
      "layers.2.blocks.11.attn_mask       torch.Size([4, 144, 144])\n",
      "364 0\n",
      "layers.2.blocks.13.attn_mask       torch.Size([4, 144, 144])\n",
      "364 0\n",
      "layers.2.blocks.15.attn_mask       torch.Size([4, 144, 144])\n",
      "364 0\n",
      "layers.2.blocks.17.attn_mask       torch.Size([4, 144, 144])\n",
      "364 0\n",
      "layers.0.blocks.0.attn.relative_position_bias_table       torch.Size([529, 4])\n",
      "364 0\n",
      "layers.0.blocks.1.attn.relative_position_bias_table       torch.Size([529, 4])\n",
      "364 0\n",
      "layers.1.blocks.0.attn.relative_position_bias_table       torch.Size([529, 8])\n",
      "364 0\n",
      "layers.1.blocks.1.attn.relative_position_bias_table       torch.Size([529, 8])\n",
      "364 0\n",
      "layers.2.blocks.0.attn.relative_position_bias_table       torch.Size([529, 16])\n",
      "364 0\n",
      "layers.2.blocks.1.attn.relative_position_bias_table       torch.Size([529, 16])\n",
      "364 0\n",
      "layers.2.blocks.2.attn.relative_position_bias_table       torch.Size([529, 16])\n",
      "364 0\n",
      "layers.2.blocks.3.attn.relative_position_bias_table       torch.Size([529, 16])\n",
      "364 0\n",
      "layers.2.blocks.4.attn.relative_position_bias_table       torch.Size([529, 16])\n",
      "364 0\n",
      "layers.2.blocks.5.attn.relative_position_bias_table       torch.Size([529, 16])\n",
      "364 0\n",
      "layers.2.blocks.6.attn.relative_position_bias_table       torch.Size([529, 16])\n",
      "364 0\n",
      "layers.2.blocks.7.attn.relative_position_bias_table       torch.Size([529, 16])\n",
      "364 0\n",
      "layers.2.blocks.8.attn.relative_position_bias_table       torch.Size([529, 16])\n",
      "364 0\n",
      "layers.2.blocks.9.attn.relative_position_bias_table       torch.Size([529, 16])\n",
      "364 0\n",
      "layers.2.blocks.10.attn.relative_position_bias_table       torch.Size([529, 16])\n",
      "364 0\n",
      "layers.2.blocks.11.attn.relative_position_bias_table       torch.Size([529, 16])\n",
      "364 0\n",
      "layers.2.blocks.12.attn.relative_position_bias_table       torch.Size([529, 16])\n",
      "364 0\n",
      "layers.2.blocks.13.attn.relative_position_bias_table       torch.Size([529, 16])\n",
      "364 0\n",
      "layers.2.blocks.14.attn.relative_position_bias_table       torch.Size([529, 16])\n",
      "364 0\n",
      "layers.2.blocks.15.attn.relative_position_bias_table       torch.Size([529, 16])\n",
      "364 0\n",
      "layers.2.blocks.16.attn.relative_position_bias_table       torch.Size([529, 16])\n",
      "364 0\n",
      "layers.2.blocks.17.attn.relative_position_bias_table       torch.Size([529, 16])\n",
      "364 0\n",
      "layers.3.blocks.0.attn.relative_position_bias_table       torch.Size([529, 32])\n",
      "364 0\n",
      "layers.3.blocks.1.attn.relative_position_bias_table       torch.Size([529, 32])\n",
      "364 0\n",
      "layers.0.downsample.reduction.weight       torch.Size([256, 512])\n",
      "364 0\n",
      "layers.1.downsample.reduction.weight       torch.Size([512, 1024])\n",
      "364 0\n",
      "layers.2.downsample.reduction.weight       torch.Size([1024, 2048])\n",
      "364 0\n"
     ]
    }
   ],
   "source": [
    "path = r\"G:\\学习资料\\目标检测\\swin_base_patch4_window12_384.pth\"\n",
    "backbone_weight = torch.load(path)\n",
    "for name, para in backbone_weight.items():\n",
    "    backbone_weight = para\n",
    "i = 0\n",
    "for name, para in backbone_weight.items():\n",
    "    print(name, \"     \", para.size())\n",
    "    print(len(backbone_weight), i)\n",
    "#     i += 1\n",
    "# for k in list(backbone_weight.keys()):\n",
    "#     if \"layers.2\" in k:\n",
    "#         i += 1\n",
    "# print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d56995",
   "metadata": {},
   "source": [
    "## 获得backbone.backbone.patch_embed(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38fdcb37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T13:18:31.885425Z",
     "start_time": "2021-11-26T13:18:31.429618Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patch_embed.proj.weight       torch.Size([128, 3, 4, 4])\n",
      "364 0\n",
      "patch_embed.proj.bias       torch.Size([128])\n",
      "364 0\n",
      "patch_embed.norm.weight       torch.Size([128])\n",
      "364 0\n",
      "patch_embed.norm.bias       torch.Size([128])\n",
      "364 0\n",
      "layers.0.blocks.0.norm1.weight       torch.Size([128])\n",
      "364 0\n",
      "layers.0.blocks.0.norm1.bias       torch.Size([128])\n",
      "364 0\n",
      "layers.0.blocks.0.attn.qkv.weight       torch.Size([384, 128])\n",
      "364 0\n",
      "layers.0.blocks.0.attn.qkv.bias       torch.Size([384])\n",
      "364 0\n",
      "layers.0.blocks.0.attn.proj.weight       torch.Size([128, 128])\n",
      "364 0\n",
      "layers.0.blocks.0.attn.proj.bias       torch.Size([128])\n",
      "364 0\n",
      "layers.0.blocks.0.norm2.weight       torch.Size([128])\n",
      "364 0\n",
      "layers.0.blocks.0.norm2.bias       torch.Size([128])\n",
      "364 0\n",
      "layers.0.blocks.0.mlp.fc1.weight       torch.Size([512, 128])\n",
      "364 0\n",
      "layers.0.blocks.0.mlp.fc1.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.0.blocks.0.mlp.fc2.weight       torch.Size([128, 512])\n",
      "364 0\n",
      "layers.0.blocks.0.mlp.fc2.bias       torch.Size([128])\n",
      "364 0\n",
      "layers.0.blocks.1.norm1.weight       torch.Size([128])\n",
      "364 0\n",
      "layers.0.blocks.1.norm1.bias       torch.Size([128])\n",
      "364 0\n",
      "layers.0.blocks.1.attn.qkv.weight       torch.Size([384, 128])\n",
      "364 0\n",
      "layers.0.blocks.1.attn.qkv.bias       torch.Size([384])\n",
      "364 0\n",
      "layers.0.blocks.1.attn.proj.weight       torch.Size([128, 128])\n",
      "364 0\n",
      "layers.0.blocks.1.attn.proj.bias       torch.Size([128])\n",
      "364 0\n",
      "layers.0.blocks.1.norm2.weight       torch.Size([128])\n",
      "364 0\n",
      "layers.0.blocks.1.norm2.bias       torch.Size([128])\n",
      "364 0\n",
      "layers.0.blocks.1.mlp.fc1.weight       torch.Size([512, 128])\n",
      "364 0\n",
      "layers.0.blocks.1.mlp.fc1.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.0.blocks.1.mlp.fc2.weight       torch.Size([128, 512])\n",
      "364 0\n",
      "layers.0.blocks.1.mlp.fc2.bias       torch.Size([128])\n",
      "364 0\n",
      "layers.0.downsample.norm.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.0.downsample.norm.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.1.blocks.0.norm1.weight       torch.Size([256])\n",
      "364 0\n",
      "layers.1.blocks.0.norm1.bias       torch.Size([256])\n",
      "364 0\n",
      "layers.1.blocks.0.attn.qkv.weight       torch.Size([768, 256])\n",
      "364 0\n",
      "layers.1.blocks.0.attn.qkv.bias       torch.Size([768])\n",
      "364 0\n",
      "layers.1.blocks.0.attn.proj.weight       torch.Size([256, 256])\n",
      "364 0\n",
      "layers.1.blocks.0.attn.proj.bias       torch.Size([256])\n",
      "364 0\n",
      "layers.1.blocks.0.norm2.weight       torch.Size([256])\n",
      "364 0\n",
      "layers.1.blocks.0.norm2.bias       torch.Size([256])\n",
      "364 0\n",
      "layers.1.blocks.0.mlp.fc1.weight       torch.Size([1024, 256])\n",
      "364 0\n",
      "layers.1.blocks.0.mlp.fc1.bias       torch.Size([1024])\n",
      "364 0\n",
      "layers.1.blocks.0.mlp.fc2.weight       torch.Size([256, 1024])\n",
      "364 0\n",
      "layers.1.blocks.0.mlp.fc2.bias       torch.Size([256])\n",
      "364 0\n",
      "layers.1.blocks.1.norm1.weight       torch.Size([256])\n",
      "364 0\n",
      "layers.1.blocks.1.norm1.bias       torch.Size([256])\n",
      "364 0\n",
      "layers.1.blocks.1.attn.qkv.weight       torch.Size([768, 256])\n",
      "364 0\n",
      "layers.1.blocks.1.attn.qkv.bias       torch.Size([768])\n",
      "364 0\n",
      "layers.1.blocks.1.attn.proj.weight       torch.Size([256, 256])\n",
      "364 0\n",
      "layers.1.blocks.1.attn.proj.bias       torch.Size([256])\n",
      "364 0\n",
      "layers.1.blocks.1.norm2.weight       torch.Size([256])\n",
      "364 0\n",
      "layers.1.blocks.1.norm2.bias       torch.Size([256])\n",
      "364 0\n",
      "layers.1.blocks.1.mlp.fc1.weight       torch.Size([1024, 256])\n",
      "364 0\n",
      "layers.1.blocks.1.mlp.fc1.bias       torch.Size([1024])\n",
      "364 0\n",
      "layers.1.blocks.1.mlp.fc2.weight       torch.Size([256, 1024])\n",
      "364 0\n",
      "layers.1.blocks.1.mlp.fc2.bias       torch.Size([256])\n",
      "364 0\n",
      "layers.1.downsample.norm.weight       torch.Size([1024])\n",
      "364 0\n",
      "layers.1.downsample.norm.bias       torch.Size([1024])\n",
      "364 0\n",
      "layers.2.blocks.0.norm1.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.0.norm1.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.0.attn.qkv.weight       torch.Size([1536, 512])\n",
      "364 0\n",
      "layers.2.blocks.0.attn.qkv.bias       torch.Size([1536])\n",
      "364 0\n",
      "layers.2.blocks.0.attn.proj.weight       torch.Size([512, 512])\n",
      "364 0\n",
      "layers.2.blocks.0.attn.proj.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.0.norm2.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.0.norm2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.0.mlp.fc1.weight       torch.Size([2048, 512])\n",
      "364 0\n",
      "layers.2.blocks.0.mlp.fc1.bias       torch.Size([2048])\n",
      "364 0\n",
      "layers.2.blocks.0.mlp.fc2.weight       torch.Size([512, 2048])\n",
      "364 0\n",
      "layers.2.blocks.0.mlp.fc2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.1.norm1.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.1.norm1.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.1.attn.qkv.weight       torch.Size([1536, 512])\n",
      "364 0\n",
      "layers.2.blocks.1.attn.qkv.bias       torch.Size([1536])\n",
      "364 0\n",
      "layers.2.blocks.1.attn.proj.weight       torch.Size([512, 512])\n",
      "364 0\n",
      "layers.2.blocks.1.attn.proj.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.1.norm2.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.1.norm2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.1.mlp.fc1.weight       torch.Size([2048, 512])\n",
      "364 0\n",
      "layers.2.blocks.1.mlp.fc1.bias       torch.Size([2048])\n",
      "364 0\n",
      "layers.2.blocks.1.mlp.fc2.weight       torch.Size([512, 2048])\n",
      "364 0\n",
      "layers.2.blocks.1.mlp.fc2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.2.norm1.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.2.norm1.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.2.attn.qkv.weight       torch.Size([1536, 512])\n",
      "364 0\n",
      "layers.2.blocks.2.attn.qkv.bias       torch.Size([1536])\n",
      "364 0\n",
      "layers.2.blocks.2.attn.proj.weight       torch.Size([512, 512])\n",
      "364 0\n",
      "layers.2.blocks.2.attn.proj.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.2.norm2.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.2.norm2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.2.mlp.fc1.weight       torch.Size([2048, 512])\n",
      "364 0\n",
      "layers.2.blocks.2.mlp.fc1.bias       torch.Size([2048])\n",
      "364 0\n",
      "layers.2.blocks.2.mlp.fc2.weight       torch.Size([512, 2048])\n",
      "364 0\n",
      "layers.2.blocks.2.mlp.fc2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.3.norm1.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.3.norm1.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.3.attn.qkv.weight       torch.Size([1536, 512])\n",
      "364 0\n",
      "layers.2.blocks.3.attn.qkv.bias       torch.Size([1536])\n",
      "364 0\n",
      "layers.2.blocks.3.attn.proj.weight       torch.Size([512, 512])\n",
      "364 0\n",
      "layers.2.blocks.3.attn.proj.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.3.norm2.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.3.norm2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.3.mlp.fc1.weight       torch.Size([2048, 512])\n",
      "364 0\n",
      "layers.2.blocks.3.mlp.fc1.bias       torch.Size([2048])\n",
      "364 0\n",
      "layers.2.blocks.3.mlp.fc2.weight       torch.Size([512, 2048])\n",
      "364 0\n",
      "layers.2.blocks.3.mlp.fc2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.4.norm1.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.4.norm1.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.4.attn.qkv.weight       torch.Size([1536, 512])\n",
      "364 0\n",
      "layers.2.blocks.4.attn.qkv.bias       torch.Size([1536])\n",
      "364 0\n",
      "layers.2.blocks.4.attn.proj.weight       torch.Size([512, 512])\n",
      "364 0\n",
      "layers.2.blocks.4.attn.proj.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.4.norm2.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.4.norm2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.4.mlp.fc1.weight       torch.Size([2048, 512])\n",
      "364 0\n",
      "layers.2.blocks.4.mlp.fc1.bias       torch.Size([2048])\n",
      "364 0\n",
      "layers.2.blocks.4.mlp.fc2.weight       torch.Size([512, 2048])\n",
      "364 0\n",
      "layers.2.blocks.4.mlp.fc2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.5.norm1.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.5.norm1.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.5.attn.qkv.weight       torch.Size([1536, 512])\n",
      "364 0\n",
      "layers.2.blocks.5.attn.qkv.bias       torch.Size([1536])\n",
      "364 0\n",
      "layers.2.blocks.5.attn.proj.weight       torch.Size([512, 512])\n",
      "364 0\n",
      "layers.2.blocks.5.attn.proj.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.5.norm2.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.5.norm2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.5.mlp.fc1.weight       torch.Size([2048, 512])\n",
      "364 0\n",
      "layers.2.blocks.5.mlp.fc1.bias       torch.Size([2048])\n",
      "364 0\n",
      "layers.2.blocks.5.mlp.fc2.weight       torch.Size([512, 2048])\n",
      "364 0\n",
      "layers.2.blocks.5.mlp.fc2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.6.norm1.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.6.norm1.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.6.attn.qkv.weight       torch.Size([1536, 512])\n",
      "364 0\n",
      "layers.2.blocks.6.attn.qkv.bias       torch.Size([1536])\n",
      "364 0\n",
      "layers.2.blocks.6.attn.proj.weight       torch.Size([512, 512])\n",
      "364 0\n",
      "layers.2.blocks.6.attn.proj.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.6.norm2.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.6.norm2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.6.mlp.fc1.weight       torch.Size([2048, 512])\n",
      "364 0\n",
      "layers.2.blocks.6.mlp.fc1.bias       torch.Size([2048])\n",
      "364 0\n",
      "layers.2.blocks.6.mlp.fc2.weight       torch.Size([512, 2048])\n",
      "364 0\n",
      "layers.2.blocks.6.mlp.fc2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.7.norm1.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.7.norm1.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.7.attn.qkv.weight       torch.Size([1536, 512])\n",
      "364 0\n",
      "layers.2.blocks.7.attn.qkv.bias       torch.Size([1536])\n",
      "364 0\n",
      "layers.2.blocks.7.attn.proj.weight       torch.Size([512, 512])\n",
      "364 0\n",
      "layers.2.blocks.7.attn.proj.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.7.norm2.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.7.norm2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.7.mlp.fc1.weight       torch.Size([2048, 512])\n",
      "364 0\n",
      "layers.2.blocks.7.mlp.fc1.bias       torch.Size([2048])\n",
      "364 0\n",
      "layers.2.blocks.7.mlp.fc2.weight       torch.Size([512, 2048])\n",
      "364 0\n",
      "layers.2.blocks.7.mlp.fc2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.8.norm1.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.8.norm1.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.8.attn.qkv.weight       torch.Size([1536, 512])\n",
      "364 0\n",
      "layers.2.blocks.8.attn.qkv.bias       torch.Size([1536])\n",
      "364 0\n",
      "layers.2.blocks.8.attn.proj.weight       torch.Size([512, 512])\n",
      "364 0\n",
      "layers.2.blocks.8.attn.proj.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.8.norm2.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.8.norm2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.8.mlp.fc1.weight       torch.Size([2048, 512])\n",
      "364 0\n",
      "layers.2.blocks.8.mlp.fc1.bias       torch.Size([2048])\n",
      "364 0\n",
      "layers.2.blocks.8.mlp.fc2.weight       torch.Size([512, 2048])\n",
      "364 0\n",
      "layers.2.blocks.8.mlp.fc2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.9.norm1.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.9.norm1.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.9.attn.qkv.weight       torch.Size([1536, 512])\n",
      "364 0\n",
      "layers.2.blocks.9.attn.qkv.bias       torch.Size([1536])\n",
      "364 0\n",
      "layers.2.blocks.9.attn.proj.weight       torch.Size([512, 512])\n",
      "364 0\n",
      "layers.2.blocks.9.attn.proj.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.9.norm2.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.9.norm2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.9.mlp.fc1.weight       torch.Size([2048, 512])\n",
      "364 0\n",
      "layers.2.blocks.9.mlp.fc1.bias       torch.Size([2048])\n",
      "364 0\n",
      "layers.2.blocks.9.mlp.fc2.weight       torch.Size([512, 2048])\n",
      "364 0\n",
      "layers.2.blocks.9.mlp.fc2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.10.norm1.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.10.norm1.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.10.attn.qkv.weight       torch.Size([1536, 512])\n",
      "364 0\n",
      "layers.2.blocks.10.attn.qkv.bias       torch.Size([1536])\n",
      "364 0\n",
      "layers.2.blocks.10.attn.proj.weight       torch.Size([512, 512])\n",
      "364 0\n",
      "layers.2.blocks.10.attn.proj.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.10.norm2.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.10.norm2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.10.mlp.fc1.weight       torch.Size([2048, 512])\n",
      "364 0\n",
      "layers.2.blocks.10.mlp.fc1.bias       torch.Size([2048])\n",
      "364 0\n",
      "layers.2.blocks.10.mlp.fc2.weight       torch.Size([512, 2048])\n",
      "364 0\n",
      "layers.2.blocks.10.mlp.fc2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.11.norm1.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.11.norm1.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.11.attn.qkv.weight       torch.Size([1536, 512])\n",
      "364 0\n",
      "layers.2.blocks.11.attn.qkv.bias       torch.Size([1536])\n",
      "364 0\n",
      "layers.2.blocks.11.attn.proj.weight       torch.Size([512, 512])\n",
      "364 0\n",
      "layers.2.blocks.11.attn.proj.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.11.norm2.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.11.norm2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.11.mlp.fc1.weight       torch.Size([2048, 512])\n",
      "364 0\n",
      "layers.2.blocks.11.mlp.fc1.bias       torch.Size([2048])\n",
      "364 0\n",
      "layers.2.blocks.11.mlp.fc2.weight       torch.Size([512, 2048])\n",
      "364 0\n",
      "layers.2.blocks.11.mlp.fc2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.12.norm1.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.12.norm1.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.12.attn.qkv.weight       torch.Size([1536, 512])\n",
      "364 0\n",
      "layers.2.blocks.12.attn.qkv.bias       torch.Size([1536])\n",
      "364 0\n",
      "layers.2.blocks.12.attn.proj.weight       torch.Size([512, 512])\n",
      "364 0\n",
      "layers.2.blocks.12.attn.proj.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.12.norm2.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.12.norm2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.12.mlp.fc1.weight       torch.Size([2048, 512])\n",
      "364 0\n",
      "layers.2.blocks.12.mlp.fc1.bias       torch.Size([2048])\n",
      "364 0\n",
      "layers.2.blocks.12.mlp.fc2.weight       torch.Size([512, 2048])\n",
      "364 0\n",
      "layers.2.blocks.12.mlp.fc2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.13.norm1.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.13.norm1.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.13.attn.qkv.weight       torch.Size([1536, 512])\n",
      "364 0\n",
      "layers.2.blocks.13.attn.qkv.bias       torch.Size([1536])\n",
      "364 0\n",
      "layers.2.blocks.13.attn.proj.weight       torch.Size([512, 512])\n",
      "364 0\n",
      "layers.2.blocks.13.attn.proj.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.13.norm2.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.13.norm2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.13.mlp.fc1.weight       torch.Size([2048, 512])\n",
      "364 0\n",
      "layers.2.blocks.13.mlp.fc1.bias       torch.Size([2048])\n",
      "364 0\n",
      "layers.2.blocks.13.mlp.fc2.weight       torch.Size([512, 2048])\n",
      "364 0\n",
      "layers.2.blocks.13.mlp.fc2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.14.norm1.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.14.norm1.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.14.attn.qkv.weight       torch.Size([1536, 512])\n",
      "364 0\n",
      "layers.2.blocks.14.attn.qkv.bias       torch.Size([1536])\n",
      "364 0\n",
      "layers.2.blocks.14.attn.proj.weight       torch.Size([512, 512])\n",
      "364 0\n",
      "layers.2.blocks.14.attn.proj.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.14.norm2.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.14.norm2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.14.mlp.fc1.weight       torch.Size([2048, 512])\n",
      "364 0\n",
      "layers.2.blocks.14.mlp.fc1.bias       torch.Size([2048])\n",
      "364 0\n",
      "layers.2.blocks.14.mlp.fc2.weight       torch.Size([512, 2048])\n",
      "364 0\n",
      "layers.2.blocks.14.mlp.fc2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.15.norm1.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.15.norm1.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.15.attn.qkv.weight       torch.Size([1536, 512])\n",
      "364 0\n",
      "layers.2.blocks.15.attn.qkv.bias       torch.Size([1536])\n",
      "364 0\n",
      "layers.2.blocks.15.attn.proj.weight       torch.Size([512, 512])\n",
      "364 0\n",
      "layers.2.blocks.15.attn.proj.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.15.norm2.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.15.norm2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.15.mlp.fc1.weight       torch.Size([2048, 512])\n",
      "364 0\n",
      "layers.2.blocks.15.mlp.fc1.bias       torch.Size([2048])\n",
      "364 0\n",
      "layers.2.blocks.15.mlp.fc2.weight       torch.Size([512, 2048])\n",
      "364 0\n",
      "layers.2.blocks.15.mlp.fc2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.16.norm1.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.16.norm1.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.16.attn.qkv.weight       torch.Size([1536, 512])\n",
      "364 0\n",
      "layers.2.blocks.16.attn.qkv.bias       torch.Size([1536])\n",
      "364 0\n",
      "layers.2.blocks.16.attn.proj.weight       torch.Size([512, 512])\n",
      "364 0\n",
      "layers.2.blocks.16.attn.proj.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.16.norm2.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.16.norm2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.16.mlp.fc1.weight       torch.Size([2048, 512])\n",
      "364 0\n",
      "layers.2.blocks.16.mlp.fc1.bias       torch.Size([2048])\n",
      "364 0\n",
      "layers.2.blocks.16.mlp.fc2.weight       torch.Size([512, 2048])\n",
      "364 0\n",
      "layers.2.blocks.16.mlp.fc2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.17.norm1.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.17.norm1.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.17.attn.qkv.weight       torch.Size([1536, 512])\n",
      "364 0\n",
      "layers.2.blocks.17.attn.qkv.bias       torch.Size([1536])\n",
      "364 0\n",
      "layers.2.blocks.17.attn.proj.weight       torch.Size([512, 512])\n",
      "364 0\n",
      "layers.2.blocks.17.attn.proj.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.17.norm2.weight       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.17.norm2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.blocks.17.mlp.fc1.weight       torch.Size([2048, 512])\n",
      "364 0\n",
      "layers.2.blocks.17.mlp.fc1.bias       torch.Size([2048])\n",
      "364 0\n",
      "layers.2.blocks.17.mlp.fc2.weight       torch.Size([512, 2048])\n",
      "364 0\n",
      "layers.2.blocks.17.mlp.fc2.bias       torch.Size([512])\n",
      "364 0\n",
      "layers.2.downsample.norm.weight       torch.Size([2048])\n",
      "364 0\n",
      "layers.2.downsample.norm.bias       torch.Size([2048])\n",
      "364 0\n",
      "layers.3.blocks.0.norm1.weight       torch.Size([1024])\n",
      "364 0\n",
      "layers.3.blocks.0.norm1.bias       torch.Size([1024])\n",
      "364 0\n",
      "layers.3.blocks.0.attn.qkv.weight       torch.Size([3072, 1024])\n",
      "364 0\n",
      "layers.3.blocks.0.attn.qkv.bias       torch.Size([3072])\n",
      "364 0\n",
      "layers.3.blocks.0.attn.proj.weight       torch.Size([1024, 1024])\n",
      "364 0\n",
      "layers.3.blocks.0.attn.proj.bias       torch.Size([1024])\n",
      "364 0\n",
      "layers.3.blocks.0.norm2.weight       torch.Size([1024])\n",
      "364 0\n",
      "layers.3.blocks.0.norm2.bias       torch.Size([1024])\n",
      "364 0\n",
      "layers.3.blocks.0.mlp.fc1.weight       torch.Size([4096, 1024])\n",
      "364 0\n",
      "layers.3.blocks.0.mlp.fc1.bias       torch.Size([4096])\n",
      "364 0\n",
      "layers.3.blocks.0.mlp.fc2.weight       torch.Size([1024, 4096])\n",
      "364 0\n",
      "layers.3.blocks.0.mlp.fc2.bias       torch.Size([1024])\n",
      "364 0\n",
      "layers.3.blocks.1.norm1.weight       torch.Size([1024])\n",
      "364 0\n",
      "layers.3.blocks.1.norm1.bias       torch.Size([1024])\n",
      "364 0\n",
      "layers.3.blocks.1.attn.qkv.weight       torch.Size([3072, 1024])\n",
      "364 0\n",
      "layers.3.blocks.1.attn.qkv.bias       torch.Size([3072])\n",
      "364 0\n",
      "layers.3.blocks.1.attn.proj.weight       torch.Size([1024, 1024])\n",
      "364 0\n",
      "layers.3.blocks.1.attn.proj.bias       torch.Size([1024])\n",
      "364 0\n",
      "layers.3.blocks.1.norm2.weight       torch.Size([1024])\n",
      "364 0\n",
      "layers.3.blocks.1.norm2.bias       torch.Size([1024])\n",
      "364 0\n",
      "layers.3.blocks.1.mlp.fc1.weight       torch.Size([4096, 1024])\n",
      "364 0\n",
      "layers.3.blocks.1.mlp.fc1.bias       torch.Size([4096])\n",
      "364 0\n",
      "layers.3.blocks.1.mlp.fc2.weight       torch.Size([1024, 4096])\n",
      "364 0\n",
      "layers.3.blocks.1.mlp.fc2.bias       torch.Size([1024])\n",
      "364 0\n",
      "norm.weight       torch.Size([1024])\n",
      "364 0\n",
      "norm.bias       torch.Size([1024])\n",
      "364 0\n",
      "head.weight       torch.Size([1000, 1024])\n",
      "364 0\n",
      "head.bias       torch.Size([1000])\n",
      "364 0\n",
      "layers.0.blocks.0.attn.relative_position_index       torch.Size([144, 144])\n",
      "364 0\n",
      "layers.0.blocks.1.attn.relative_position_index       torch.Size([144, 144])\n",
      "364 0\n",
      "layers.1.blocks.0.attn.relative_position_index       torch.Size([144, 144])\n",
      "364 0\n",
      "layers.1.blocks.1.attn.relative_position_index       torch.Size([144, 144])\n",
      "364 0\n",
      "layers.2.blocks.0.attn.relative_position_index       torch.Size([144, 144])\n",
      "364 0\n",
      "layers.2.blocks.1.attn.relative_position_index       torch.Size([144, 144])\n",
      "364 0\n",
      "layers.2.blocks.2.attn.relative_position_index       torch.Size([144, 144])\n",
      "364 0\n",
      "layers.2.blocks.3.attn.relative_position_index       torch.Size([144, 144])\n",
      "364 0\n",
      "layers.2.blocks.4.attn.relative_position_index       torch.Size([144, 144])\n",
      "364 0\n",
      "layers.2.blocks.5.attn.relative_position_index       torch.Size([144, 144])\n",
      "364 0\n",
      "layers.2.blocks.6.attn.relative_position_index       torch.Size([144, 144])\n",
      "364 0\n",
      "layers.2.blocks.7.attn.relative_position_index       torch.Size([144, 144])\n",
      "364 0\n",
      "layers.2.blocks.8.attn.relative_position_index       torch.Size([144, 144])\n",
      "364 0\n",
      "layers.2.blocks.9.attn.relative_position_index       torch.Size([144, 144])\n",
      "364 0\n",
      "layers.2.blocks.10.attn.relative_position_index       torch.Size([144, 144])\n",
      "364 0\n",
      "layers.2.blocks.11.attn.relative_position_index       torch.Size([144, 144])\n",
      "364 0\n",
      "layers.2.blocks.12.attn.relative_position_index       torch.Size([144, 144])\n",
      "364 0\n",
      "layers.2.blocks.13.attn.relative_position_index       torch.Size([144, 144])\n",
      "364 0\n",
      "layers.2.blocks.14.attn.relative_position_index       torch.Size([144, 144])\n",
      "364 0\n",
      "layers.2.blocks.15.attn.relative_position_index       torch.Size([144, 144])\n",
      "364 0\n",
      "layers.2.blocks.16.attn.relative_position_index       torch.Size([144, 144])\n",
      "364 0\n",
      "layers.2.blocks.17.attn.relative_position_index       torch.Size([144, 144])\n",
      "364 0\n",
      "layers.3.blocks.0.attn.relative_position_index       torch.Size([144, 144])\n",
      "364 0\n",
      "layers.3.blocks.1.attn.relative_position_index       torch.Size([144, 144])\n",
      "364 0\n",
      "layers.0.blocks.1.attn_mask       torch.Size([64, 144, 144])\n",
      "364 0\n",
      "layers.1.blocks.1.attn_mask       torch.Size([16, 144, 144])\n",
      "364 0\n",
      "layers.2.blocks.1.attn_mask       torch.Size([4, 144, 144])\n",
      "364 0\n",
      "layers.2.blocks.3.attn_mask       torch.Size([4, 144, 144])\n",
      "364 0\n",
      "layers.2.blocks.5.attn_mask       torch.Size([4, 144, 144])\n",
      "364 0\n",
      "layers.2.blocks.7.attn_mask       torch.Size([4, 144, 144])\n",
      "364 0\n",
      "layers.2.blocks.9.attn_mask       torch.Size([4, 144, 144])\n",
      "364 0\n",
      "layers.2.blocks.11.attn_mask       torch.Size([4, 144, 144])\n",
      "364 0\n",
      "layers.2.blocks.13.attn_mask       torch.Size([4, 144, 144])\n",
      "364 0\n",
      "layers.2.blocks.15.attn_mask       torch.Size([4, 144, 144])\n",
      "364 0\n",
      "layers.2.blocks.17.attn_mask       torch.Size([4, 144, 144])\n",
      "364 0\n",
      "layers.0.blocks.0.attn.relative_position_bias_table       torch.Size([529, 4])\n",
      "364 0\n",
      "layers.0.blocks.1.attn.relative_position_bias_table       torch.Size([529, 4])\n",
      "364 0\n",
      "layers.1.blocks.0.attn.relative_position_bias_table       torch.Size([529, 8])\n",
      "364 0\n",
      "layers.1.blocks.1.attn.relative_position_bias_table       torch.Size([529, 8])\n",
      "364 0\n",
      "layers.2.blocks.0.attn.relative_position_bias_table       torch.Size([529, 16])\n",
      "364 0\n",
      "layers.2.blocks.1.attn.relative_position_bias_table       torch.Size([529, 16])\n",
      "364 0\n",
      "layers.2.blocks.2.attn.relative_position_bias_table       torch.Size([529, 16])\n",
      "364 0\n",
      "layers.2.blocks.3.attn.relative_position_bias_table       torch.Size([529, 16])\n",
      "364 0\n",
      "layers.2.blocks.4.attn.relative_position_bias_table       torch.Size([529, 16])\n",
      "364 0\n",
      "layers.2.blocks.5.attn.relative_position_bias_table       torch.Size([529, 16])\n",
      "364 0\n",
      "layers.2.blocks.6.attn.relative_position_bias_table       torch.Size([529, 16])\n",
      "364 0\n",
      "layers.2.blocks.7.attn.relative_position_bias_table       torch.Size([529, 16])\n",
      "364 0\n",
      "layers.2.blocks.8.attn.relative_position_bias_table       torch.Size([529, 16])\n",
      "364 0\n",
      "layers.2.blocks.9.attn.relative_position_bias_table       torch.Size([529, 16])\n",
      "364 0\n",
      "layers.2.blocks.10.attn.relative_position_bias_table       torch.Size([529, 16])\n",
      "364 0\n",
      "layers.2.blocks.11.attn.relative_position_bias_table       torch.Size([529, 16])\n",
      "364 0\n",
      "layers.2.blocks.12.attn.relative_position_bias_table       torch.Size([529, 16])\n",
      "364 0\n",
      "layers.2.blocks.13.attn.relative_position_bias_table       torch.Size([529, 16])\n",
      "364 0\n",
      "layers.2.blocks.14.attn.relative_position_bias_table       torch.Size([529, 16])\n",
      "364 0\n",
      "layers.2.blocks.15.attn.relative_position_bias_table       torch.Size([529, 16])\n",
      "364 0\n",
      "layers.2.blocks.16.attn.relative_position_bias_table       torch.Size([529, 16])\n",
      "364 0\n",
      "layers.2.blocks.17.attn.relative_position_bias_table       torch.Size([529, 16])\n",
      "364 0\n",
      "layers.3.blocks.0.attn.relative_position_bias_table       torch.Size([529, 32])\n",
      "364 0\n",
      "layers.3.blocks.1.attn.relative_position_bias_table       torch.Size([529, 32])\n",
      "364 0\n",
      "layers.0.downsample.reduction.weight       torch.Size([256, 512])\n",
      "364 0\n",
      "layers.1.downsample.reduction.weight       torch.Size([512, 1024])\n",
      "364 0\n",
      "layers.2.downsample.reduction.weight       torch.Size([1024, 2048])\n",
      "364 0\n"
     ]
    }
   ],
   "source": [
    "path = r\"G:\\学习资料\\目标检测\\swin_base_patch4_window12_384.pth\"\n",
    "backbone_weight = torch.load(path)\n",
    "for name, para in backbone_weight.items():\n",
    "    backbone_weight = para\n",
    "i = 0\n",
    "\n",
    "temp1 = collections.OrderedDict()\n",
    "for k in list(backbone_weight.keys()):\n",
    "    if \"patch_embed\" in k:\n",
    "        new_name = \"backbone.backbone.\" + k\n",
    "        temp1.update({new_name: backbone_weight[k]})\n",
    "#         i += 1\n",
    "#         del no_backbone_weight[k]\n",
    "# print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fb21773",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T13:18:31.901363Z",
     "start_time": "2021-11-26T13:18:31.886380Z"
    }
   },
   "outputs": [],
   "source": [
    "# for k, v in temp6.items():\n",
    "#     print(k,  v.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199d60a2",
   "metadata": {},
   "source": [
    "## 获得backbone.backbone.layers（0-3）：349"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490149ed",
   "metadata": {},
   "source": [
    "## layers.0(28 = 32-3(downsample）-1(attn_mask))  (我们保留了attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bbff7fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T13:18:32.156978Z",
     "start_time": "2021-11-26T13:18:31.902338Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "path = r\"G:\\学习资料\\目标检测\\swin_base_patch4_window12_384.pth\"\n",
    "backbone_weight = torch.load(path)\n",
    "for name, para in backbone_weight.items():\n",
    "    backbone_weight = para\n",
    "\n",
    "i = 0\n",
    "temp2 = collections.OrderedDict()\n",
    "for k in list(backbone_weight.keys()):\n",
    "    if \"layers.0.block\" in k:\n",
    "        new_name = \"backbone.backbone.\" + k\n",
    "#         print(k, backbone_weight[k].size())\n",
    "        temp2.update({new_name:backbone_weight[k]})\n",
    "        i += 1\n",
    "\n",
    "print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78f6ca1",
   "metadata": {},
   "source": [
    "## layers.1(31=28+3)(保留了attn_mask，实际为32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e166df8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T13:18:32.423620Z",
     "start_time": "2021-11-26T13:18:32.159686Z"
    }
   },
   "outputs": [],
   "source": [
    "path = r\"G:\\学习资料\\目标检测\\swin_base_patch4_window12_384.pth\"\n",
    "backbone_weight = torch.load(path)\n",
    "for name, para in backbone_weight.items():\n",
    "    backbone_weight = para\n",
    "\n",
    "i = 0\n",
    "temp3 = collections.OrderedDict()\n",
    "for k in list(backbone_weight.keys()):\n",
    "    if \"layers.0.downsample\" in k:\n",
    "        p = k.replace(\"layers.0\", \"layers.1\")\n",
    "        new_name = \"backbone.backbone.\" + p\n",
    "        temp3.update({new_name:backbone_weight[k]})\n",
    "    if \"layers.1.blocks\" in k:\n",
    "        new_name = \"backbone.backbone.\" + k\n",
    "        temp3.update({new_name:backbone_weight[k]})\n",
    "#         i += 1\n",
    "#         new_name = \"backbone.backbone.\" + k\n",
    "#         print(k, backbone_weight[k].size())\n",
    "#         temp2.update({new_name:backbone_weight[k]})\n",
    "#         i += 1\n",
    "\n",
    "# print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0aa515",
   "metadata": {},
   "source": [
    "## layers.2(255=3+14 * 18) （保留了attn_mask，实际为264）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10697813",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T13:18:32.720783Z",
     "start_time": "2021-11-26T13:18:32.425572Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264\n"
     ]
    }
   ],
   "source": [
    "path = r\"G:\\学习资料\\目标检测\\swin_base_patch4_window12_384.pth\"\n",
    "backbone_weight = torch.load(path)\n",
    "for name, para in backbone_weight.items():\n",
    "    backbone_weight = para\n",
    "\n",
    "i = 0\n",
    "temp4 = collections.OrderedDict()\n",
    "for k in list(backbone_weight.keys()):\n",
    "    if \"layers.1.downsample\" in k:\n",
    "        p = k.replace(\"layers.1\", \"layers.2\")\n",
    "        new_name = \"backbone.backbone.\" + p\n",
    "        temp4.update({new_name:backbone_weight[k]})\n",
    "        i += 1\n",
    "    if \"layers.2.blocks\" in k:\n",
    "        new_name = \"backbone.backbone.\" + k\n",
    "        temp4.update({new_name:backbone_weight[k]})\n",
    "        i += 1\n",
    "#         new_name = \"backbone.backbone.\" + k\n",
    "#         print(k, backbone_weight[k].size())\n",
    "#         temp2.update({new_name:backbone_weight[k]})\n",
    "#         i += 1\n",
    "\n",
    "print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "526dfd39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T13:18:32.751745Z",
     "start_time": "2021-11-26T13:18:32.721782Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backbone.backbone.layers.2.downsample.norm.weight torch.Size([1024])\n",
      "backbone.backbone.layers.2.downsample.norm.bias torch.Size([1024])\n",
      "backbone.backbone.layers.2.blocks.0.norm1.weight torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.0.norm1.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.0.attn.qkv.weight torch.Size([1536, 512])\n",
      "backbone.backbone.layers.2.blocks.0.attn.qkv.bias torch.Size([1536])\n",
      "backbone.backbone.layers.2.blocks.0.attn.proj.weight torch.Size([512, 512])\n",
      "backbone.backbone.layers.2.blocks.0.attn.proj.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.0.norm2.weight torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.0.norm2.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.0.mlp.fc1.weight torch.Size([2048, 512])\n",
      "backbone.backbone.layers.2.blocks.0.mlp.fc1.bias torch.Size([2048])\n",
      "backbone.backbone.layers.2.blocks.0.mlp.fc2.weight torch.Size([512, 2048])\n",
      "backbone.backbone.layers.2.blocks.0.mlp.fc2.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.1.norm1.weight torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.1.norm1.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.1.attn.qkv.weight torch.Size([1536, 512])\n",
      "backbone.backbone.layers.2.blocks.1.attn.qkv.bias torch.Size([1536])\n",
      "backbone.backbone.layers.2.blocks.1.attn.proj.weight torch.Size([512, 512])\n",
      "backbone.backbone.layers.2.blocks.1.attn.proj.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.1.norm2.weight torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.1.norm2.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.1.mlp.fc1.weight torch.Size([2048, 512])\n",
      "backbone.backbone.layers.2.blocks.1.mlp.fc1.bias torch.Size([2048])\n",
      "backbone.backbone.layers.2.blocks.1.mlp.fc2.weight torch.Size([512, 2048])\n",
      "backbone.backbone.layers.2.blocks.1.mlp.fc2.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.2.norm1.weight torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.2.norm1.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.2.attn.qkv.weight torch.Size([1536, 512])\n",
      "backbone.backbone.layers.2.blocks.2.attn.qkv.bias torch.Size([1536])\n",
      "backbone.backbone.layers.2.blocks.2.attn.proj.weight torch.Size([512, 512])\n",
      "backbone.backbone.layers.2.blocks.2.attn.proj.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.2.norm2.weight torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.2.norm2.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.2.mlp.fc1.weight torch.Size([2048, 512])\n",
      "backbone.backbone.layers.2.blocks.2.mlp.fc1.bias torch.Size([2048])\n",
      "backbone.backbone.layers.2.blocks.2.mlp.fc2.weight torch.Size([512, 2048])\n",
      "backbone.backbone.layers.2.blocks.2.mlp.fc2.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.3.norm1.weight torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.3.norm1.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.3.attn.qkv.weight torch.Size([1536, 512])\n",
      "backbone.backbone.layers.2.blocks.3.attn.qkv.bias torch.Size([1536])\n",
      "backbone.backbone.layers.2.blocks.3.attn.proj.weight torch.Size([512, 512])\n",
      "backbone.backbone.layers.2.blocks.3.attn.proj.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.3.norm2.weight torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.3.norm2.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.3.mlp.fc1.weight torch.Size([2048, 512])\n",
      "backbone.backbone.layers.2.blocks.3.mlp.fc1.bias torch.Size([2048])\n",
      "backbone.backbone.layers.2.blocks.3.mlp.fc2.weight torch.Size([512, 2048])\n",
      "backbone.backbone.layers.2.blocks.3.mlp.fc2.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.4.norm1.weight torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.4.norm1.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.4.attn.qkv.weight torch.Size([1536, 512])\n",
      "backbone.backbone.layers.2.blocks.4.attn.qkv.bias torch.Size([1536])\n",
      "backbone.backbone.layers.2.blocks.4.attn.proj.weight torch.Size([512, 512])\n",
      "backbone.backbone.layers.2.blocks.4.attn.proj.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.4.norm2.weight torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.4.norm2.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.4.mlp.fc1.weight torch.Size([2048, 512])\n",
      "backbone.backbone.layers.2.blocks.4.mlp.fc1.bias torch.Size([2048])\n",
      "backbone.backbone.layers.2.blocks.4.mlp.fc2.weight torch.Size([512, 2048])\n",
      "backbone.backbone.layers.2.blocks.4.mlp.fc2.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.5.norm1.weight torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.5.norm1.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.5.attn.qkv.weight torch.Size([1536, 512])\n",
      "backbone.backbone.layers.2.blocks.5.attn.qkv.bias torch.Size([1536])\n",
      "backbone.backbone.layers.2.blocks.5.attn.proj.weight torch.Size([512, 512])\n",
      "backbone.backbone.layers.2.blocks.5.attn.proj.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.5.norm2.weight torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.5.norm2.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.5.mlp.fc1.weight torch.Size([2048, 512])\n",
      "backbone.backbone.layers.2.blocks.5.mlp.fc1.bias torch.Size([2048])\n",
      "backbone.backbone.layers.2.blocks.5.mlp.fc2.weight torch.Size([512, 2048])\n",
      "backbone.backbone.layers.2.blocks.5.mlp.fc2.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.6.norm1.weight torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.6.norm1.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.6.attn.qkv.weight torch.Size([1536, 512])\n",
      "backbone.backbone.layers.2.blocks.6.attn.qkv.bias torch.Size([1536])\n",
      "backbone.backbone.layers.2.blocks.6.attn.proj.weight torch.Size([512, 512])\n",
      "backbone.backbone.layers.2.blocks.6.attn.proj.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.6.norm2.weight torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.6.norm2.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.6.mlp.fc1.weight torch.Size([2048, 512])\n",
      "backbone.backbone.layers.2.blocks.6.mlp.fc1.bias torch.Size([2048])\n",
      "backbone.backbone.layers.2.blocks.6.mlp.fc2.weight torch.Size([512, 2048])\n",
      "backbone.backbone.layers.2.blocks.6.mlp.fc2.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.7.norm1.weight torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.7.norm1.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.7.attn.qkv.weight torch.Size([1536, 512])\n",
      "backbone.backbone.layers.2.blocks.7.attn.qkv.bias torch.Size([1536])\n",
      "backbone.backbone.layers.2.blocks.7.attn.proj.weight torch.Size([512, 512])\n",
      "backbone.backbone.layers.2.blocks.7.attn.proj.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.7.norm2.weight torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.7.norm2.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.7.mlp.fc1.weight torch.Size([2048, 512])\n",
      "backbone.backbone.layers.2.blocks.7.mlp.fc1.bias torch.Size([2048])\n",
      "backbone.backbone.layers.2.blocks.7.mlp.fc2.weight torch.Size([512, 2048])\n",
      "backbone.backbone.layers.2.blocks.7.mlp.fc2.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.8.norm1.weight torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.8.norm1.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.8.attn.qkv.weight torch.Size([1536, 512])\n",
      "backbone.backbone.layers.2.blocks.8.attn.qkv.bias torch.Size([1536])\n",
      "backbone.backbone.layers.2.blocks.8.attn.proj.weight torch.Size([512, 512])\n",
      "backbone.backbone.layers.2.blocks.8.attn.proj.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.8.norm2.weight torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.8.norm2.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.8.mlp.fc1.weight torch.Size([2048, 512])\n",
      "backbone.backbone.layers.2.blocks.8.mlp.fc1.bias torch.Size([2048])\n",
      "backbone.backbone.layers.2.blocks.8.mlp.fc2.weight torch.Size([512, 2048])\n",
      "backbone.backbone.layers.2.blocks.8.mlp.fc2.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.9.norm1.weight torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.9.norm1.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.9.attn.qkv.weight torch.Size([1536, 512])\n",
      "backbone.backbone.layers.2.blocks.9.attn.qkv.bias torch.Size([1536])\n",
      "backbone.backbone.layers.2.blocks.9.attn.proj.weight torch.Size([512, 512])\n",
      "backbone.backbone.layers.2.blocks.9.attn.proj.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.9.norm2.weight torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.9.norm2.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.9.mlp.fc1.weight torch.Size([2048, 512])\n",
      "backbone.backbone.layers.2.blocks.9.mlp.fc1.bias torch.Size([2048])\n",
      "backbone.backbone.layers.2.blocks.9.mlp.fc2.weight torch.Size([512, 2048])\n",
      "backbone.backbone.layers.2.blocks.9.mlp.fc2.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.10.norm1.weight torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.10.norm1.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.10.attn.qkv.weight torch.Size([1536, 512])\n",
      "backbone.backbone.layers.2.blocks.10.attn.qkv.bias torch.Size([1536])\n",
      "backbone.backbone.layers.2.blocks.10.attn.proj.weight torch.Size([512, 512])\n",
      "backbone.backbone.layers.2.blocks.10.attn.proj.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.10.norm2.weight torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.10.norm2.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.10.mlp.fc1.weight torch.Size([2048, 512])\n",
      "backbone.backbone.layers.2.blocks.10.mlp.fc1.bias torch.Size([2048])\n",
      "backbone.backbone.layers.2.blocks.10.mlp.fc2.weight torch.Size([512, 2048])\n",
      "backbone.backbone.layers.2.blocks.10.mlp.fc2.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.11.norm1.weight torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.11.norm1.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.11.attn.qkv.weight torch.Size([1536, 512])\n",
      "backbone.backbone.layers.2.blocks.11.attn.qkv.bias torch.Size([1536])\n",
      "backbone.backbone.layers.2.blocks.11.attn.proj.weight torch.Size([512, 512])\n",
      "backbone.backbone.layers.2.blocks.11.attn.proj.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.11.norm2.weight torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.11.norm2.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.11.mlp.fc1.weight torch.Size([2048, 512])\n",
      "backbone.backbone.layers.2.blocks.11.mlp.fc1.bias torch.Size([2048])\n",
      "backbone.backbone.layers.2.blocks.11.mlp.fc2.weight torch.Size([512, 2048])\n",
      "backbone.backbone.layers.2.blocks.11.mlp.fc2.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.12.norm1.weight torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.12.norm1.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.12.attn.qkv.weight torch.Size([1536, 512])\n",
      "backbone.backbone.layers.2.blocks.12.attn.qkv.bias torch.Size([1536])\n",
      "backbone.backbone.layers.2.blocks.12.attn.proj.weight torch.Size([512, 512])\n",
      "backbone.backbone.layers.2.blocks.12.attn.proj.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.12.norm2.weight torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.12.norm2.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.12.mlp.fc1.weight torch.Size([2048, 512])\n",
      "backbone.backbone.layers.2.blocks.12.mlp.fc1.bias torch.Size([2048])\n",
      "backbone.backbone.layers.2.blocks.12.mlp.fc2.weight torch.Size([512, 2048])\n",
      "backbone.backbone.layers.2.blocks.12.mlp.fc2.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.13.norm1.weight torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.13.norm1.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.13.attn.qkv.weight torch.Size([1536, 512])\n",
      "backbone.backbone.layers.2.blocks.13.attn.qkv.bias torch.Size([1536])\n",
      "backbone.backbone.layers.2.blocks.13.attn.proj.weight torch.Size([512, 512])\n",
      "backbone.backbone.layers.2.blocks.13.attn.proj.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.13.norm2.weight torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.13.norm2.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.13.mlp.fc1.weight torch.Size([2048, 512])\n",
      "backbone.backbone.layers.2.blocks.13.mlp.fc1.bias torch.Size([2048])\n",
      "backbone.backbone.layers.2.blocks.13.mlp.fc2.weight torch.Size([512, 2048])\n",
      "backbone.backbone.layers.2.blocks.13.mlp.fc2.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.14.norm1.weight torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.14.norm1.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.14.attn.qkv.weight torch.Size([1536, 512])\n",
      "backbone.backbone.layers.2.blocks.14.attn.qkv.bias torch.Size([1536])\n",
      "backbone.backbone.layers.2.blocks.14.attn.proj.weight torch.Size([512, 512])\n",
      "backbone.backbone.layers.2.blocks.14.attn.proj.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.14.norm2.weight torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.14.norm2.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.14.mlp.fc1.weight torch.Size([2048, 512])\n",
      "backbone.backbone.layers.2.blocks.14.mlp.fc1.bias torch.Size([2048])\n",
      "backbone.backbone.layers.2.blocks.14.mlp.fc2.weight torch.Size([512, 2048])\n",
      "backbone.backbone.layers.2.blocks.14.mlp.fc2.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.15.norm1.weight torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.15.norm1.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.15.attn.qkv.weight torch.Size([1536, 512])\n",
      "backbone.backbone.layers.2.blocks.15.attn.qkv.bias torch.Size([1536])\n",
      "backbone.backbone.layers.2.blocks.15.attn.proj.weight torch.Size([512, 512])\n",
      "backbone.backbone.layers.2.blocks.15.attn.proj.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.15.norm2.weight torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.15.norm2.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.15.mlp.fc1.weight torch.Size([2048, 512])\n",
      "backbone.backbone.layers.2.blocks.15.mlp.fc1.bias torch.Size([2048])\n",
      "backbone.backbone.layers.2.blocks.15.mlp.fc2.weight torch.Size([512, 2048])\n",
      "backbone.backbone.layers.2.blocks.15.mlp.fc2.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.16.norm1.weight torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.16.norm1.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.16.attn.qkv.weight torch.Size([1536, 512])\n",
      "backbone.backbone.layers.2.blocks.16.attn.qkv.bias torch.Size([1536])\n",
      "backbone.backbone.layers.2.blocks.16.attn.proj.weight torch.Size([512, 512])\n",
      "backbone.backbone.layers.2.blocks.16.attn.proj.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.16.norm2.weight torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.16.norm2.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.16.mlp.fc1.weight torch.Size([2048, 512])\n",
      "backbone.backbone.layers.2.blocks.16.mlp.fc1.bias torch.Size([2048])\n",
      "backbone.backbone.layers.2.blocks.16.mlp.fc2.weight torch.Size([512, 2048])\n",
      "backbone.backbone.layers.2.blocks.16.mlp.fc2.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.17.norm1.weight torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.17.norm1.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.17.attn.qkv.weight torch.Size([1536, 512])\n",
      "backbone.backbone.layers.2.blocks.17.attn.qkv.bias torch.Size([1536])\n",
      "backbone.backbone.layers.2.blocks.17.attn.proj.weight torch.Size([512, 512])\n",
      "backbone.backbone.layers.2.blocks.17.attn.proj.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.17.norm2.weight torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.17.norm2.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.17.mlp.fc1.weight torch.Size([2048, 512])\n",
      "backbone.backbone.layers.2.blocks.17.mlp.fc1.bias torch.Size([2048])\n",
      "backbone.backbone.layers.2.blocks.17.mlp.fc2.weight torch.Size([512, 2048])\n",
      "backbone.backbone.layers.2.blocks.17.mlp.fc2.bias torch.Size([512])\n",
      "backbone.backbone.layers.2.blocks.0.attn.relative_position_index torch.Size([144, 144])\n",
      "backbone.backbone.layers.2.blocks.1.attn.relative_position_index torch.Size([144, 144])\n",
      "backbone.backbone.layers.2.blocks.2.attn.relative_position_index torch.Size([144, 144])\n",
      "backbone.backbone.layers.2.blocks.3.attn.relative_position_index torch.Size([144, 144])\n",
      "backbone.backbone.layers.2.blocks.4.attn.relative_position_index torch.Size([144, 144])\n",
      "backbone.backbone.layers.2.blocks.5.attn.relative_position_index torch.Size([144, 144])\n",
      "backbone.backbone.layers.2.blocks.6.attn.relative_position_index torch.Size([144, 144])\n",
      "backbone.backbone.layers.2.blocks.7.attn.relative_position_index torch.Size([144, 144])\n",
      "backbone.backbone.layers.2.blocks.8.attn.relative_position_index torch.Size([144, 144])\n",
      "backbone.backbone.layers.2.blocks.9.attn.relative_position_index torch.Size([144, 144])\n",
      "backbone.backbone.layers.2.blocks.10.attn.relative_position_index torch.Size([144, 144])\n",
      "backbone.backbone.layers.2.blocks.11.attn.relative_position_index torch.Size([144, 144])\n",
      "backbone.backbone.layers.2.blocks.12.attn.relative_position_index torch.Size([144, 144])\n",
      "backbone.backbone.layers.2.blocks.13.attn.relative_position_index torch.Size([144, 144])\n",
      "backbone.backbone.layers.2.blocks.14.attn.relative_position_index torch.Size([144, 144])\n",
      "backbone.backbone.layers.2.blocks.15.attn.relative_position_index torch.Size([144, 144])\n",
      "backbone.backbone.layers.2.blocks.16.attn.relative_position_index torch.Size([144, 144])\n",
      "backbone.backbone.layers.2.blocks.17.attn.relative_position_index torch.Size([144, 144])\n",
      "backbone.backbone.layers.2.blocks.1.attn_mask torch.Size([4, 144, 144])\n",
      "backbone.backbone.layers.2.blocks.3.attn_mask torch.Size([4, 144, 144])\n",
      "backbone.backbone.layers.2.blocks.5.attn_mask torch.Size([4, 144, 144])\n",
      "backbone.backbone.layers.2.blocks.7.attn_mask torch.Size([4, 144, 144])\n",
      "backbone.backbone.layers.2.blocks.9.attn_mask torch.Size([4, 144, 144])\n",
      "backbone.backbone.layers.2.blocks.11.attn_mask torch.Size([4, 144, 144])\n",
      "backbone.backbone.layers.2.blocks.13.attn_mask torch.Size([4, 144, 144])\n",
      "backbone.backbone.layers.2.blocks.15.attn_mask torch.Size([4, 144, 144])\n",
      "backbone.backbone.layers.2.blocks.17.attn_mask torch.Size([4, 144, 144])\n",
      "backbone.backbone.layers.2.blocks.0.attn.relative_position_bias_table torch.Size([529, 16])\n",
      "backbone.backbone.layers.2.blocks.1.attn.relative_position_bias_table torch.Size([529, 16])\n",
      "backbone.backbone.layers.2.blocks.2.attn.relative_position_bias_table torch.Size([529, 16])\n",
      "backbone.backbone.layers.2.blocks.3.attn.relative_position_bias_table torch.Size([529, 16])\n",
      "backbone.backbone.layers.2.blocks.4.attn.relative_position_bias_table torch.Size([529, 16])\n",
      "backbone.backbone.layers.2.blocks.5.attn.relative_position_bias_table torch.Size([529, 16])\n",
      "backbone.backbone.layers.2.blocks.6.attn.relative_position_bias_table torch.Size([529, 16])\n",
      "backbone.backbone.layers.2.blocks.7.attn.relative_position_bias_table torch.Size([529, 16])\n",
      "backbone.backbone.layers.2.blocks.8.attn.relative_position_bias_table torch.Size([529, 16])\n",
      "backbone.backbone.layers.2.blocks.9.attn.relative_position_bias_table torch.Size([529, 16])\n",
      "backbone.backbone.layers.2.blocks.10.attn.relative_position_bias_table torch.Size([529, 16])\n",
      "backbone.backbone.layers.2.blocks.11.attn.relative_position_bias_table torch.Size([529, 16])\n",
      "backbone.backbone.layers.2.blocks.12.attn.relative_position_bias_table torch.Size([529, 16])\n",
      "backbone.backbone.layers.2.blocks.13.attn.relative_position_bias_table torch.Size([529, 16])\n",
      "backbone.backbone.layers.2.blocks.14.attn.relative_position_bias_table torch.Size([529, 16])\n",
      "backbone.backbone.layers.2.blocks.15.attn.relative_position_bias_table torch.Size([529, 16])\n",
      "backbone.backbone.layers.2.blocks.16.attn.relative_position_bias_table torch.Size([529, 16])\n",
      "backbone.backbone.layers.2.blocks.17.attn.relative_position_bias_table torch.Size([529, 16])\n",
      "backbone.backbone.layers.2.downsample.reduction.weight torch.Size([512, 1024])\n"
     ]
    }
   ],
   "source": [
    "for k in list(temp4.keys()):\n",
    "    print(k, temp4[k].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c0270c",
   "metadata": {},
   "source": [
    "## layers.3(31= 2 * 14 +3) （从layers.3开始没有attn_mask）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d425004",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T13:18:33.063904Z",
     "start_time": "2021-11-26T13:18:32.756687Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "path = r\"G:\\学习资料\\目标检测\\swin_base_patch4_window12_384.pth\"\n",
    "backbone_weight = torch.load(path)\n",
    "for name, para in backbone_weight.items():\n",
    "    backbone_weight = para\n",
    "\n",
    "i = 0\n",
    "temp5 = collections.OrderedDict()\n",
    "for k in list(backbone_weight.keys()):\n",
    "    if \"layers.2.downsample\" in k:\n",
    "        p = k.replace(\"layers.2\", \"layers.3\")\n",
    "        new_name = \"backbone.backbone.\" + p\n",
    "        temp5.update({new_name:backbone_weight[k]})\n",
    "        i += 1\n",
    "    if \"layers.3.blocks\" in k:\n",
    "        new_name = \"backbone.backbone.\" + k\n",
    "        temp5.update({new_name:backbone_weight[k]})\n",
    "        i += 1\n",
    "#         new_name = \"backbone.backbone.\" + k\n",
    "#         print(k, backbone_weight[k].size())\n",
    "#         temp2.update({new_name:backbone_weight[k]})\n",
    "#         i += 1\n",
    "\n",
    "print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595f2566",
   "metadata": {},
   "source": [
    "## layers.4(12,即spp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78580f2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T13:18:33.190590Z",
     "start_time": "2021-11-26T13:18:33.065860Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "path = r\"G:\\学习资料\\目标检测\\yolox_l.pth\"\n",
    "no_backbone_weight = torch.load(path)\n",
    "i = 0\n",
    "\n",
    "temp6 = collections.OrderedDict()\n",
    "for k in list(no_backbone_weight.keys()):\n",
    "    if \"backbone.backbone.dark5.1\" in k:\n",
    "#         i += 1\n",
    "        new_name = k.replace(\"dark5.1\", \"layers.4\")\n",
    "        temp6.update({new_name:no_backbone_weight[k]})\n",
    "#         new_name = \"backbone.backbone.\" + k\n",
    "#         temp1.update({new_name: backbone_weight[k]})\n",
    "#         i += 1\n",
    "#         del no_backbone_weight[k]\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f211160d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T13:00:02.384718Z",
     "start_time": "2021-11-26T13:00:02.369726Z"
    }
   },
   "source": [
    "## others(240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a1d24c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T13:18:33.315950Z",
     "start_time": "2021-11-26T13:18:33.192279Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "path = r\"G:\\学习资料\\目标检测\\yolox_l.pth\"\n",
    "no_backbone_weight = torch.load(path)\n",
    "\n",
    "i = 0\n",
    "\n",
    "temp7 = collections.OrderedDict()\n",
    "for k in list(no_backbone_weight.keys()):\n",
    "    if \"backbone.backbone\" in k:\n",
    "        del no_backbone_weight[k]\n",
    "#         i += 1\n",
    "#         new_name = k.replace(\"dark5.1\", \"layers.4\")\n",
    "#         temp6.update({new_name:no_backbone_weight[k]})\n",
    "for k in list(no_backbone_weight.keys()):\n",
    "    if \"backbone\" in k:\n",
    "#         i += 1\n",
    "        temp7.update({k:no_backbone_weight[k]})\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee1093c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T13:18:33.330950Z",
     "start_time": "2021-11-26T13:18:33.316947Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(temp7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e9327e",
   "metadata": {},
   "source": [
    "## head(108)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16b519df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T13:18:33.425660Z",
     "start_time": "2021-11-26T13:18:33.331905Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "path = r\"G:\\学习资料\\目标检测\\yolox_l.pth\"\n",
    "no_backbone_weight = torch.load(path)\n",
    "\n",
    "i = 0\n",
    "\n",
    "temp8 = collections.OrderedDict()\n",
    "\n",
    "#         i += 1\n",
    "#         new_name = k.replace(\"dark5.1\", \"layers.4\")\n",
    "#         temp6.update({new_name:no_backbone_weight[k]})\n",
    "for k in list(no_backbone_weight.keys()):\n",
    "    if \"head\" in k:\n",
    "#         i += 1\n",
    "        temp8.update({k:no_backbone_weight[k]})\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "461bb3fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T13:18:33.441654Z",
     "start_time": "2021-11-26T13:18:33.426654Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head.cls_convs.0.0.conv.weight torch.Size([256, 256, 3, 3])\n",
      "head.cls_convs.0.0.bn.weight torch.Size([256])\n",
      "head.cls_convs.0.0.bn.bias torch.Size([256])\n",
      "head.cls_convs.0.0.bn.running_mean torch.Size([256])\n",
      "head.cls_convs.0.0.bn.running_var torch.Size([256])\n",
      "head.cls_convs.0.0.bn.num_batches_tracked torch.Size([])\n",
      "head.cls_convs.0.1.conv.weight torch.Size([256, 256, 3, 3])\n",
      "head.cls_convs.0.1.bn.weight torch.Size([256])\n",
      "head.cls_convs.0.1.bn.bias torch.Size([256])\n",
      "head.cls_convs.0.1.bn.running_mean torch.Size([256])\n",
      "head.cls_convs.0.1.bn.running_var torch.Size([256])\n",
      "head.cls_convs.0.1.bn.num_batches_tracked torch.Size([])\n",
      "head.cls_convs.1.0.conv.weight torch.Size([256, 256, 3, 3])\n",
      "head.cls_convs.1.0.bn.weight torch.Size([256])\n",
      "head.cls_convs.1.0.bn.bias torch.Size([256])\n",
      "head.cls_convs.1.0.bn.running_mean torch.Size([256])\n",
      "head.cls_convs.1.0.bn.running_var torch.Size([256])\n",
      "head.cls_convs.1.0.bn.num_batches_tracked torch.Size([])\n",
      "head.cls_convs.1.1.conv.weight torch.Size([256, 256, 3, 3])\n",
      "head.cls_convs.1.1.bn.weight torch.Size([256])\n",
      "head.cls_convs.1.1.bn.bias torch.Size([256])\n",
      "head.cls_convs.1.1.bn.running_mean torch.Size([256])\n",
      "head.cls_convs.1.1.bn.running_var torch.Size([256])\n",
      "head.cls_convs.1.1.bn.num_batches_tracked torch.Size([])\n",
      "head.cls_convs.2.0.conv.weight torch.Size([256, 256, 3, 3])\n",
      "head.cls_convs.2.0.bn.weight torch.Size([256])\n",
      "head.cls_convs.2.0.bn.bias torch.Size([256])\n",
      "head.cls_convs.2.0.bn.running_mean torch.Size([256])\n",
      "head.cls_convs.2.0.bn.running_var torch.Size([256])\n",
      "head.cls_convs.2.0.bn.num_batches_tracked torch.Size([])\n",
      "head.cls_convs.2.1.conv.weight torch.Size([256, 256, 3, 3])\n",
      "head.cls_convs.2.1.bn.weight torch.Size([256])\n",
      "head.cls_convs.2.1.bn.bias torch.Size([256])\n",
      "head.cls_convs.2.1.bn.running_mean torch.Size([256])\n",
      "head.cls_convs.2.1.bn.running_var torch.Size([256])\n",
      "head.cls_convs.2.1.bn.num_batches_tracked torch.Size([])\n",
      "head.reg_convs.0.0.conv.weight torch.Size([256, 256, 3, 3])\n",
      "head.reg_convs.0.0.bn.weight torch.Size([256])\n",
      "head.reg_convs.0.0.bn.bias torch.Size([256])\n",
      "head.reg_convs.0.0.bn.running_mean torch.Size([256])\n",
      "head.reg_convs.0.0.bn.running_var torch.Size([256])\n",
      "head.reg_convs.0.0.bn.num_batches_tracked torch.Size([])\n",
      "head.reg_convs.0.1.conv.weight torch.Size([256, 256, 3, 3])\n",
      "head.reg_convs.0.1.bn.weight torch.Size([256])\n",
      "head.reg_convs.0.1.bn.bias torch.Size([256])\n",
      "head.reg_convs.0.1.bn.running_mean torch.Size([256])\n",
      "head.reg_convs.0.1.bn.running_var torch.Size([256])\n",
      "head.reg_convs.0.1.bn.num_batches_tracked torch.Size([])\n",
      "head.reg_convs.1.0.conv.weight torch.Size([256, 256, 3, 3])\n",
      "head.reg_convs.1.0.bn.weight torch.Size([256])\n",
      "head.reg_convs.1.0.bn.bias torch.Size([256])\n",
      "head.reg_convs.1.0.bn.running_mean torch.Size([256])\n",
      "head.reg_convs.1.0.bn.running_var torch.Size([256])\n",
      "head.reg_convs.1.0.bn.num_batches_tracked torch.Size([])\n",
      "head.reg_convs.1.1.conv.weight torch.Size([256, 256, 3, 3])\n",
      "head.reg_convs.1.1.bn.weight torch.Size([256])\n",
      "head.reg_convs.1.1.bn.bias torch.Size([256])\n",
      "head.reg_convs.1.1.bn.running_mean torch.Size([256])\n",
      "head.reg_convs.1.1.bn.running_var torch.Size([256])\n",
      "head.reg_convs.1.1.bn.num_batches_tracked torch.Size([])\n",
      "head.reg_convs.2.0.conv.weight torch.Size([256, 256, 3, 3])\n",
      "head.reg_convs.2.0.bn.weight torch.Size([256])\n",
      "head.reg_convs.2.0.bn.bias torch.Size([256])\n",
      "head.reg_convs.2.0.bn.running_mean torch.Size([256])\n",
      "head.reg_convs.2.0.bn.running_var torch.Size([256])\n",
      "head.reg_convs.2.0.bn.num_batches_tracked torch.Size([])\n",
      "head.reg_convs.2.1.conv.weight torch.Size([256, 256, 3, 3])\n",
      "head.reg_convs.2.1.bn.weight torch.Size([256])\n",
      "head.reg_convs.2.1.bn.bias torch.Size([256])\n",
      "head.reg_convs.2.1.bn.running_mean torch.Size([256])\n",
      "head.reg_convs.2.1.bn.running_var torch.Size([256])\n",
      "head.reg_convs.2.1.bn.num_batches_tracked torch.Size([])\n",
      "head.cls_preds.0.weight torch.Size([80, 256, 1, 1])\n",
      "head.cls_preds.0.bias torch.Size([80])\n",
      "head.cls_preds.1.weight torch.Size([80, 256, 1, 1])\n",
      "head.cls_preds.1.bias torch.Size([80])\n",
      "head.cls_preds.2.weight torch.Size([80, 256, 1, 1])\n",
      "head.cls_preds.2.bias torch.Size([80])\n",
      "head.reg_preds.0.weight torch.Size([4, 256, 1, 1])\n",
      "head.reg_preds.0.bias torch.Size([4])\n",
      "head.reg_preds.1.weight torch.Size([4, 256, 1, 1])\n",
      "head.reg_preds.1.bias torch.Size([4])\n",
      "head.reg_preds.2.weight torch.Size([4, 256, 1, 1])\n",
      "head.reg_preds.2.bias torch.Size([4])\n",
      "head.obj_preds.0.weight torch.Size([1, 256, 1, 1])\n",
      "head.obj_preds.0.bias torch.Size([1])\n",
      "head.obj_preds.1.weight torch.Size([1, 256, 1, 1])\n",
      "head.obj_preds.1.bias torch.Size([1])\n",
      "head.obj_preds.2.weight torch.Size([1, 256, 1, 1])\n",
      "head.obj_preds.2.bias torch.Size([1])\n",
      "head.stems.0.conv.weight torch.Size([256, 256, 1, 1])\n",
      "head.stems.0.bn.weight torch.Size([256])\n",
      "head.stems.0.bn.bias torch.Size([256])\n",
      "head.stems.0.bn.running_mean torch.Size([256])\n",
      "head.stems.0.bn.running_var torch.Size([256])\n",
      "head.stems.0.bn.num_batches_tracked torch.Size([])\n",
      "head.stems.1.conv.weight torch.Size([256, 512, 1, 1])\n",
      "head.stems.1.bn.weight torch.Size([256])\n",
      "head.stems.1.bn.bias torch.Size([256])\n",
      "head.stems.1.bn.running_mean torch.Size([256])\n",
      "head.stems.1.bn.running_var torch.Size([256])\n",
      "head.stems.1.bn.num_batches_tracked torch.Size([])\n",
      "head.stems.2.conv.weight torch.Size([256, 1024, 1, 1])\n",
      "head.stems.2.bn.weight torch.Size([256])\n",
      "head.stems.2.bn.bias torch.Size([256])\n",
      "head.stems.2.bn.running_mean torch.Size([256])\n",
      "head.stems.2.bn.running_var torch.Size([256])\n",
      "head.stems.2.bn.num_batches_tracked torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "for i,k in temp8.items():\n",
    "    print(i, k.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91847e2",
   "metadata": {},
   "source": [
    "## 汇总所有的权值（709+11（attn_mask）=720）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a231f862",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T13:18:33.457899Z",
     "start_time": "2021-11-26T13:18:33.442609Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720\n"
     ]
    }
   ],
   "source": [
    "temp = collections.OrderedDict()\n",
    "temp.update(temp1)\n",
    "temp.update(temp2)\n",
    "temp.update(temp3)\n",
    "temp.update(temp4)\n",
    "temp.update(temp5)\n",
    "temp.update(temp6)\n",
    "temp.update(temp7)\n",
    "temp.update(temp8)\n",
    "print(len(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c4ab9a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T13:20:42.864994Z",
     "start_time": "2021-11-26T13:20:42.207142Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(temp, \"G:/学习资料/目标检测/swinyolo.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0d423c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T14:04:54.116343Z",
     "start_time": "2021-11-26T14:04:53.721126Z"
    }
   },
   "outputs": [],
   "source": [
    "path = r\"G:\\学习资料\\目标检测\\swinyolo.pth\"\n",
    "true_weight = torch.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b3d1f70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T14:09:38.227839Z",
     "start_time": "2021-11-26T14:09:38.213876Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "709\n"
     ]
    }
   ],
   "source": [
    "for k in list(true_weight.keys()):\n",
    "    if \"attn_mask\" in k:\n",
    "#         i += 1\n",
    "#         temp8.update({k:no_backbone_weight[k]})\n",
    "        del true_weight[k]\n",
    "new_weight = true_weight\n",
    "print(len(new_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b4d5e89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T14:46:41.230808Z",
     "start_time": "2021-11-26T14:46:40.584281Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(temp, \"G:/学习资料/目标检测/true_swinyolo.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32edadf1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T13:29:04.461601Z",
     "start_time": "2021-11-26T13:26:23.791Z"
    }
   },
   "outputs": [],
   "source": [
    "model = YoloBody(num_classes=80, phi=\"l\")\n",
    "model.load_state_dict(true_weight, strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e49b247",
   "metadata": {},
   "source": [
    "## 查看具体某一层的详细信息，注意其与参数是有变化的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c7c8475",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T13:18:34.916666Z",
     "start_time": "2021-11-26T13:18:33.459564Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "model = YoloBody(num_classes=80, phi=\"l\")\n",
    "# 查看模型及参数\n",
    "# print(model.backbone.backbone.state_dict())\n",
    "\n",
    "# 查看具体某一层的详细信息，注意其与参数是有变化的\n",
    "# print(model.backbone.backbone.patch_embed)\n",
    "print(type(model.backbone.backbone.patch_embed.proj.bias)) # nn.parameters\n",
    "print(type(model.backbone.backbone.patch_embed.proj.bias.data)) # tensor\n",
    "print(type(model.backbone.backbone.patch_embed.proj.bias.grad)) # 还没计算就是None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69a2b5ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T13:18:34.932624Z",
     "start_time": "2021-11-26T13:18:34.918661Z"
    }
   },
   "outputs": [],
   "source": [
    "# 下划线在函数名后面表示是替换函数，会直接替换掉变量原来的值\n",
    "# net.add_module('name', block())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "091ee239",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T13:18:34.948581Z",
     "start_time": "2021-11-26T13:18:34.934618Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YoloBody(\n",
      "  (backbone): YOLOPAFPN(\n",
      "    (backbone): SwinTransformer(\n",
      "      (patch_embed): PatchEmbed(\n",
      "        (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
      "        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "      (layers): ModuleList(\n",
      "        (0): BasicLayer(\n",
      "          (blocks): ModuleList(\n",
      "            (0): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path): Identity()\n",
      "              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "                (act): GELU()\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (1): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path): DropPath()\n",
      "              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "                (act): GELU()\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): BasicLayer(\n",
      "          (blocks): ModuleList(\n",
      "            (0): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path): DropPath()\n",
      "              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "                (act): GELU()\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (1): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path): DropPath()\n",
      "              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "                (act): GELU()\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (downsample): PatchMerging(\n",
      "            (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
      "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (2): BasicLayer(\n",
      "          (blocks): ModuleList(\n",
      "            (0): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path): DropPath()\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                (act): GELU()\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (1): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path): DropPath()\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                (act): GELU()\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (2): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path): DropPath()\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                (act): GELU()\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (3): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path): DropPath()\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                (act): GELU()\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (4): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path): DropPath()\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                (act): GELU()\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (5): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path): DropPath()\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                (act): GELU()\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (6): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path): DropPath()\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                (act): GELU()\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (7): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path): DropPath()\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                (act): GELU()\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (8): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path): DropPath()\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                (act): GELU()\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (9): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path): DropPath()\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                (act): GELU()\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (10): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path): DropPath()\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                (act): GELU()\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (11): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path): DropPath()\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                (act): GELU()\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (12): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path): DropPath()\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                (act): GELU()\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (13): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path): DropPath()\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                (act): GELU()\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (14): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path): DropPath()\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                (act): GELU()\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (15): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path): DropPath()\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                (act): GELU()\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (16): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path): DropPath()\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                (act): GELU()\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (17): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path): DropPath()\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                (act): GELU()\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (downsample): PatchMerging(\n",
      "            (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
      "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (3): BasicLayer(\n",
      "          (blocks): ModuleList(\n",
      "            (0): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path): DropPath()\n",
      "              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (act): GELU()\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (1): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path): DropPath()\n",
      "              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (act): GELU()\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (downsample): PatchMerging(\n",
      "            (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
      "            (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (4): SPPBottleneck(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (m): ModuleList(\n",
      "            (0): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
      "            (1): MaxPool2d(kernel_size=9, stride=1, padding=4, dilation=1, ceil_mode=False)\n",
      "            (2): MaxPool2d(kernel_size=13, stride=1, padding=6, dilation=1, ceil_mode=False)\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(1024, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
      "    (lateral_conv0): BaseConv(\n",
      "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (C3_p4): CSPLayer(\n",
      "      (conv1): BaseConv(\n",
      "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (conv2): BaseConv(\n",
      "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (conv3): BaseConv(\n",
      "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (reduce_conv1): BaseConv(\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (C3_p3): CSPLayer(\n",
      "      (conv1): BaseConv(\n",
      "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (conv2): BaseConv(\n",
      "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (conv3): BaseConv(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bu_conv2): BaseConv(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (C3_n3): CSPLayer(\n",
      "      (conv1): BaseConv(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (conv2): BaseConv(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (conv3): BaseConv(\n",
      "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bu_conv1): BaseConv(\n",
      "      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (C3_n4): CSPLayer(\n",
      "      (conv1): BaseConv(\n",
      "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (conv2): BaseConv(\n",
      "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (conv3): BaseConv(\n",
      "        (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(1024, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): YOLOXHead(\n",
      "    (cls_convs): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): BaseConv(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (1): BaseConv(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): BaseConv(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (1): BaseConv(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): BaseConv(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (1): BaseConv(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (reg_convs): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): BaseConv(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (1): BaseConv(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): BaseConv(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (1): BaseConv(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): BaseConv(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (1): BaseConv(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (cls_preds): ModuleList(\n",
      "      (0): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (2): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (reg_preds): ModuleList(\n",
      "      (0): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (2): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (obj_preds): ModuleList(\n",
      "      (0): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (2): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (stems): ModuleList(\n",
      "      (0): BaseConv(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (1): BaseConv(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (2): BaseConv(\n",
      "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python37",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
